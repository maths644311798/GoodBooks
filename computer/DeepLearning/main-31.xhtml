<?xml version="1.0" encoding="UTF-8"?>

<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta name="charset" content="UTF-8"/><title></title><link rel="stylesheet" href="main.css" type="text/css"/>
</head>
<body><h4><a id="bookmark0"></a><span class="font65" style="font-weight:bold;">16.5 Learning about Dependencies</span></h4>
<p><span class="font64">A good generative model needs to accurately capture the distribution over the observed or “visible” variables v. Often the different elements of v are highly&#160;dependent on each other. In the context of deep learning, the approach most&#160;commonly used to model these dependencies is to introduce several latent or&#160;“hidden” variables, h. The model can then capture dependencies between any pair&#160;of variables v and </span><span class="font64" style="font-weight:bold;font-style:italic;">vj</span><span class="font64"> indirectly, via direct dependencies between v and h, and&#160;direct dependencies between h and vj.</span></p>
<p><span class="font64">A good model of v which did not contain any latent variables would need to have very large numbers of parents per node in a Bayesian network or very large&#160;cliques in a Markov network. Just representing these higher order interactions is&#160;costly—both in a computational sense, because the number of parameters that&#160;must be stored in memory scales exponentially with the number of members in a&#160;clique, but also in a statistical sense, because this exponential number of parameters&#160;requires a wealth of data to estimate accurately.</span></p>
<p><span class="font64">When the model is intended to capture dependencies between visible variables with direct connections, it is usually infeasible to connect all variables, so the graph&#160;must be designed to connect those variables that are tightly coupled and omit&#160;edges between other variables. An entire field of machine learning called </span><span class="font64" style="font-weight:bold;font-style:italic;">structure&#160;learning</span><span class="font64"> is devoted to this problem For a good reference on structure learning, see&#160;(Koller and Friedman, 2009). Most structure learning techniques are a form of&#160;greedy search. A structure is proposed, a model with that structure is trained,&#160;then given a score. The score rewards high training set accuracy and penalizes&#160;model complexity. Candidate structures with a small number of edges added or&#160;removed are then proposed as the next step of the search. The search proceeds to&#160;a new structure that is expected to increase the score.</span></p>
<p><span class="font64">Using latent variables instead of adaptive structure avoids the need to perform discrete searches and multiple rounds of training. A fixed structure over visible&#160;and hidden variables can use direct interactions between visible and hidden units&#160;to impose indirect interactions between visible units. Using simple parameter&#160;learning techniques we can learn a model with a fixed structure that imputes the&#160;right structure on the marginal </span><span class="font64" style="font-weight:bold;font-style:italic;">p(v).</span></p>
<p><span class="font64">Latent variables have advantages beyond their role in efficiently capturing </span><span class="font64" style="font-weight:bold;font-style:italic;">p(v). </span><span class="font64">The new variables h also provide an alternative representation for v. For example,&#160;as discussed in Sec. 3.9.6, the mixture of Gaussians model learns a latent variable&#160;that corresponds to which category of examples the input was drawn from. This&#160;means that the latent variable in a mixture of Gaussians model can be used to do&#160;classification. In Chapter 14 we saw how simple probabilistic models like sparse&#160;coding learn latent variables that can be used as input features for a classifier,&#160;or as coordinates along a manifold. Other models can be used in this same way,&#160;but deeper models and models with different kinds of interactions can create even&#160;richer descriptions of the input. Many approaches accomplish feature learning&#160;by learning latent variables. Often, given some model of v and h, experimental&#160;observations show that E[h | v] or argmax^p(h, v</span><span class="font64" style="font-weight:bold;font-style:italic;">)</span><span class="font64"> is a good feature mapping for&#160;v.</span></p><h4><a id="bookmark1"></a><span class="font65" style="font-weight:bold;">16.6 Inference and Approximate Inference</span></h4>
<p><span class="font64">One of the main ways we can use a probabilistic model is to ask questions about how variables are related to each other. Given a set of medical tests, we can ask&#160;what disease a patient might have. In a latent variable model, we might want to&#160;extract features E[h | v ] describing the observed variables v. Sometimes we need&#160;to solve such problems in order to perform other tasks. We often train our models&#160;using the principle of maximum likelihood. Because</span></p>
<p><span class="font64">logp(v) = Eh~<sub>p</sub>(h|v) <sup>[lo</sup>g</span><span class="font64" style="font-weight:bold;font-style:italic;">P<sup>(</sup></span><span class="font63" style="font-style:italic;"><sup>h</sup></span><span class="font64" style="font-weight:bold;font-style:italic;"><sup>, </sup></span><span class="font63" style="font-style:italic;"><sup>v</sup></span><span class="font64" style="font-weight:bold;font-style:italic;"><sup>) </sup></span><span class="font63" style="font-style:italic;"><sup>-</sup></span><span class="font64"><sup> </sup></span><span class="font18"><sup>10</sup></span><span class="font64">g</span><span class="font64" style="font-weight:bold;font-style:italic;">P<sup>(</sup></span><span class="font63" style="font-style:italic;"><sup>h</sup></span><span class="font64"> \ <sup>v)] , &#160;&#160;&#160;(16</sup>.<sup>9)</sup></span></p>
<p><span class="font64">we often want to compute p(h | v</span><span class="font63" style="font-style:italic;">)</span><span class="font64"> in order to implement a learning rule. All of these are examples of </span><span class="font63" style="font-style:italic;">inference</span><span class="font64"> problems in which we must predict the value of&#160;some variables given other variables, or predict the probability distribution over&#160;some variables given the value of other variables.</span></p>
<p><span class="font64">Unfortunately, for most interesting deep models, these inference problems are intractable, even when we use a structured graphical model to simplify them. The&#160;graph structure allows us to represent complicated, high-dimensional distributions&#160;with a reasonable number of parameters, but the graphs used for deep learning are&#160;usually not restrictive enough to also allow efficient inference.</span></p>
<p><span class="font64">It is straightforward to see that computing the marginal probability of a general graphical model is #P hard. The complexity class #P is a generalization of the&#160;complexity class NP. Problems in NP require determining only whether a problem&#160;has a solution and finding a solution if one exists. Problems in #P require counting&#160;the number of solutions. To construct a worst-case graphical model, imagine that&#160;we define a graphical model over the binary variables in a 3-SAT problem. We&#160;can impose a uniform distribution over these variables. We can then add one&#160;binary latent variable per clause that indicates whether each clause is satisfied.&#160;We can then add another latent variable indicating whether all of the clauses are&#160;satisfied. This can be done without making a large clique, by building a reduction&#160;tree of latent variables, with each node in the tree reporting whether two other&#160;variables are satisfied. The leaves of this tree are the variables for each clause.&#160;The root of the tree reports whether the entire problem is satisfied. Due to the&#160;uniform distribution over the literals, the marginal distribution over the root of the&#160;reduction tree specifies what fraction of assignments satisfy the problem. While&#160;this is a contrived worst-case example, NP hard graphs commonly arise in practical&#160;real-world scenarios.</span></p>
<p><span class="font64">This motivates the use of approximate inference. In the context of deep learning, this usually refers to variational inference, in which we approximate the&#160;true distribution p(h | v) by seeking an approximate distribution q(h|v) that is as&#160;close to the true one as possible. This and other techniques are described in depth&#160;in Chapter 19.</span></p><h4><a id="bookmark2"></a><span class="font65" style="font-weight:bold;">16.7 The Deep Learning Approach to Structured Probabilistic Models</span></h4>
<p><span class="font64">Deep learning practitioners generally use the same basic computational tools as other machine learning practitioners who work with structured probabilistic models.</span></p>
<p><span class="font64">However, in the context of deep learning, we usually make different design decisions about how to combine these tools, resulting in overall algorithms and models that&#160;have a very different flavor from more traditional graphical models.</span></p>
<p><span class="font64">Deep learning does not always involve especially deep graphical models. In the context of graphical models, we can define the depth of a model in terms of the&#160;graphical model graph rather than the computational graph. We can think of a&#160;latent variable </span><span class="font64" style="font-weight:bold;font-style:italic;">hi</span><span class="font64"> as being at depth j if the shortest path from </span><span class="font64" style="font-weight:bold;font-style:italic;">hi</span><span class="font64"> to an observed&#160;variable is j steps. We usually describe the depth of the model as being the greatest&#160;depth of any such h<sub>i</sub>. This kind of depth is different from the depth induced by&#160;the computational graph. Many generative models used for deep learning have no&#160;latent variables or only one layer of latent variables, but use deep computational&#160;graphs to define the conditional distributions within a model.</span></p>
<p><span class="font64">Deep learning essentially always makes use of the idea of distributed representations. Even shallow models used for deep learning purposes (such as pretraining shallow models that will later be composed to form deep ones) nearly always&#160;have a single, large layer of latent variables. Deep learning models typically have&#160;more latent variables than observed variables. Complicated nonlinear interactions&#160;between variables are accomplished via indirect connections that flow through&#160;multiple latent variables.</span></p>
<p><span class="font64">By contrast, traditional graphical models usually contain mostly variables that are at least occasionally observed, even if many of the variables are missing at&#160;random from some training examples. Traditional models mostly use higher-order&#160;terms and structure learning to capture complicated nonlinear interactions between&#160;variables. If there are latent variables, they are usually few in number.</span></p>
<p><span class="font64">The way that latent variables are designed also differs in deep learning. The deep learning practitioner typically does not intend for the latent variables to&#160;take on any specific semantics ahead of time—the training algorithm is free to&#160;invent the concepts it needs to model a particular dataset. The latent variables are&#160;usually not very easy for a human to interpret after the fact, though visualization&#160;techniques may allow some rough characterization of what they represent. When&#160;latent variables are used in the context of traditional graphical models, they are&#160;often designed with some specific semantics in mind—the topic of a document,&#160;the intelligence of a student, the disease causing a patient’s symptoms, etc. These&#160;models are often much more interpretable by human practitioners and often have&#160;more theoretical guarantees, yet are less able to scale to complex problems and are&#160;not reusable in as many different contexts as deep models.</span></p>
<p><span class="font64">Another obvious difference is the kind of connectivity typically used in the deep learning approach. Deep graphical models typically have large groups of units&#160;that are all connected to other groups of units, so that the interactions between&#160;two groups may be described by a single matrix. Traditional graphical models&#160;have very few connections and the choice of connections for each variable may be&#160;individually designed. The design of the model structure is tightly linked with&#160;the choice of inference algorithm. Traditional approaches to graphical models&#160;typically aim to maintain the tractability of exact inference. When this constraint&#160;is too limiting, a popular approximate inference algorithm is an algorithm called&#160;</span><span class="font63" style="font-style:italic;">loopy belief propagation.</span><span class="font64"> Both of these approaches often work well with very&#160;sparsely connected graphs. By comparison, models used in deep learning tend to&#160;connect each visible unit v to very many hidden units hj, so that h can provide a&#160;distributed representation of v (and probably several other observed variables too).&#160;Distributed representations have many advantages, but from the point of view&#160;of graphical models and computational complexity, distributed representations&#160;have the disadvantage of usually yielding graphs that are not sparse enough for&#160;the traditional techniques of exact inference and loopy belief propagation to be&#160;relevant. As a consequence, one of the most striking differences between the larger&#160;graphical models community and the deep graphical models community is that&#160;loopy belief propagation is almost never used for deep learning. Most deep models&#160;are instead designed to make Gibbs sampling or variational inference algorithms&#160;efficient. Another consideration is that deep learning models contain a very large&#160;number of latent variables, making efficient numerical code essential. This provides&#160;an additional motivation, besides the choice of high-level inference algorithm, for&#160;grouping the units into layers with a matrix describing the interaction between&#160;two layers. This allows the individual steps of the algorithm to be implemented&#160;with efficient matrix product operations, or sparsely connected generalizations, like&#160;block diagonal matrix products or convolutions.</span></p>
<p><span class="font64">Finally, the deep learning approach to graphical modeling is characterized by a marked tolerance of the unknown. Rather than simplifying the model until&#160;all quantities we might want can be computed exactly, we increase the power of&#160;the model until it is just barely possible to train or use. We often use models&#160;whose marginal distributions cannot be computed, and are satisfied simply to draw&#160;approximate samples from these models. We often train models with an intractable&#160;objective function that we cannot even approximate in a reasonable amount of&#160;time, but we are still able to approximately train the model if we can efficiently&#160;obtain an estimate of the gradient of such a function. The deep learning approach&#160;is often to figure out what the minimum amount of information we absolutely&#160;need is, and then to figure out how to get a reasonable approximation of that&#160;information as quickly as possible.</span></p><div><img src="main-177.jpg" alt=""/>
<p><span class="font64">Figure 16.14: An RBM drawn as a Markov network.</span></p></div><h5><a id="bookmark3"></a><span class="font64">16.7.1 Example: The Restricted Boltzmann Machine</span></h5>
<p><span class="font64">The </span><span class="font64" style="font-weight:bold;font-style:italic;">restricted Boltzmann machine</span><span class="font64"> (RBM) (Smolensky, 1986) or </span><span class="font64" style="font-weight:bold;font-style:italic;">harmonium</span><span class="font64"> is the quintessential example of how graphical models are used for deep learning. The&#160;RBM is not itself a deep model. Instead, it has a single layer of latent variables&#160;that may be used to learn a representation for the input. In Chapter 20, we will&#160;see how RBMs can be used to build many deeper models. Here, we show how the&#160;RBM exemplifies many of the practices used in a wide variety of deep graphical&#160;models: its units are organized into large groups called layers, the connectivity&#160;between layers is described by a matrix, the connectivity is relatively dense, the&#160;model is designed to allow efficient Gibbs sampling, and the emphasis of the model&#160;design is on freeing the training algorithm to learn latent variables whose semantics&#160;were not specified by the designer. Later, in Sec. 20.2, we will revisit the RBM in&#160;more detail.</span></p>
<p><span class="font64">The canonical RBM is an energy-based model with binary visible and hidden units. Its energy function is</span></p>
<p><span class="font64">E(v, h) = —bv </span><span class="font64" style="font-weight:bold;font-style:italic;">— </span><span class="font63" style="font-style:italic;">c<sup>T</sup>h </span><span class="font64" style="font-weight:bold;font-style:italic;">— </span><span class="font63" style="font-style:italic;">v Wh,</span><span class="font64"> &#160;&#160;&#160;(16.10)</span></p>
<p><span class="font64">where b, c, and W are unconstrained, real-valued, learnable parameters. We can see that the model is divided into two groups of units: v and h, and the interaction&#160;between them is described by a matrix W. The model is depicted graphically&#160;in Fig. 16.14. As this figure makes clear, an important aspect of this model is&#160;that there are no direct interactions between any two visible units or between any&#160;two hidden units (hence the “restricted,” a general Boltzmann machine may have&#160;arbitrary connections).</span></p>
<p><span class="font64">The restrictions on the RBM structure yield the nice properties</span></p>
<p><span class="font63" style="font-style:italic;">p</span><span class="font64" style="font-weight:bold;font-style:italic;">(</span><span class="font63" style="font-style:italic;">h</span><span class="font64"> | v) = np(h</span><span class="font63" style="font-style:italic;">i</span><span class="font64"> | v) &#160;&#160;&#160;(16.11)</span></p>
<p><span class="font64">and</span></p>
<p><span class="font63" style="font-style:italic;">p</span><span class="font64" style="font-weight:bold;font-style:italic;"><sup>(</sup></span><span class="font63" style="font-style:italic;"><sup>v </sup></span><span class="font64" style="font-weight:bold;font-style:italic;"><sup>1</sup></span><span class="font64"><sup> h)</sup> = <sup>n</sup>ip(v i </span><span class="font18"><sup>1</sup></span><span class="font64"><sup> h)</sup>. &#160;&#160;&#160;<sup>(16</sup>.<sup>12)</sup></span></p><h4 dir="rtl"><a id="bookmark4"></a><span class="font64" style="font-weight:bold;">נג?&gt;כ)8־)?3?&gt;??נ?80?ג־£י&amp;ד</span></h4>
<p dir="rtl"><span class="font64">MiJ?׳7tunooutni </span><span class="font65" style="font-weight:bold;">גג?0)£-&gt;??״)??ג?ס?8ג#)&lt;&amp;ד&#160;ג ג n Uq ? ־1 n ג uo8 צ u ל</span></p>
<p dir="rtl"><span class="font64">גג?&gt;,)£־)8*״) Uinonn^ צגי)י}?־1 Uinon ntn?</span></p>
<p><span class="font64">Figure 16.15: Samples from a trained RBM, and its weights. Image reproduced with permission from LISA (2008). </span><span class="font64" style="font-style:italic;">(Left)</span><span class="font64"> Samples from a model trained on MNIST, drawn&#160;using Gibbs sampling. Each column is a separate Gibbs sampling process. Each row&#160;represents the output of another 1,000 steps of Gibbs sampling. Successive samples are&#160;highly correlated with one another. </span><span class="font64" style="font-style:italic;">(Right)</span><span class="font64"> The corresponding weight vectors. Compare&#160;this to the samples and weights of a linear factor model, shown in Fig. 13.2. The samples&#160;here are much better because the RBM priorp(h) is not constrained to be factorial. The&#160;RBM can learn which features should appear together when sampling. On the other hand,&#160;the RBM posterior </span><span class="font64" style="font-style:italic;">p(h |</span><span class="font64"> v) is factorial, while the sparse coding posterior </span><span class="font64" style="font-style:italic;">p(h</span><span class="font63"> | v) is not,&#160;so the sparse coding model may be better for feature extraction. Other models are able&#160;to have both a non-factorial p(h) and a non-factorial p(h | v).</span></p>
<p><span class="font64">The individual conditionals are simple to compute as well. For the binary RBM we obtain:</span></p>
<p><span class="font64">(16.13)</span></p>
<p><span class="font64">(16.14)</span></p>
<p><span class="font64">Together these properties allow for efficient </span><span class="font64" style="font-weight:bold;font-style:italic;">block Gibbs</span><span class="font64"> sampling, which alternates between sampling all of h simultaneously and sampling all of v simultaneously.&#160;Samples generated by Gibbs sampling from an RBM model are shown in Fig.&#160;16.15.</span></p>
<p><span class="font64">Since the energy function itself is just a linear function of the parameters, it is easy to take derivatives of the energy function. For example,</span></p><div>
<p><span class="font64">(16.15)</span></p></div><div><div><img src="main-178.jpg" alt=""/></div></div><div>
<p><span class="font64">P(hi = </span><span class="font18">1</span><span class="font64"> | v) = a v<sup>T</sup>W,<sub>־</sub> + b, ,</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">P</span><span class="font64">(h, = 0 | v) = </span><span class="font18">1</span><span class="font64"> - a v</span><span class="font64" style="font-weight:bold;font-style:italic;"><sup>T</sup></span><span class="font63" style="font-style:italic;">W:</span><span class="font64" style="font-weight:bold;font-style:italic;">,,</span><span class="font64"> + b, &#160;&#160;&#160;.</span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">E</span><span class="font64">(v, h) = —v,hj.</span></p></div>
<p><span class="font64">d</span></p><div>
<p dir="rtl"><span class="font64">נ<sup>,,</sup></span></p></div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">dWi</span></p>
<p><span class="font64">These two properties—efficient Gibbs sampling and efficient derivatives—make training convenient. In Chapter 18, we will see that undirected models may be&#160;trained by computing such derivatives applied to samples from the model.</span></p>
<p><span class="font64">Training the model induces a representation h of the data v. We can often use Eh~<sub>p</sub>(h|<sub>v</sub>) [h] as a set of features to describe v.</span></p>
<p><span class="font64">Overall, the RBM demonstrates the typical deep learning approach to graphical models: representation learning accomplished via layers of latent variables, combined with efficient interactions between layers parametrized by matrices.</span></p>
<p><span class="font64">The language of graphical models provides an elegant, flexible and clear language for describing probabilistic models. In the chapters ahead, we use this language,&#160;among other perspectives, to describe a wide variety of deep probabilistic models.</span></p>
</body>
</html>