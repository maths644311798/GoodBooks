<?xml version="1.0" encoding="UTF-8"?>

<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta name="charset" content="UTF-8"/><title></title><link rel="stylesheet" href="main.css" type="text/css"/>
</head>
<body><h2><span class="font66" style="font-weight:bold;">Chapter 5</span></h2><h2><a id="bookmark0"></a><span class="font67" style="font-weight:bold;">Machine Learning Basics</span></h2>
<p><span class="font64">Deep learning is a specific kind of machine learning. In order to understand deep learning well, one must have a solid understanding of the basic principles&#160;of machine learning. This chapter provides a brief course in the most important&#160;general principles that will be applied throughout the rest of the book. Novice&#160;readers or those who want a wider perspective are encouraged to consider machine&#160;learning textbooks with a more comprehensive coverage of the fundamentals, such&#160;as Murphy (2012) or Bishop (2006). If you are already familiar with machine&#160;learning basics, feel free to skip ahead to Sec. 5.11. That section covers some perspectives on traditional machine learning techniques that have strongly influenced&#160;the development of deep learning algorithms.</span></p>
<p><span class="font64">We begin with a definition of what a learning algorithm is, and present an example: the linear regression algorithm. We then proceed to describe how the&#160;challenge of fitting the training data differs from the challenge of finding patterns&#160;that generalize to new data. Most machine learning algorithms have settings&#160;called hyperparameters that must be determined external to the learning algorithm&#160;itself; we discuss how to set these using additional data. Machine learning is&#160;essentially a form of applied statistics with increased emphasis on the use of&#160;computers to statistically estimate complicated functions and a decreased emphasis&#160;on proving confidence intervals around these functions; we therefore present the&#160;two central approaches to statistics: frequentist estimators and Bayesian inference.&#160;Most machine learning algorithms can be divided into the categories of supervised&#160;learning and unsupervised learning; we describe these categories and give some&#160;examples of simple learning algorithms from each category. Most deep learning&#160;algorithms are based on an optimization algorithm called stochastic gradient&#160;descent. We describe how to combine various algorithm components such as an&#160;optimization algorithm, a cost function, a model, and a dataset to build a machine&#160;learning algorithm. Finally, in Sec. 5.11, we describe some of the factors that have&#160;limited the ability of traditional machine learning to generalize. These challenges&#160;have motivated the development of deep learning algorithms that overcome these&#160;obstacles.</span></p><h4><a id="bookmark1"></a><span class="font65" style="font-weight:bold;">5.1 &#160;&#160;&#160;Learning Algorithms</span></h4>
<p><span class="font64">A machine learning algorithm is an algorithm that is able to learn from data. But what do we mean by learning? Mitchell (1997) provides the definition “A computer&#160;program is said to learn from experience E with respect to some class of tasks T&#160;and performance measure P, if its performance at tasks in T, as measured by </span><span class="font64" style="font-weight:bold;font-style:italic;">P</span><span class="font64">,&#160;improves with experience E.” One can imagine a very wide variety of experiences&#160;E, tasks T, and performance measures P, and we do not make any attempt in this&#160;book to provide a formal definition of what may be used for each of these entities.&#160;Instead, the following sections provide intuitive descriptions and examples of the&#160;different kinds of tasks, performance measures and experiences that can be used&#160;to construct machine learning algorithms.</span></p><h5><a id="bookmark2"></a><span class="font64" style="font-weight:bold;">5.1.1 &#160;&#160;&#160;The Task, </span><span class="font64">T</span></h5>
<p><span class="font64">Machine learning allows us to tackle tasks that are too difficult to solve with fixed programs written and designed by human beings. From a scientific and&#160;philosophical point of view, machine learning is interesting because developing our&#160;understanding of machine learning entails developing our understanding of the&#160;principles that underlie intelligence.</span></p>
<p><span class="font64">In this relatively formal definition of the word “task,” the process of learning itself is not the task. Learning is our means of attaining the ability to perform the&#160;task. For example, if we want a robot to be able to walk, then walking is the task.&#160;We could program the robot to learn to walk, or we could attempt to directly write&#160;a program that specifies how to walk manually.</span></p>
<p><span class="font64">Machine learning tasks are usually described in terms of how the machine learning system should process an </span><span class="font64" style="font-weight:bold;font-style:italic;">example.</span><span class="font64"> An example is a collection of </span><span class="font64" style="font-weight:bold;font-style:italic;">features&#160;</span><span class="font64">that have been quantitatively measured from some object or event that we want&#160;the machine learning system to process. We typically represent an example as a&#160;vector x E R<sup>n</sup> where each entry </span><span class="font64" style="font-weight:bold;font-style:italic;">x<sub>i</sub></span><span class="font64"> of the vector is another feature. For example,&#160;the features of an image are usually the values of the pixels in the image.</span></p>
<p><span class="font64">Many kinds of tasks can be solved with machine learning. Some of the most common machine learning tasks include the following:</span></p>
<p><span class="font64">• &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">Classification:</span><span class="font64"> In this type of task, the computer program is asked to specify&#160;which of k categories some input belongs to. To solve this task, the learning&#160;algorithm is usually asked to produce a function f : R<sup>n</sup> —^ {1,..., k}. When&#160;y = f (x), the model assigns an input described by vector x to a category&#160;identified by numeric code y. There are other variants of the classification&#160;task, for example, where f outputs a probability distribution over classes.&#160;An example of a classification task is object recognition, where the input&#160;is an image (usually described as a set of pixel brightness values), and the&#160;output is a numeric code identifying the object in the image. For example,&#160;the Willow Garage PR2 robot is able to act as a waiter that can recognize&#160;different kinds of drinks and deliver them to people on command (Good-fellow </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2010). Modern object recognition is best accomplished with&#160;deep learning (Krizhevsky </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2012; Ioffe and Szegedy, 2015). Object&#160;recognition is the same basic technology that allows computers to recognize&#160;faces (Taigman </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2014), which can be used to automatically tag people&#160;in photo collections and allow computers to interact more naturally with&#160;their users.</span></p>
<p><span class="font64">• &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">Classification with missing inputs:</span><span class="font64"> Classification becomes more challenging if&#160;the computer program is not guaranteed that every measurement in its input&#160;vector will always be provided. In order to solve the classification task, the&#160;learning algorithm only has to define a </span><span class="font64" style="font-weight:bold;font-style:italic;">single</span><span class="font64"> function mapping from a vector&#160;input to a categorical output. When some of the inputs may be missing,&#160;rather than providing a single classification function, the learning algorithm&#160;must learn a </span><span class="font64" style="font-weight:bold;font-style:italic;">set</span><span class="font64"> of functions. Each function corresponds to classifying x with&#160;a different subset of its inputs missing. This kind of situation arises frequently&#160;in medical diagnosis, because many kinds of medical tests are expensive or&#160;invasive. One way to efficiently define such a large set of functions is to learn&#160;a probability distribution over all of the relevant variables, then solve the&#160;classification task by marginalizing out the missing variables. With </span><span class="font64" style="font-weight:bold;font-style:italic;">n</span><span class="font64"> input&#160;variables, we can now obtain all </span><span class="font64" style="font-weight:bold;font-style:italic;">2<sup>n</sup></span><span class="font64"> different classification functions needed&#160;for each possible set of missing inputs, but we only need to learn a single&#160;function describing the joint probability distribution. See Goodfellow </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.&#160;</span><span class="font64">(2013b) for an example of a deep probabilistic model applied to such a task&#160;in this way. Many of the other tasks described in this section can also be&#160;generalized to work with missing inputs; classification with missing inputs is&#160;just one example of what machine learning can do.</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">• &#160;&#160;&#160;Regression:</span><span class="font64"> In this type of task, the computer program is asked to predict a&#160;numerical value given some input. To solve this task, the learning algorithm&#160;is asked to output a function f : R<sup>n</sup> ^ R. This type of task is similar to&#160;classification, except that the format of output is different. An example of&#160;a regression task is the prediction of the expected claim amount that an&#160;insured person will make (used to set insurance premiums), or the prediction&#160;of future prices of securities. These kinds of predictions are also used for&#160;algorithmic trading.</span></p>
<p><span class="font64">• &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">Transcription:</span><span class="font64"> In this type of task, the machine learning system is asked to&#160;observe a relatively unstructured representation of some kind of data and&#160;transcribe it into discrete, textual form. For example, in optical character&#160;recognition, the computer program is shown a photograph containing an&#160;image of text and is asked to return this text in the form of a sequence&#160;of characters (e.g., in ASCII or Unicode format). Google Street View uses&#160;deep learning to process address numbers in this way (Goodfellow </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,&#160;</span><span class="font64">2014d). Another example is speech recognition, where the computer program&#160;is provided an audio waveform and emits a sequence of characters or word&#160;ID codes describing the words that were spoken in the audio recording. Deep&#160;learning is a crucial component of modern speech recognition systems used&#160;at major companies including Microsoft, IBM and Google (Hinton </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,&#160;</span><span class="font64">2012b).</span></p>
<p><span class="font64">• &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">Machine translation:</span><span class="font64"> In a machine translation task, the input already consists&#160;of a sequence of symbols in some language, and the computer program must&#160;convert this into a sequence of symbols in another language. This is commonly&#160;applied to natural languages, such as to translate from English to French.&#160;Deep learning has recently begun to have an important impact on this kind&#160;of task (Sutskever </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2014; Bahdanau </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2015).</span></p>
<p><span class="font64">• &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">Structured output:</span><span class="font64"> Structured output tasks involve any task where the output&#160;is a vector (or other data structure containing multiple values) with important&#160;relationships between the different elements. This is a broad category, and&#160;subsumes the transcription and translation tasks described above, but also&#160;many other tasks. One example is parsing—mapping a natural language&#160;sentence into a tree that describes its grammatical structure and tagging nodes&#160;of the trees as being verbs, nouns, or adverbs, and so on. See Collobert (2011)&#160;for an example of deep learning applied to a parsing task. Another example&#160;is pixel-wise segmentation of images, where the computer program assigns&#160;every pixel in an image to a specific category. For example, deep learning can&#160;be used to annotate the locations of roads in aerial photographs (Mnih and&#160;Hinton, 2010). The output need not have its form mirror the structure of&#160;the input as closely as in these annotation-style tasks. For example, in image&#160;captioning, the computer program observes an image and outputs a natural&#160;language sentence describing the image (Kiros </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2014a,b; Mao </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,&#160;</span><span class="font64">2015; Vinyals </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2015b; Donahue </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2014; Karpathy and Li, 2015;&#160;Fang </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2015; Xu </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2015). These tasks are called structured output&#160;tasks because the program must output several values that are all tightly&#160;inter-related. For example, the words produced by an image captioning&#160;program must form a valid sentence.</span></p>
<p><span class="font64">• &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">Anomaly detection</span><span class="font64">: In this type of task, the computer program sifts through&#160;a set of events or objects, and flags some of them as being unusual or atypical.&#160;An example of an anomaly detection task is credit card fraud detection. By&#160;modeling your purchasing habits, a credit card company can detect misuse&#160;of your cards. If a thief steals your credit card or credit card information,&#160;the thief’s purchases will often come from a different probability distribution&#160;over purchase types than your own. The credit card company can prevent&#160;fraud by placing a hold on an account as soon as that card has been used&#160;for an uncharacteristic purchase. See Chandola </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2009) for a survey of&#160;anomaly detection methods.</span></p>
<p><span class="font64">• &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">Synthesis and sampling:</span><span class="font64"> In this type of task, the machine learning algorithm&#160;is asked to generate new examples that are similar to those in the training&#160;data. Synthesis and sampling via machine learning can be useful for media&#160;applications where it can be expensive or boring for an artist to generate large&#160;volumes of content by hand. For example, video games can automatically&#160;generate textures for large objects or landscapes, rather than requiring an&#160;artist to manually label each pixel (Luo </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2013). In some cases, we&#160;want the sampling or synthesis procedure to generate some specific kind of&#160;output given the input. For example, in a speech synthesis task, we provide a&#160;written sentence and ask the program to emit an audio waveform containing&#160;a spoken version of that sentence. This is a kind of structured output task,&#160;but with the added qualification that there is no single correct output for&#160;each input, and we explicitly desire a large amount of variation in the output,&#160;in order for the output to seem more natural and realistic.</span></p>
<p><span class="font64">• &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">Imputation of missing values:</span><span class="font64"> In this type of task, the machine learning&#160;algorithm is given a new example x G R<sup>n</sup>, but with some entries </span><span class="font64" style="font-weight:bold;font-style:italic;">xi</span><span class="font64"> of </span><span class="font64" style="font-weight:bold;font-style:italic;">x&#160;</span><span class="font64">missing. The algorithm must provide a prediction of the values of the missing&#160;entries.</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">• &#160;&#160;&#160;Denoising</span><span class="font64">: In this type of task, the machine learning algorithm is given in&#160;input a </span><span class="font64" style="font-weight:bold;font-style:italic;">corrupted example x E</span><span class="font64"> R<sup>n</sup> obtained by an unknown corruption process&#160;from a </span><span class="font64" style="font-weight:bold;font-style:italic;">clean example x E</span><span class="font64"> R<sup>n</sup>. The learner must predict the clean example&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">x</span><span class="font64"> from its corrupted version </span><span class="font64" style="font-weight:bold;font-style:italic;">x</span><span class="font64">, or more generally predict the conditional&#160;probability distribution p(x | x).</span></p>
<p><span class="font64">• &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">Density estimation</span><span class="font64"> or </span><span class="font64" style="font-weight:bold;font-style:italic;">probability mass function estimation:</span><span class="font64"> In the density&#160;estimation problem, the machine learning algorithm is asked to learn a&#160;function p<sub>mo</sub>d</span><span class="font18"><sub>e</sub>1</span><span class="font64"> : R<sup>n</sup> ^ R, where Pm<sub>0</sub>d</span><span class="font18"><sub>e</sub>1</span><span class="font64"> (x) can be interpreted as a probability&#160;density function (if x is continuous) or a probability mass function (if x is&#160;discrete) on the space that the examples were drawn from. To do such a task&#160;well (we will specify exactly what that means when we discuss performance&#160;measures </span><span class="font64" style="font-weight:bold;font-style:italic;">P</span><span class="font64">), the algorithm needs to learn the structure of the data it&#160;has seen. It must know where examples cluster tightly and where they&#160;are unlikely to occur. Most of the tasks described above require that the&#160;learning algorithm has at least implicitly captured the structure of the&#160;probability distribution. Density estimation allows us to explicitly capture&#160;that distribution. In principle, we can then perform computations on that&#160;distribution in order to solve the other tasks as well. For example, if we&#160;have performed density estimation to obtain a probability distribution p(x),&#160;we can use that distribution to solve the missing value imputation task. If&#160;a value </span><span class="font64" style="font-weight:bold;font-style:italic;">x<sub>i</sub></span><span class="font64"> is missing and all of the other values, denoted x<sub>-i</sub>, are given,&#160;then we know the distribution over it is given by p(x<sub>i</sub> | x <sub>-i</sub>). In practice,&#160;density estimation does not always allow us to solve all of these related tasks,&#160;because in many cases the required operations on px) are computationally&#160;intractable.</span></p>
<p><span class="font64">Of course, many other tasks and types of tasks are possible. The types of tasks we list here are intended only to provide examples of what machine learning can&#160;do, not to define a rigid taxonomy of tasks.</span></p><h5><a id="bookmark3"></a><span class="font64" style="font-weight:bold;">5.1.2 The Performance Measure, </span><span class="font64" style="font-weight:bold;font-style:italic;">P</span></h5>
<p><span class="font64">In order to evaluate the abilities of a machine learning algorithm, we must design a quantitative measure of its performance. Usually this performance measure P is&#160;specific to the task T being carried out by the system.</span></p>
<p><span class="font64">For tasks such as classification, classification with missing inputs, and transcription, we often measure the </span><span class="font64" style="font-weight:bold;font-style:italic;">accuracy</span><span class="font64"> of the model. Accuracy is just the proportion of examples for which the model produces the correct output. We can also obtain&#160;equivalent information by measuring the </span><span class="font64" style="font-weight:bold;font-style:italic;">error rate</span><span class="font64">, the proportion of examples for&#160;which the model produces an incorrect output. We often refer to the error rate as&#160;the expected 0-1 loss. The 0-1 loss on a particular example is 0 if it is correctly&#160;classified and 1 if it is not. For tasks such as density estimation, it does not make&#160;sense to measure accuracy, error rate, or any other kind of 0-1 loss. Instead, we&#160;must use a different performance metric that gives the model a continuous-valued&#160;score for each example. The most common approach is to report the average&#160;log-probability the model assigns to some examples.</span></p>
<p><span class="font64">Usually we are interested in how well the machine learning algorithm performs on data that it has not seen before, since this determines how well it will work when&#160;deployed in the real world. We therefore evaluate these performance measures&#160;using a </span><span class="font64" style="font-weight:bold;font-style:italic;">test set</span><span class="font64"> of data that is separate from the data used for training the machine&#160;learning system.</span></p>
<p><span class="font64">The choice of performance measure may seem straightforward and objective, but it is often difficult to choose a performance measure that corresponds well to&#160;the desired behavior of the system.</span></p>
<p><span class="font64">In some cases, this is because it is difficult to decide what should be measured. For example, when performing a transcription task, should we measure the accuracy&#160;of the system at transcribing entire sequences, or should we use a more fine-grained&#160;performance measure that gives partial credit for getting some elements of the&#160;sequence correct? When performing a regression task, should we penalize the&#160;system more if it frequently makes medium-sized mistakes or if it rarely makes&#160;very large mistakes? These kinds of design choices depend on the application.</span></p>
<p><span class="font64">In other cases, we know what quantity we would ideally like to measure, but measuring it is impractical. For example, this arises frequently in the context of&#160;density estimation. Many of the best probabilistic models represent probability&#160;distributions only implicitly. Computing the actual probability value assigned to&#160;a specific point in space in many such models is intractable. In these cases, one&#160;must design an alternative criterion that still corresponds to the design objectives,&#160;or design a good approximation to the desired criterion.</span></p><h5><a id="bookmark4"></a><span class="font64" style="font-weight:bold;">5.1.3 The Experience, </span><span class="font64">E</span></h5>
<p><span class="font64">Machine learning algorithms can be broadly categorized as </span><span class="font64" style="font-weight:bold;font-style:italic;">unsupervised</span><span class="font64"> or </span><span class="font64" style="font-weight:bold;font-style:italic;">supervised</span><span class="font64"> by what kind of experience they are allowed to have during the learning process.</span></p>
<p><span class="font64">Most of the learning algorithms in this book can be understood as being allowed to experience an entire </span><span class="font64" style="font-weight:bold;font-style:italic;">dataset.</span><span class="font64"> A dataset is a collection of many examples, as&#160;defined in Sec. 5.1.1. Sometimes we will also call examples </span><span class="font64" style="font-weight:bold;font-style:italic;">data points.</span></p>
<p><span class="font64">One of the oldest datasets studied by statisticians and machine learning researchers is the Iris dataset (Fisher, 1936). It is a collection of measurements of different parts of 150 iris plants. Each individual plant corresponds to one example.&#160;The features within each example are the measurements of each of the parts of the&#160;plant: the sepal length, sepal width, petal length and petal width. The dataset&#160;also records which species each plant belonged to. Three different species are&#160;represented in the dataset.</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">Unsupervised learning algorithms</span><span class="font64"> experience a dataset containing many features, then learn useful properties of the structure of this dataset. In the context of deep&#160;learning, we usually want to learn the entire probability distribution that generated&#160;a dataset, whether explicitly as in density estimation or implicitly for tasks like&#160;synthesis or denoising. Some other unsupervised learning algorithms perform other&#160;roles, like clustering, which consists of dividing the dataset into clusters of similar&#160;examples.</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">Supervised learning algorithms</span><span class="font64"> experience a dataset containing features, but each example is also associated with a </span><span class="font64" style="font-weight:bold;font-style:italic;">label</span><span class="font64"> or </span><span class="font64" style="font-weight:bold;font-style:italic;">target.</span><span class="font64"> For example, the Iris dataset&#160;is annotated with the species of each iris plant. A supervised learning algorithm&#160;can study the Iris dataset and learn to classify iris plants into three different species&#160;based on their measurements.</span></p>
<p><span class="font64">Roughly speaking, unsupervised learning involves observing several examples of a random vector x, and attempting to implicitly or explicitly learn the probability distribution p(x), or some interesting properties of that distribution, while&#160;supervised learning involves observing several examples of a random vector x and&#160;an associated value or vector y, and learning to predict y from x, usually by&#160;estimating </span><span class="font64" style="font-weight:bold;font-style:italic;">p</span><span class="font64"> (y | x). The term </span><span class="font64" style="font-weight:bold;font-style:italic;">supervised learning</span><span class="font64"> originates from the view of&#160;the target y being provided by an instructor or teacher who shows the machine&#160;learning system what to do. In unsupervised learning, there is no instructor or&#160;teacher, and the algorithm must learn to make sense of the data without this guide.</span></p>
<p><span class="font64">Unsupervised learning and supervised learning are not formally defined terms. The lines between them are often blurred. Many machine learning technologies can&#160;be used to perform both tasks. For example, the chain rule of probability states&#160;that for a vector x E R<sup>n</sup>, the joint distribution can be decomposed as</span></p>
<p><span class="font63">n</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">p<sup>(x)</sup></span><span class="font64"><sup> =</sup></span><span class="font21">n</span><span class="font64">p(xi I x </span><span class="font18">1</span><span class="font64">,...,xi-</span><span class="font18">1</span><span class="font64">). &#160;&#160;&#160;(5.1)</span></p>
<p><span class="font64" style="font-style:italic;">i=1</span></p>
<p><span class="font64">This decomposition means that we can solve the ostensibly unsupervised problem of modeling p(x) by splitting it into </span><span class="font64" style="font-weight:bold;font-style:italic;">n</span><span class="font64"> supervised learning problems. Alternatively, we&#160;can solve the supervised learning problem of learning </span><span class="font64" style="font-style:italic;">p (y</span><span class="font64"> | x) by using traditional&#160;unsupervised learning technologies to learn the joint distribution p(x, y) and&#160;inferring</span></p>
<p><span class="font64">p(y|x) = &#160;&#160;&#160;.&#160;&#160;&#160;&#160;(5.2)</span></p>
<p><span class="font64" style="font-style:italic;">y p<sup>(x,</sup>y )</span></p>
<p><span class="font64">Though unsupervised learning and supervised learning are not completely formal or distinct concepts, they do help to roughly categorize some of the things we do with&#160;machine learning algorithms. Traditionally, people refer to regression, classification&#160;and structured output problems as supervised learning. Density estimation in&#160;support of other tasks is usually considered unsupervised learning.</span></p>
<p><span class="font64">Other variants of the learning paradigm are possible. For example, in semi-supervised learning, some examples include a supervision target but others do not. In multi-instance learning, an entire collection of examples is labeled as&#160;containing or not containing an example of a class, but the individual members&#160;of the collection are not labeled. For a recent example of multi-instance learning&#160;with deep models, see Kotzias </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2015).</span></p>
<p><span class="font64">Some machine learning algorithms do not just experience a fixed dataset. For example, </span><span class="font64" style="font-weight:bold;font-style:italic;">reinforcement learning</span><span class="font64"> algorithms interact with an environment, so there&#160;is a feedback loop between the learning system and its experiences. Such algorithms&#160;are beyond the scope of this book. Please see Sutton and Barto (1998) or Bertsekas&#160;and Tsitsiklis (1996) for information about reinforcement learning, and Mnih </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span></p>
<p><span class="font64">(2013) for the deep learning approach to reinforcement learning.</span></p>
<p><span class="font64">Most machine learning algorithms simply experience a dataset. A dataset can be described in many ways. In all cases, a dataset is a collection of examples,&#160;which are in turn collections of features.</span></p>
<p><span class="font64">One common way of describing a dataset is with a </span><span class="font64" style="font-weight:bold;font-style:italic;">design matrix.</span><span class="font64"> A design matrix is a matrix containing a different example in each row. Each column of the&#160;matrix corresponds to a different feature. For instance, the Iris dataset contains&#160;150 examples with four features for each example. This means we can represent&#160;the dataset with a design matrix </span><span class="font64" style="font-weight:bold;">X </span><span class="font64" style="font-weight:bold;font-style:italic;">e</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">R<sup>150x4</sup>, where X<sub>i;1</sub> is the sepal length of&#160;plant </span><span class="font64" style="font-weight:bold;font-style:italic;">i, Xi</span><span class="font18">,2</span><span class="font64"> is the sepal width of plant i, etc. We will describe most of the learning&#160;algorithms in this book in terms of how they operate on design matrix datasets.</span></p>
<p><span class="font64">Of course, to describe a dataset as a design matrix, it must be possible to describe each example as a vector, and each of these vectors must be the same size.&#160;This is not always possible. For example, if you have a collection of photographs&#160;with different widths and heights, then different photographs will contain different&#160;numbers of pixels, so not all of the photographs may be described with the same&#160;length of vector. Sec. 9.7 and Chapter 10 describe how to handle different types&#160;of such heterogeneous data. In cases like these, rather than describing the dataset&#160;as a matrix with m rows, we will describe it as a set containing m elements:&#160;{</span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(1)</sup>, </span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(2)</sup>,..., </span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(m)</sup>}. This notation does not imply that any two example vectors&#160;</span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(i)</sup> and </span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>j)</sup> have the same size.</span></p>
<p><span class="font64">In the case of supervised learning, the example contains a label or target as well as a collection of features. For example, if we want to use a learning algorithm&#160;to perform object recognition from photographs, we need to specify which object&#160;appears in each of the photos. We might do this with a numeric code, with 0&#160;signifying a person, 1 signifying a car, 2 signifying a cat, etc. Often when working&#160;with a dataset containing a design matrix of feature observations </span><span class="font64" style="font-weight:bold;">X</span><span class="font64">, we also&#160;provide a vector of labels </span><span class="font64" style="font-weight:bold;">y</span><span class="font64">, with y providing the label for example i.</span></p>
<p><span class="font64">Of course, sometimes the label may be more than just a single number. For example, if we want to train a speech recognition system to transcribe entire&#160;sentences, then the label for each example sentence is a sequence of words.</span></p>
<p><span class="font64">Just as there is no formal definition of supervised and unsupervised learning, there is no rigid taxonomy of datasets or experiences. The structures described here&#160;cover most cases, but it is always possible to design new ones for new applications.</span></p><h5><a id="bookmark5"></a><span class="font64" style="font-weight:bold;">5.1.4 Example: Linear Regression</span></h5>
<p><span class="font64">Our definition of a machine learning algorithm as an algorithm that is capable of improving a computer program’s performance at some task via experience is&#160;somewhat abstract. To make this more concrete, we present an example of a simple&#160;machine learning algorithm: </span><span class="font64" style="font-weight:bold;font-style:italic;">linear regression.</span><span class="font64"> We will return to this example&#160;repeatedly as we introduce more machine learning concepts that help to understand&#160;its behavior.</span></p>
<p><span class="font64">As the name implies, linear regression solves a regression problem. In other words, the goal is to build a system that can take a vector </span><span class="font64" style="font-weight:bold;">x </span><span class="font64">E R<sup>n</sup> as input and&#160;predict the value of a scalar </span><span class="font64" style="font-weight:bold;font-style:italic;">y E</span><span class="font64"> R as its output. In the case of linear regression,&#160;the output is a linear function of the input. Let </span><span class="font64" style="font-weight:bold;font-style:italic;">y</span><span class="font64"> be the value that our model&#160;predicts y should take on. We define the output to be</span></p>
<p><span class="font64">y </span><span class="font64" style="font-weight:bold;">= w <sup>T</sup>x &#160;&#160;&#160;</span><span class="font64">(5.3)</span></p>
<p><span class="font64">where </span><span class="font64" style="font-weight:bold;">w </span><span class="font64" style="font-weight:bold;font-style:italic;">E</span><span class="font64"> R<sup>n</sup> is a vector of </span><span class="font64" style="font-weight:bold;font-style:italic;">parameters.</span></p>
<p><span class="font64">Parameters are values that control the behavior of the system. In this case, </span><span class="font64" style="font-weight:bold;font-style:italic;">wi</span><span class="font64"> is the coefficient that we multiply by feature </span><span class="font64" style="font-weight:bold;font-style:italic;">x</span><span class="font64"><sub>i</sub> before summing up the contributions&#160;from all the features. We can think of </span><span class="font64" style="font-weight:bold;">w </span><span class="font64">as a set of </span><span class="font64" style="font-weight:bold;font-style:italic;">weights</span><span class="font64"> that determine how&#160;each feature affects the prediction. If a feature x<sub>i</sub> receives a positive weight w<sub>i</sub>,&#160;then increasing the value of that feature increases the value of our prediction y.&#160;If a feature receives a negative weight, then increasing the value of that feature&#160;decreases the value of our prediction. If a feature’s weight is large in magnitude,&#160;then it has a large effect on the prediction. If a feature’s weight is zero, it has no&#160;effect on the prediction.</span></p>
<p><span class="font64">We thus have a definition of our task T: to predict y from x by outputting y = w<sup>T</sup>x. Next we need a definition of our performance measure, P.</span></p>
<p><span class="font64">Suppose that we have a design matrix of m example inputs that we will not use for training, only for evaluating how well the model performs. We also have&#160;a vector of regression targets providing the correct value of y for each of these&#160;examples. Because this dataset will only be used for evaluation, we call it the </span><span class="font64" style="font-weight:bold;font-style:italic;">test&#160;set.</span><span class="font64"> We refer to the design matrix of inputs as X<sup>(test)</sup> and the vector of regression&#160;targets as y<sup>(test)</sup>.</span></p>
<p><span class="font64">One way of measuring the performance of the model is to compute the </span><span class="font64" style="font-weight:bold;font-style:italic;">mean squared error</span><span class="font64"> of the model on the test set. If y<sup>(test)</sup> gives the predictions of the&#160;model on the test set, then the mean squared error is given by</span></p>
<p><span class="font64">1</span></p>
<p><span class="font64">MSEtest = - V(y<sup>(test)</sup> - y<sup>(test)</sup>)i<sup>2</sup>. &#160;&#160;&#160;(5.4)</span></p>
<p><span class="font64">m</span></p>
<p><span class="font64" style="font-style:italic;">i</span></p>
<p><span class="font64">Intuitively, one can see that this error measure decreases to 0 when y<sup>(test)</sup> = y<sup>(test)</sup>. We can also see that</span></p><h5><a id="bookmark6"></a><span class="font64"><sub>1</sub></span></h5>
<p><span class="font64">MSEtest =- ||y<sup>(test)</sup> - y<sup>(test)</sup> |2, &#160;&#160;&#160;(5.5)</span></p>
<p><span class="font64">m</span></p>
<p><span class="font64">so the error increases whenever the Euclidean distance between the predictions and the targets increases.</span></p>
<p><span class="font64">To make a machine learning algorithm, we need to design an algorithm that will improve the weights w in a way that reduces MSE<sub>test</sub> when the algorithm&#160;is allowed to gain experience by observing a training set (X<sup>(tra1n)</sup>, y<sup>(tra1n)</sup>). One&#160;intuitive way of doing this (which we will justify later, in Sec. 5.5.1) is just to&#160;minimize the mean squared error on the training set, MSEt<sub>ra</sub>!<sub>n</sub>.</span></p>
<p><span class="font64">To minimize MSE<sub>tra</sub>!<sub>n</sub>, we can simply solve for where its gradient is 0:</span></p>
<p><span class="font64">m</span></p><div><div><img src="main-38.jpg" alt=""/>
<p><span class="font64">Figure 5.1: A linear regression problem, with a training set consisting of ten data points, each containing one feature. Because there is only one feature, the weight vector w&#160;contains only a single parameter to learn, </span><span class="font64" style="font-style:italic;">w</span><span class="font64"><sub>1</sub>. </span><span class="font64" style="font-style:italic;">(Left)</span><span class="font64"> Observe that linear regression learns&#160;to set w<sub>1</sub> such that the line </span><span class="font64" style="font-style:italic;">y _ w<sub>1</sub> x</span><span class="font64"> comes as close as possible to passing through all the&#160;training points. </span><span class="font64" style="font-style:italic;">(Right)</span><span class="font64"> The plotted point indicates the value ofw <sub>1</sub> found by the normal&#160;equations, which we can see minimizes the mean squared error on the training set.</span></p></div></div><div>
<p><span class="font64">^ V<sub>w</sub> (</span><span class="font64" style="font-weight:bold;">X </span><span class="font64"><sup>(train)</sup></span><span class="font64" style="font-weight:bold;">w </span><span class="font64">- </span><span class="font64" style="font-weight:bold;">y</span><span class="font64"><sup>(train)</sup> &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;">X</span><span class="font64"><sup>(train)</sup> </span><span class="font64" style="font-weight:bold;">w </span><span class="font64">- </span><span class="font64" style="font-weight:bold;">y</span><span class="font64"><sup>(train)</sup>) = 0</span></p>
<p><span class="font64">/</span><span class="font64" style="font-weight:bold;"><sub>w</sub></span><span class="font63">T</span><span class="font64" style="font-weight:bold;"><sub>X</sub></span><span class="font64"><sup>(</sup>t<sup>rain</sup>)T</span><span class="font64" style="font-weight:bold;"><sub>X</sub></span><span class="font64">(train)</span><span class="font64" style="font-weight:bold;"><sub>w</sub> </span><span class="font64">_ <sub>2</sub></span><span class="font64" style="font-weight:bold;"><sub>w</sub></span><span class="font63"><sup>T</sup></span><span class="font64" style="font-weight:bold;"><sub>X</sub></span><span class="font64"><sup>(</sup>tram)T</span><span class="font64" style="font-weight:bold;"><sub>y</sub></span><span class="font64"><sup>(</sup>tram) + </span><span class="font64" style="font-weight:bold;"><sub>y</sub></span><span class="font64"><sup>(</sup>tr<sup>ai</sup>n)T</span><span class="font64" style="font-weight:bold;"><sub>y</sub></span><span class="font64"><sup>(</sup>tr<sup>ain</sup>A</span></p></div><div>
<p><span class="font64">2</span><span class="font64" style="font-weight:bold;">x<sup>(train)T</sup>X<sup>(train)</sup><sub>w</sub> _ 2X<sup>(train)T</sup></span><span class="font64" style="font-weight:bold;font-style:italic;">y<sup>(train)</sup> _</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">0</span></p></div><div>
<p><span class="font64">-1</span></p></div><div>
<p><span class="font64" style="font-weight:bold;">w</span></p></div><div>
<p><span class="font63">_ / X(train)TX(train) j &#160;&#160;&#160;X(train)Ty(train)</span></p></div><div>
<p><span class="font64">(5.9)</span></p>
<p><span class="font64" style="font-weight:bold;">= 0</span></p>
<p><span class="font64">(5.10)</span></p>
<p><span class="font64">(5.11)</span></p>
<p><span class="font64">(5.12)</span></p></div>
<p><span class="font64">The system of equations whose solution is given by Eq. 5.12 is known as the </span><span class="font64" style="font-weight:bold;font-style:italic;">normal equations.</span><span class="font64"> Evaluating Eq. 5.12 constitutes a simple learning algorithm.&#160;For an example of the linear regression learning algorithm in action, see Fig. 5.1.</span></p>
<p><span class="font64">It is worth noting that the term </span><span class="font64" style="font-weight:bold;font-style:italic;">linear regression</span><span class="font64"> is often used to refer to a slightly more sophisticated model with one additional parameter—an intercept&#160;term b. In this model</span></p>
<p><span class="font64">y _ w<sup>T</sup>x + b &#160;&#160;&#160;(5.13)</span></p>
<p><span class="font64">so the mapping from parameters to predictions is still a linear function but the mapping from features to predictions is now an affine function. This extension to&#160;affine functions means that the plot of the model’s predictions still looks like a&#160;line, but it need not pass through the origin. Instead of adding the bias parameter&#160;b, one can continue to use the model with only weights but augment x with an&#160;extra entry that is always set to 1. The weight corresponding to the extra 1 entry&#160;plays the role of the bias parameter. We will frequently use the term “linear” when&#160;referring to affine functions throughout this book.</span></p>
<p><span class="font64">The intercept term b is often called the </span><span class="font64" style="font-weight:bold;font-style:italic;">bias</span><span class="font64"> parameter of the affine transformation. This terminology derives from the point of view that the output of the transformation is biased toward being b in the absence of any input. This term&#160;is different from the idea of a statistical bias, in which a statistical estimation&#160;algorithm’s expected estimate of a quantity is not equal to the true quantity.</span></p>
<p><span class="font64">Linear regression is of course an extremely simple and limited learning algorithm, but it provides an example of how a learning algorithm can work. In the subsequent&#160;sections we will describe some of the basic principles underlying learning algorithm&#160;design and demonstrate how these principles can be used to build more complicated&#160;learning algorithms.</span></p><h4><a id="bookmark7"></a><span class="font65" style="font-weight:bold;">5.2 Capacity, Overfitting and Underfitting</span></h4>
<p><span class="font64">The central challenge in machine learning is that we must perform well on </span><span class="font64" style="font-weight:bold;">new, previously unseen </span><span class="font64">inputs—not just those on which our model was trained. The&#160;ability to perform well on previously unobserved inputs is called </span><span class="font64" style="font-weight:bold;font-style:italic;">generalization.</span></p>
<p><span class="font64">Typically, when training a machine learning model, we have access to a training set, we can compute some error measure on the training set called the </span><span class="font64" style="font-weight:bold;font-style:italic;">training&#160;error,</span><span class="font64"> and we reduce this training error. So far, what we have described is simply&#160;an optimization problem. What separates machine learning from optimization is&#160;that we want the </span><span class="font64" style="font-weight:bold;font-style:italic;">generalization error,</span><span class="font64"> also called the </span><span class="font64" style="font-weight:bold;font-style:italic;">test error,</span><span class="font64"> to be low as well.&#160;The generalization error is defined as the expected value of the error on a new&#160;input. Here the expectation is taken across different possible inputs, drawn from&#160;the distribution of inputs we expect the system to encounter in practice.</span></p>
<p><span class="font64">We typically estimate the generalization error of a machine learning model by measuring its performance on a </span><span class="font64" style="font-weight:bold;font-style:italic;">test set</span><span class="font64"> of examples that were collected separately&#160;from the training set.</span></p>
<p><span class="font64">In our linear regression example, we trained the model by minimizing the training error,</span></p>
<p><span class="font64" style="font-weight:bold;">1</span></p><div>
<p><span class="font64">m<sup>(train)</sup></span></p>
<p><span class="font64">but we actually care about the test error,</span></p></div><div>
<p><span class="font64" style="font-weight:bold;">X </span><span class="font64">(tram) </span><span class="font64" style="font-weight:bold;font-style:italic;"><sub>w —</sub></span><span class="font64" style="font-weight:bold;"> y</span><span class="font64">(tram) || 2,</span></p></div>
<p><span class="font64">(5.14)</span></p><div>
<p><span class="font64" style="text-decoration:underline;">1</span></p></div>
<p><span class="font64">|X<sup>(test)</sup><sub>w</sub> - y<sup>(test)</sup> ||2</span></p>
<p><span class="font64">How can we affect performance on the test set when we get to observe only the training set? The field of </span><span class="font64" style="font-weight:bold;font-style:italic;">statistical learning theory</span><span class="font64"> provides some answers. If the&#160;training and the test set are collected arbitrarily, there is indeed little we can do.&#160;If we are allowed to make some assumptions about how the training and test set&#160;are collected, then we can make some progress.</span></p>
<p><span class="font64">The train and test data are generated by a probability distribution over datasets called the </span><span class="font64" style="font-weight:bold;font-style:italic;">data generating process.</span><span class="font64"> We typically make a set of assumptions known&#160;collectively as the </span><span class="font64" style="font-weight:bold;font-style:italic;">i.i.d. assumptions</span><span class="font64"> These assumptions are that the examples&#160;in each dataset are </span><span class="font64" style="font-weight:bold;font-style:italic;">independent</span><span class="font64"> from each other, and that the train set and test&#160;set are </span><span class="font64" style="font-weight:bold;font-style:italic;">identically distributed,</span><span class="font64"> drawn from the same probability distribution as&#160;each other. This assumption allows us to describe the data generating process&#160;with a probability distribution over a single example. The same distribution is&#160;then used to generate every train example and every test example. We call that&#160;shared underlying distribution the </span><span class="font64" style="font-weight:bold;font-style:italic;">data generating distribution,</span><span class="font64"> denoted pd<sub>ata</sub>. This&#160;probabilistic framework and the i.i.d. assumptions allow us to mathematically&#160;study the relationship between training error and test error.</span></p>
<p><span class="font64">One immediate connection we can observe between the training and test error is that the expected training error of a randomly selected model is equal to the&#160;expected test error of that model. Suppose we have a probability distribution&#160;p(</span><span class="font64" style="font-weight:bold;font-style:italic;">x,y)</span><span class="font64"> and we sample from it repeatedly to generate the train set and the test&#160;set. For some fixed value w, the expected training set error is exactly the same as&#160;the expected test set error, because both expectations are formed using the same&#160;dataset sampling process. The only difference between the two conditions is the&#160;name we assign to the dataset we sample.</span></p>
<p><span class="font64">Of course, when we use a machine learning algorithm, we do not fix the parameters ahead of time, then sample both datasets. We sample the training set,&#160;then use it to choose the parameters to reduce training set error, then sample the&#160;test set. Under this process, the expected test error is greater than or equal to&#160;the expected value of training error. The factors determining how well a machine&#160;learning algorithm will perform are its ability to:</span></p>
<p><span class="font64">1. &#160;&#160;&#160;Make the training error small.</span></p>
<p><span class="font64">2. &#160;&#160;&#160;Make the gap between training and test error small.</span></p>
<p><span class="font64">These two factors correspond to the two central challenges in machine learning: </span><span class="font64" style="font-weight:bold;font-style:italic;">underfitting</span><span class="font64"> and </span><span class="font64" style="font-weight:bold;font-style:italic;">overfitting.</span><span class="font64"> Underfitting occurs when the model is not able to&#160;obtain a sufficiently low error value on the training set. Overfitting occurs when&#160;the gap between the training error and test error is too large.</span></p>
<p><span class="font64">We can control whether a model is more likely to overfit or underfit by altering its </span><span class="font64" style="font-weight:bold;font-style:italic;">capacity.</span><span class="font64"> Informally, a model’s capacity is its ability to fit a wide variety of&#160;functions. Models with low capacity may struggle to fit the training set. Models&#160;with high capacity can overfit by memorizing properties of the training set that do&#160;not serve them well on the test set.</span></p>
<p><span class="font64">One way to control the capacity of a learning algorithm is by choosing its </span><span class="font64" style="font-weight:bold;font-style:italic;">hypothesis space</span><span class="font64">, the set of functions that the learning algorithm is allowed to&#160;select as being the solution. For example, the linear regression algorithm has the&#160;set of all linear functions of its input as its hypothesis space. We can generalize&#160;linear regression to include polynomials, rather than just linear functions, in its&#160;hypothesis space. Doing so increases the model’s capacity.</span></p>
<p><span class="font64">A polynomial of degree one gives us the linear regression model with which we are already familiar, with prediction</span></p>
<p><span class="font64">y = b + wx. &#160;&#160;&#160;(5.15)</span></p>
<p><span class="font64">By introducing </span><span class="font31" style="font-style:italic;">XX</span><span class="font65"> as another feature provided to the linear regression model, we can learn a model that is quadratic as a function of x:</span></p>
<p><span class="font31" style="font-style:italic;">y </span><span class="font64" style="font-weight:bold;font-style:italic;">= </span><span class="font31" style="font-style:italic;">b</span><span class="font65"> + w<sub>1</sub>x + w<sub>2</sub></span><span class="font31" style="font-style:italic;">XX .</span><span class="font65"> &#160;&#160;&#160;(5.16)</span></p>
<p><span class="font64">Though this model implements a quadratic function of its </span><span class="font64" style="font-weight:bold;">input</span><span class="font64">, the output is still a linear function of the </span><span class="font64" style="font-weight:bold;">parameters</span><span class="font64">, so we can still use the normal equations&#160;to train the model in closed form. We can continue to add more powers of x as&#160;additional features, for example to obtain a polynomial of degree 9:</span></p>
<p><span class="font64">9</span></p>
<p><span class="font31" style="font-style:italic;">y </span><span class="font64" style="font-weight:bold;font-style:italic;">= </span><span class="font31" style="font-style:italic;">b </span><span class="font64" style="font-weight:bold;font-style:italic;">+ &#160;&#160;&#160;</span><span class="font31" style="font-style:italic;">w</span><span class="font64" style="font-weight:bold;font-style:italic;">i</span><span class="font31" style="font-style:italic;">X.</span><span class="font65">&#160;&#160;&#160;&#160;(5.17)</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">i=1</span></p>
<p><span class="font64">Machine learning algorithms will generally perform best when their capacity is appropriate in regard to the true complexity of the task they need to perform&#160;and the amount of training data they are provided with. Models with insufficient&#160;capacity are unable to solve complex tasks. Models with high capacity can solve&#160;complex tasks, but when their capacity is higher than needed to solve the present&#160;task they may overfit.</span></p>
<p><span class="font64">Fig. 5.2 shows this principle in action. We compare a linear, quadratic and degree-9 predictor attempting to fit a problem where the true underlying function&#160;is quadratic. The linear function is unable to capture the curvature in the true underlying problem, so it underfits. The degree-9 predictor is capable of representing&#160;the correct function, but it is also capable of representing infinitely many other&#160;functions that pass exactly through the training points, because we have more&#160;parameters than training examples. We have little chance of choosing a solution&#160;that generalizes well when so many wildly different solutions exist. In this example,&#160;the quadratic model is perfectly matched to the true structure of the task so it&#160;generalizes well to new data.</span></p>
<table border="1">
<tr><td>
<p><span class="font64">Underfitting</span></p></td><td>
<p><span class="font64">A</span></p></td><td colspan="2">
<p><span class="font64">ppropriate capacity</span></p></td><td colspan="2">
<p><span class="font64">Overfitting</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font64">•</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font64">&gt;</span></p></td><td>
<p></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font10"><sup>x</sup>0</span></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font10"><sup>x</sup> 0</span></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font10"><sup>x</sup>0</span></p></td></tr>
</table>
<p><span class="font64">Figure 5.2: We fit three models to this example training set. The training data was generated synthetically, by randomly sampling x values and choosing y deterministically&#160;by evaluating a quadratic function. </span><span class="font64" style="font-style:italic;">(Left)</span><span class="font64"> A linear function fit to the data suffers from&#160;underfitting—it cannot capture the curvature that is present in the data. (</span><span class="font64" style="font-style:italic;">Center</span><span class="font64">) A&#160;quadratic function fit to the data generalizes well to unseen points. It does not suffer from&#160;a significant amount of overfitting or underfitting. </span><span class="font64" style="font-style:italic;">(Right)</span><span class="font64"> A polynomial of degree 9 fit to&#160;the data suffers from overfitting. Here we used the Moore-Penrose pseudoinverse to solve&#160;the underdetermined normal equations. The solution passes through all of the training&#160;points exactly, but we have not been lucky enough for it to extract the correct structure.&#160;It now has a deep valley in between two training points that does not appear in the true&#160;underlying function. It also increases sharply on the left side of the data, while the true&#160;function decreases in this area. <a id="footnote1"></a><sup><a href="#bookmark8">1</a></sup><sup></sup></span></p>
<p><span class="font64">of the optimization algorithm, mean that the learning algorithm’s </span><span class="font31" style="font-style:italic;">effective capacity </span><span class="font64">may be less than the representational capacity of the model family.</span></p>
<p><span class="font64">Our modern ideas about improving the generalization of machine learning models are refinements of thought dating back to philosophers at least as early&#160;as Ptolemy. Many early scholars invoke a principle of parsimony that is now&#160;most widely known as </span><span class="font31" style="font-style:italic;">Occam’s razor</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">(c. 1287-1347). This principle states that&#160;among competing hypotheses that explain known observations equally well, one&#160;should choose the “simplest” one. This idea was formalized and made more precise&#160;in the 20th century by the founders of statistical learning theory (Vapnik and&#160;Chervonenkis, 1971; Vapnik, 1982; Blumer </span><span class="font31" style="font-style:italic;">et al.</span><span class="font64" style="font-weight:bold;font-style:italic;">,</span><span class="font64"> 1989; Vapnik, 1995).</span></p>
<p><span class="font64">Statistical learning theory provides various means of quantifying model capacity. Among these, the most well-known is the </span><span class="font31" style="font-style:italic;">Vapnik-Chervonenkis dimension</span><span class="font64" style="font-weight:bold;font-style:italic;">,</span><span class="font64"> or VC&#160;dimension. The VC dimension measures the capacity of a binary classifier. The&#160;VC dimension is defined as being the largest possible value of </span><span class="font31" style="font-style:italic;">m</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">for which there&#160;exists a training set of m different x points that the classifier can label arbitrarily.</span></p>
<p><span class="font64">Quantifying the capacity of the model allows statistical learning theory to make quantitative predictions. The most important results in statistical learning&#160;theory show that the discrepancy between training error and generalization error&#160;is bounded from above by a quantity that grows as the model capacity grows but&#160;shrinks as the number of training examples increases (Vapnik and Chervonenkis,&#160;1971; Vapnik, 1982; Blumer </span><span class="font31" style="font-style:italic;">et al.</span><span class="font64" style="font-weight:bold;font-style:italic;">,</span><span class="font64"> 1989; Vapnik, 1995). These bounds provide&#160;intellectual justification that machine learning algorithms can work, but they are&#160;rarely used in practice when working with deep learning algorithms. This is in&#160;part because the bounds are often quite loose and in part because it can be quite&#160;difficult to determine the capacity of deep learning algorithms. The problem of&#160;determining the capacity of a deep learning model is especially difficult because the&#160;effective capacity is limited by the capabilities of the optimization algorithm, and&#160;we have little theoretical understanding of the very general non-convex optimization&#160;problems involved in deep learning.</span></p>
<p><span class="font64">We must remember that while simpler functions are more likely to generalize (to have a small gap between training and test error) we must still choose a&#160;sufficiently complex hypothesis to achieve low training error. Typically, training&#160;error decreases until it asymptotes to the minimum possible error value as model&#160;capacity increases (assuming the error measure has a minimum value). Typically,&#160;generalization error has a U-shaped curve as a function of model capacity. This is&#160;illustrated in Fig. 5.3.</span></p>
<p><span class="font64">To reach the most extreme case of arbitrarily high capacity, we introduce the concept of </span><span class="font31" style="font-style:italic;">non-parametric</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">models. So far, we have seen only parametric</span></p><div><img src="main-39.jpg" alt=""/>
<p><span class="font64">Figure 5.3: Typical relationship between capacity and error. Training and test error behave differently. At the left end of the graph, training error and generalization error&#160;are both high. This is the </span><span class="font64" style="font-style:italic;">underfitting regime.</span><span class="font64"> As we increase capacity, training error&#160;decreases, but the gap between training and generalization error increases. Eventually,&#160;the size of this gap outweighs the decrease in training error, and we enter the </span><span class="font64" style="font-style:italic;">overfitting&#160;regime,</span><span class="font64"> where capacity is too large, above the </span><span class="font64" style="font-style:italic;">optimal capacity.</span></p></div>
<p><span class="font64">models, such as linear regression. Parametric models learn a function described by a parameter vector whose size is finite and fixed before any data is observed.&#160;Non-parametric models have no such limitation.</span></p>
<p><span class="font64">Sometimes, non-parametric models are just theoretical abstractions (such as an algorithm that searches over all possible probability distributions) that cannot&#160;be implemented in practice. However, we can also design practical non-parametric&#160;models by making their complexity a function of the training set size. One example&#160;of such an algorithm is </span><span class="font64" style="font-weight:bold;font-style:italic;">nearest neighbor regression.</span><span class="font64"> Unlike linear regression, which&#160;has a fixed-length vector of weights, the nearest neighbor regression model simply&#160;stores the X and y from the training set. When asked to classify a test point x,&#160;the model looks up the nearest entry in the training set and returns the associated&#160;regression target. In other words, y = y where </span><span class="font64" style="font-weight:bold;font-style:italic;">i =</span><span class="font64"> argmin ||Xi,<sub>:</sub> — x|||. The&#160;algorithm can also be generalized to distance metrics other than the L<sup>2</sup> norm, such&#160;as learned distance metrics (Goldberger </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2005). If the algorithm is allowed&#160;to break ties by averaging the y values for all X</span><span class="font64" style="font-weight:bold;font-style:italic;">i,<sub>:</sub></span><span class="font64"> that are tied for nearest, then&#160;this algorithm is able to achieve the minimum possible training error (which might&#160;be greater than zero, if two identical inputs are associated with different outputs)&#160;on any regression dataset.</span></p>
<p><span class="font64">Finally, we can also create a non-parametric learning algorithm by wrapping a parametric learning algorithm inside another algorithm that increases the number&#160;of parameters as needed. For example, we could imagine an outer loop of learning&#160;that changes the degree of the polynomial learned by linear regression on top of a&#160;polynomial expansion of the input.</span></p>
<p><span class="font64">The ideal model is an oracle that simply knows the true probability distribution that generates the data. Even such a model will still incur some error on many&#160;problems, because there may still be some noise in the distribution. In the case&#160;of supervised learning, the mapping from x to y may be inherently stochastic,&#160;or y may be a deterministic function that involves other variables besides those&#160;included in x. The error incurred by an oracle making predictions from the true&#160;distribution p(x,y) is called the </span><span class="font64" style="font-weight:bold;font-style:italic;">Bayes error.</span></p>
<p><span class="font64">Training and generalization error vary as the size of the training set varies. Expected generalization error can never increase as the number of training examples&#160;increases. For non-parametric models, more data yields better generalization until&#160;the best possible error is achieved. Any fixed parametric model with less than&#160;optimal capacity will asymptote to an error value that exceeds the Bayes error. See&#160;Fig. 5.4 for an illustration. Note that it is possible for the model to have optimal&#160;capacity and yet still have a large gap between training and generalization error.&#160;In this situation, we may be able to reduce this gap by gathering more training&#160;examples.</span></p><h5><a id="bookmark9"></a><span class="font64" style="font-weight:bold;">5.2.1 The No Free Lunch Theorem</span></h5>
<p><span class="font64">Learning theory claims that a machine learning algorithm can generalize well from a finite training set of examples. This seems to contradict some basic principles of&#160;logic. Inductive reasoning, or inferring general rules from a limited set of examples,&#160;is not logically valid. To logically infer a rule describing every member of a set,&#160;one must have information about every member of that set.</span></p>
<p><span class="font64">In part, machine learning avoids this problem by offering only probabilistic rules, rather than the entirely certain rules used in purely logical reasoning. Machine&#160;learning promises to find rules that are </span><span class="font64" style="font-weight:bold;font-style:italic;">probably</span><span class="font64"> correct about </span><span class="font64" style="font-weight:bold;font-style:italic;">most</span><span class="font64"> members of&#160;the set they concern.</span></p>
<p><span class="font64">Unfortunately, even this does not resolve the entire problem. The </span><span class="font64" style="font-weight:bold;font-style:italic;">no free lunch theorem</span><span class="font64"> for machine learning (Wolpert, 1996) states that, averaged over all possible&#160;data generating distributions, every classification algorithm has the same error&#160;rate when classifying previously unobserved points. In other words, in some sense,&#160;no machine learning algorithm is universally any better than any other. The most&#160;sophisticated algorithm we can conceive of has the same average performance (over&#160;all possible tasks) as merely predicting that every point belongs to the same class.</span></p><div><div>
<p><span class="font64">H</span></p>
<p dir="rtl"><span class="font50">נע</span></p><img src="main-40.png" alt=""/>
<p><span class="font64">H</span></p></div></div><div>
<p><span class="font63">3.5</span></p>
<p><span class="font63">3.0</span></p>
<p><span class="font63">2.5</span></p>
<p><span class="font63">2.0</span></p>
<p><span class="font63">1.5 1.0&#160;0.5&#160;0.0</span></p></div><div><div>
<p dir="rtl"><span class="font17" style="font-weight:bold;font-style:italic;">rr.</span><span class="font62" style="font-variant:small-caps;"> j.i.i.iji . ו . . . .1 . .1.1 jjui . . . j . .1. ! .i.ijn . . . j . .1. </span><span class="font17" style="font-weight:bold;font-style:italic;">1</span><span class="font62"> .1.1.11 r</span></p><img src="main-41.jpg" alt=""/>
<p><span class="font63">10<sup>0</sup> &#160;&#160;&#160;10<sup>1</sup>&#160;&#160;&#160;&#160;10<sup>2</sup> 10<sup>3</sup> 10&#160;&#160;&#160;&#160;10<sup>5</sup></span></p></div></div><div>
<p><span class="font64"><sup>_</sup> ■ Bayes error</span></p>
<p><span class="font64">Train (quadratic)</span></p>
<p><span class="font64">Test (quadratic)</span></p>
<p><span class="font64">H Test (optimal capacity) Train (optimal capacity)</span></p></div><div><div>
<p><span class="font63">Number of training examples</span></p><img src="main-42.jpg" alt=""/></div></div>
<p><span class="font64">Figure 5.4: The effect of the training dataset size on the train and test error, as well as on the optimal model capacity. We constructed a synthetic regression problem based on&#160;adding moderate amount of noise to a degree 5 polynomial, generated a single test set,&#160;and then generated several different sizes of training set. For each size, we generated 40&#160;different training sets in order to plot error bars showing 95% confidence intervals. </span><span class="font64" style="font-style:italic;">(Top)&#160;</span><span class="font64">The MSE on the train and test set for two different models: a quadratic model, and a&#160;model with degree chosen to minimize the test error. Both are fit in closed form. For&#160;the quadratic model, the training error increases as the size of the training set increases.&#160;This is because larger datasets are harder to fit. Simultaneously, the test error decreases,&#160;because fewer incorrect hypotheses are consistent with the training data. The quadratic&#160;model does not have enough capacity to solve the task, so its test error asymptotes to&#160;a high value. The test error at optimal capacity asymptotes to the Bayes error. The&#160;training error can fall below the Bayes error, due to the ability of the training algorithm&#160;to memorize specific instances of the training set. As the training size increases to infinity,&#160;the training error of any fixed-capacity model (here, the quadratic model) must rise to at&#160;least the Bayes error. </span><span class="font64" style="font-style:italic;">(Bottom)</span><span class="font64"> As the training set size increases, the optimal capacity&#160;(shown here as the degree of the optimal polynomial regressor) increases. The optimal&#160;capacity plateaus after reaching sufficient complexity to solve the task.</span></p>
<p><span class="font64">Fortunately, these results hold only when we average over </span><span class="font64" style="font-weight:bold;font-style:italic;">all</span><span class="font64"> possible data generating distributions. If we make assumptions about the kinds of probability&#160;distributions we encounter in real-world applications, then we can design learning&#160;algorithms that perform well on these distributions.</span></p>
<p><span class="font64">This means that the goal of machine learning research is not to seek a universal learning algorithm or the absolute best learning algorithm. Instead, our goal is to&#160;understand what kinds of distributions are relevant to the “real world” that an AI&#160;agent experiences, and what kinds of machine learning algorithms perform well on&#160;data drawn from the kinds of data generating distributions we care about.</span></p><h5><a id="bookmark10"></a><span class="font64" style="font-weight:bold;">5.2.2 Regularization</span></h5>
<p><span class="font64">The no free lunch theorem implies that we must design our machine learning algorithms to perform well on a specific task. We do so by building a set of&#160;preferences into the learning algorithm. When these preferences are aligned with&#160;the learning problems we ask the algorithm to solve, it performs better.</span></p>
<p><span class="font64">So far, the only method of modifying a learning algorithm we have discussed is to increase or decrease the model’s capacity by adding or removing functions from&#160;the hypothesis space of solutions the learning algorithm is able to choose. We gave&#160;the specific example of increasing or decreasing the degree of a polynomial for a&#160;regression problem. The view we have described so far is oversimplified.</span></p>
<p><span class="font64">The behavior of our algorithm is strongly affected not just by how large we make the set of functions allowed in its hypothesis space, but by the specific identity&#160;of those functions. The learning algorithm we have studied so far, linear regression,&#160;has a hypothesis space consisting of the set of linear functions of its input. These&#160;linear functions can be very useful for problems where the relationship between&#160;inputs and outputs truly is close to linear. They are less useful for problems&#160;that behave in a very nonlinear fashion. For example, linear regression would&#160;not perform very well if we tried to use it to predict sin(x) from x. We can thus&#160;control the performance of our algorithms by choosing what kind of functions we&#160;allow them to draw solutions from, as well as by controlling the amount of these&#160;functions.</span></p>
<p><span class="font64">We can also give a learning algorithm a preference for one solution in its hypothesis space to another. This means that both functions are eligible, but one&#160;is preferred. The unpreferred solution be chosen only if it fits the training data&#160;significantly better than the preferred solution.</span></p>
<p><span class="font64">For example, we can modify the training criterion for linear regression to include </span><span class="font64" style="font-weight:bold;font-style:italic;">weight decay.</span><span class="font64"> To perform linear regression with weight decay, we minimize&#160;a sum comprising both the mean squared error on the training and a criterion&#160;J(w) that expresses a preference for the weights to have smaller squared L<sup>2</sup> norm.&#160;Specifically,</span></p>
<p><span class="font64">J (w) = MSE<sub>train</sub> + Aw<sup>T</sup>w, &#160;&#160;&#160;(5.18)</span></p>
<p><span class="font64">where A is a value chosen ahead of time that controls the strength of our preference for smaller weights. When A = 0, we impose no preference, and larger A forces the&#160;weights to become smaller. Minimizing J(w) results in a choice of weights that&#160;make a tradeoff between fitting the training data and being small. This gives us&#160;solutions that have a smaller slope, or put weight on fewer of the features. As an&#160;example of how we can control a model’s tendency to overfit or underfit via weight&#160;decay, we can train a high-degree polynomial regression model with different values&#160;of A. See Fig. 5.5 for the results.</span></p>
<p><span class="font64">Underfitting Appropriate weight decay Overfitting (Excessive A)&#160;&#160;&#160;&#160;(Medium A)&#160;&#160;&#160;&#160;(A ^0)</span></p><div><img src="main-43.jpg" alt=""/>
<p><span class="font64">Figure 5.5: We fit a high-degree polynomial regression model to our example training set from Fig. 5.2. The true function is quadratic, but here we use only models with degree 9.&#160;We vary the amount of weight decay to prevent these high-degree models from overfitting.&#160;</span><span class="font64" style="font-style:italic;">(Left)</span><span class="font64"> With very large A, we can force the model to learn a function with no slope at&#160;all. This underfits because it can only represent a constant function. </span><span class="font64" style="font-style:italic;">(Center)</span><span class="font64"> With a&#160;medium value of A, the learning algorithm recovers a curve with the right general shape.&#160;Even though the model is capable of representing functions with much more complicated&#160;shape, weight decay has encouraged it to use a simpler function described by smaller&#160;coefficients. </span><span class="font64" style="font-style:italic;">(Right)</span><span class="font64"> With weight decay approaching zero (i.e., using the Moore-Penrose&#160;pseudoinverse to solve the underdetermined problem with minimal regularization), the&#160;degree-9 polynomial overfits significantly, as we saw in Fig. 5.2.</span></p></div>
<p><span class="font64">More generally, we can regularize a model that learns a function f (x; </span><span class="font64" style="font-weight:bold;font-style:italic;">6)</span><span class="font64"> by adding a penalty called a </span><span class="font64" style="font-weight:bold;font-style:italic;">regularizer</span><span class="font64"> to the cost function. In the case of weight&#160;decay, the regularizer is 0(w) = w<sup>T</sup>w. In Chapter 7, we will see that many other&#160;regularizers are possible.</span></p>
<p><span class="font64">Expressing preferences for one function over another is a more general way of controlling a model’s capacity than including or excluding members from the&#160;hypothesis space. We can think of excluding a function from a hypothesis space as&#160;expressing an infinitely strong preference against that function.</span></p>
<p><span class="font64">In our weight decay example, we expressed our preference for linear functions defined with smaller weights explicitly, via an extra term in the criterion we&#160;minimize. There are many other ways of expressing preferences for different&#160;solutions, both implicitly and explicitly. Together, these different approaches are&#160;known as </span><span class="font64" style="font-weight:bold;font-style:italic;">regularization.</span><span class="font64"> </span><span class="font64" style="font-weight:bold;">Regularization is any modification we make to&#160;a learning algorithm that is intended to reduce its generalization error&#160;but not its training error. </span><span class="font64">Regularization is one of the central concerns of the&#160;field of machine learning, rivaled in its importance only by optimization.</span></p>
<p><span class="font64">The no free lunch theorem has made it clear that there is no best machine learning algorithm, and, in particular, no best form of regularization. Instead&#160;we must choose a form of regularization that is well-suited to the particular task&#160;we want to solve. The philosophy of deep learning in general and this book in&#160;particular is that a very wide range of tasks (such as all of the intellectual tasks&#160;that people can do) may all be solved effectively using very general-purpose forms&#160;of regularization.</span></p>
<p><a id="bookmark8"><sup><a href="#footnote1">1</a></sup></a></p>
<p><span class="font64"> far we have only described changing a model’s capacity by changing the number of input features it has (and simultaneously adding new parameters&#160;associated with those features). There are in fact many ways of changing a model’s&#160;capacity. Capacity is not determined only by the choice of model. The model&#160;specifies which family of functions the learning algorithm can choose from when&#160;varying the parameters in order to reduce a training objective. This is called the&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">representational capacity</span><span class="font64"> of the model. In many cases, finding the best function&#160;within this family is a very difficult optimization problem. In practice, the learning&#160;algorithm does not actually find the best function, but merely one that significantly&#160;reduces the training error. These additional limitations, such as the imperfection</span></p>
</body>
</html>