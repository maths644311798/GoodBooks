<?xml version="1.0" encoding="UTF-8"?>

<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta name="charset" content="UTF-8"/><title></title><link rel="stylesheet" href="main.css" type="text/css"/>
</head>
<body><a id="caption1"></a><h2><a id="bookmark0"></a><span class="font67" style="font-weight:bold;">Contents</span></h2>
<p><span class="font64">18.2 &#160;&#160;&#160;Stochastic Maximum Likelihood and Contrastive Divergence . . . 609</span></p>
<ul><li><a href="main-1.xhtml">Website</a></li><li><a href="main-2.xhtml">Acknowledgments</a></li><li><a href="main-3.xhtml">Notation</a></li><li><a href="main-4.xhtml">Chapter 1. Introduction</a></li><li><a href="main-5.xhtml">Chapter 2. Linear Algebra</a></li><li><a href="main-6.xhtml">Chapter 3. Probability and Information&#160;Theory</a></li><li><a href="main-7.xhtml">Chapter 4. Numerical Computation</a></li><li><a href="main-8.xhtml">Chapter 5. Machine Learning Basics</a></li><ul><li><a href="main-9.xhtml">5.3&#160;Hyperparameters and Validation Sets</a></li><ul><li><a href="main-10.xhtml">5.7.3&#160;Other Simple Supervised Learning Algorithms</a></li></ul></ul><li><a href="main-11.xhtml">Chapter 6. Deep Feedforward Networks</a></li><ul><li><a href="main-12.xhtml">6.3&#160;Hidden Units</a></li><ul><li><a href="main-13.xhtml">6.5.6&#160;General Back-Propagation</a></li></ul></ul><li><a href="main-14.xhtml">Chapter 7. Regularization for Deep Learning</a></li><ul><li><a href="main-15.xhtml">7.9&#160;Parameter Tying and Parameter Sharing</a></li></ul><li><a href="main-16.xhtml">Chapter 8. Optimization for Training Deep&#160;Models</a></li><ul><li><a href="main-17.xhtml">8.3.3&#160;Nesterov Momentum</a></li><li><a href="main-18.xhtml">8.7.2&#160;Coordinate Descent</a></li></ul><li><a href="main-19.xhtml">Chapter 9. Convolutional Networks</a></li><ul><li><a href="main-20.xhtml">9.7&#160;Data Types</a></li></ul><li><a href="main-21.xhtml">Chapter 10. Sequence Modeling: Recurrent&#160;and Recursive Nets</a></li><ul><li><a href="main-22.xhtml">10.5&#160;Deep Recurrent Networks</a></li></ul><li><a href="main-23.xhtml">Chapter 11. Practical Methodology</a></li><li><a href="main-24.xhtml">Chapter 12. Applications</a></li><ul><li><a href="main-25.xhtml">12.4.3&#160;High-Dimensional Outputs</a></li></ul><li><a href="main-26.xhtml">Chapter 13. Linear Factor Models</a></li><li><a href="main-27.xhtml">Chapter 14. Autoencoders</a></li><li><a href="main-28.xhtml">Chapter 15. Representation Learning</a></li><ul><li><a href="main-29.xhtml">15.5&#160;Exponential Gains from Depth</a></li></ul><li><a href="main-30.xhtml">Chapter 16. Structured Probabilistic Models&#160;for Deep Learning</a></li><ul><li><a href="main-31.xhtml">16.5&#160;Learning about Dependencies</a></li></ul><li><a href="main-32.xhtml">Chapter 17. Monte Carlo Methods</a></li><li><a href="main-33.xhtml">Chapter 18. Confronting the Partition&#160;Function</a></li><ul><li><a href="main-34.xhtml">18.7.1&#160;Annealed Importance Sampling</a></li></ul><li><a href="main-35.xhtml">Chapter 19. Approximate Inference</a></li><ul><li><a href="main-36.xhtml">19.5&#160;Learned Approximate Inference</a></li></ul><li><a href="main-37.xhtml">Chapter 20. Deep Generative Models</a></li><ul><li><a href="main-38.xhtml">20.5&#160;Boltzmann Machines for Real-Valued Data</a></li><li><a href="main-39.xhtml">20.10&#160;Directed Generative Nets</a></li><li><a href="main-40.xhtml">20.11&#160;Drawing Samples from Autoencoders</a></li></ul><li><a href="main-41.xhtml">0ס000000000נ;&amp;</a></li><li><a href="main-42.xhtml">Bibliography</a></li><ul><li><a href="main-43.xhtml">Le Roux, N. and Bengio, Y. (2008). Representationa</a></li></ul><li><a href="main-44.xhtml">Index</a></li></ul>
</body>
</html>