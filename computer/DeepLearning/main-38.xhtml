<?xml version="1.0" encoding="UTF-8"?>

<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta name="charset" content="UTF-8"/><title></title><link rel="stylesheet" href="main.css" type="text/css"/>
</head>
<body><h4><a id="bookmark0"></a><span class="font65" style="font-weight:bold;">20.5 Boltzmann Machines for Real-Valued Data</span></h4>
<p><span class="font64">While Boltzmann machines were originally developed for use with binary data, many applications such as image and audio modeling seem to require the ability&#160;to represent probability distributions over real values. In some cases, it is possible&#160;to treat real-valued data in the interval [0, 1] as representing the expectation of a&#160;binary variable. For example, Hinton (2000) treats grayscale images in the training&#160;set as defining [0,1] probability values. Each pixel defines the probability of a&#160;binary value being 1, and the binary pixels are all sampled independently from&#160;each other. This is a common procedure for evaluating binary models on grayscale&#160;image datasets. However, it is not a particularly theoretically satisfying approach,&#160;and binary images sampled independently in this way have a noisy appearance. In&#160;this section, we present Boltzmann machines that define a probability density over&#160;real-valued data.</span></p><h5><a id="bookmark1"></a><span class="font64" style="font-weight:bold;">20.5.1 Gaussian-Bernoulli RBMs</span></h5>
<p><span class="font64">Restricted Boltzmann machines may be developed for many exponential family conditional distributions (Welling </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2005). Of these, the most common is the&#160;RBM with binary hidden units and real-valued visible units, with the conditional&#160;distribution over the visible units being a Gaussian distribution whose mean is a&#160;function of the hidden units.</span></p>
<p><span class="font64">There are many ways of parametrizing Gaussian-Bernoulli RBMs. First, we may choose whether to use a covariance matrix or a precision matrix for the Gaussian&#160;distribution. Here we present the precision formulation. The modification to obtain&#160;the covariance formulation is straightforward. We wish to have the conditional&#160;distribution</span></p>
<p><span class="font64">p(</span><span class="font64" style="font-weight:bold;">v </span><span class="font64" style="font-weight:bold;font-style:italic;">|</span><span class="font64"> </span><span class="font64" style="font-weight:bold;">h</span><span class="font64">) </span><span class="font64" style="font-weight:bold;font-style:italic;">= N</span><span class="font64">(</span><span class="font64" style="font-weight:bold;">v</span><span class="font64">; </span><span class="font64" style="font-weight:bold;">Wh</span><span class="font64">, </span><span class="font64" style="font-weight:bold;font-style:italic;">0<sup>-1</sup>).</span><span class="font64"> &#160;&#160;&#160;(20.38)</span></p>
<p><span class="font64">We can find the terms we need to add to the energy function by expanding the unnormalized log conditional distribution:</span></p>
<p><span class="font64">log</span><span class="font64" style="font-weight:bold;font-style:italic;">N(v</span><span class="font64">; </span><span class="font64" style="font-weight:bold;">Wh</span><span class="font64">, </span><span class="font64" style="font-weight:bold;">0<sup>-</sup></span><span class="font64"><sup>1</sup>) = - - (</span><span class="font64" style="font-weight:bold;">v </span><span class="font64">- </span><span class="font64" style="font-weight:bold;">Wh</span><span class="font64">)</span><span class="font64" style="font-weight:bold;"><sup>T</sup> 0 </span><span class="font64">(</span><span class="font64" style="font-weight:bold;">v </span><span class="font64">- </span><span class="font64" style="font-weight:bold;">Wh</span><span class="font64">) + </span><span class="font64" style="font-weight:bold;font-style:italic;">f</span><span class="font64"> (</span><span class="font64" style="font-weight:bold;">0</span><span class="font64">). &#160;&#160;&#160;(20.39)</span></p>
<p><span class="font64">—</span></p>
<p><span class="font64">Here f encapsulates all the terms that are a function only of the parameters and not the random variables in the model. We can discard f because its only&#160;role is to normalize the distribution, and the partition function of whatever energy&#160;function we choose will carry out that role.</span></p>
<p><span class="font64">If we include all of the terms (with their sign flipped) involving </span><span class="font64" style="font-weight:bold;">v </span><span class="font64">from Eq. 20.39 in our energy function and do not add any other terms involving </span><span class="font64" style="font-weight:bold;">v</span><span class="font64">, then our energy&#160;function will represent the desired conditional p(</span><span class="font64" style="font-weight:bold;">v </span><span class="font64">| </span><span class="font64" style="font-weight:bold;">h</span><span class="font64">).</span></p>
<p><span class="font64">We have some freedom regarding the other conditional distribution, p(</span><span class="font64" style="font-weight:bold;">h </span><span class="font64">| </span><span class="font64" style="font-weight:bold;">v</span><span class="font64">). Note that Eq. 20.39 contains a term</span></p>
<p><span class="font64">1</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;"><sub>—</sub>h<sup>T</sup>W</span><span class="font64"> </span><span class="font64" style="font-weight:bold;">0Wh</span><span class="font64">. &#160;&#160;&#160;(20.40)</span></p>
<p><span class="font64">—</span></p>
<p><span class="font64">This term cannot be included in its entirety because it includes h</span><span class="font64" style="font-weight:bold;font-style:italic;">hj</span><span class="font64"> terms. These correspond to edges between the hidden units. If we included these terms, we&#160;would have a linear factor model instead of a restricted Boltzmann machine.&#160;When designing our Boltzmann machine, we simply omit these h</span><span class="font64" style="font-weight:bold;font-style:italic;">ih j</span><span class="font64"> cross terms.&#160;Omitting them does not change the conditional p(</span><span class="font64" style="font-weight:bold;">v </span><span class="font64">| </span><span class="font64" style="font-weight:bold;">h</span><span class="font64">) so Eq. 20.39 is still&#160;respected. However, we still have a choice about whether to include the terms&#160;involving only a single hi. If we assume a diagonal precision matrix, we find that&#160;for each hidden unit h<sub>i</sub> we have a term</span></p>
<p><span class="font64"><sub>1</sub></span></p>
<p><span class="font64">- hi£ </span><span class="font64" style="font-weight:bold;font-style:italic;">j W</span><span class="font64">j. &#160;&#160;&#160;(20.41)</span></p>
<p><span class="font64"><sup>j</sup></span></p>
<p><span class="font64">In the above, we used the fact that h<sup>j</sup> = </span><span class="font64" style="font-weight:bold;font-style:italic;">hi</span><span class="font64"> because </span><span class="font64" style="font-weight:bold;font-style:italic;">hi</span><span class="font64"> £ {0,1}. If we include this term (with its sign flipped) in the energy function, then it will naturally bias </span><span class="font64" style="font-weight:bold;font-style:italic;">hi&#160;</span><span class="font64">to be turned off when the weights for that unit are large and connected to visible&#160;units with high precision. The choice of whether or not to include this bias term&#160;does not affect the family of distributions the model can represent (assuming that&#160;we include bias parameters for the hidden units) but it does affect the learning&#160;dynamics of the model. Including the term may help the hidden unit activations&#160;remain reasonable even when the weights rapidly increase in magnitude.</span></p>
<p><span class="font64">One way to define the energy function on a Gaussian-Bernoulli RBM is thus</span></p>
<p><span class="font64" style="font-weight:bold;">1</span></p>
<p><span class="font64">E</span><span class="font64" style="font-weight:bold;">(v</span><span class="font64">, </span><span class="font64" style="font-weight:bold;">h) = 2 </span><span class="font64" style="font-weight:bold;font-style:italic;">v</span><span class="font64"><sup>T</sup></span><span class="font64" style="font-weight:bold;">(3 </span><span class="font64">© </span><span class="font64" style="font-weight:bold;">v) </span><span class="font64">- </span><span class="font64" style="font-weight:bold;">(v </span><span class="font64">© </span><span class="font64" style="font-weight:bold;">3)</span><span class="font64"><sup>T</sup> </span><span class="font64" style="font-weight:bold;font-style:italic;">Wh - b<sup>T</sup>h</span><span class="font64"> &#160;&#160;&#160;(20.42)</span></p>
<p><span class="font64" style="font-weight:bold;">2</span></p>
<p><span class="font64">but we may also add extra terms or parametrize the energy in terms of the variance rather than precision if we choose.</span></p>
<p><span class="font64">In this derivation, we have not included a bias term on the visible units, but one could easily be added. One final source of variability in the parametrization of a&#160;Gaussian-Bernoulli RBM is the choice of how to treat the precision matrix. It may&#160;either be fixed to a constant (perhaps estimated based on the marginal precision&#160;of the data) or learned. It may also be a scalar times the identity matrix, or it&#160;may be a diagonal matrix. Typically we do not allow the precision matrix to be&#160;non-diagonal in this context, because some operations would then require inverting&#160;the matrix. In the sections ahead, we will see that other forms of Boltzmann&#160;machines permit modeling the covariance structure, using various techniques to&#160;avoid inverting the precision matrix.</span></p><h5><a id="bookmark2"></a><span class="font64" style="font-weight:bold;">20.5.2 Undirected Models of Conditional Covariance</span></h5>
<p><span class="font64">While the Gaussian RBM has been the canonical energy model for real-valued data, Ranzato </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2010a) argue that the Gaussian RBM inductive bias is not&#160;well suited to the statistical variations present in some types of real-valued data,&#160;especially natural images. The problem is that much of the information content&#160;present in natural images is embedded in the covariance between pixels rather than&#160;in the raw pixel values. In other words, it is the relationships between pixels and&#160;not their absolute values where most of the useful information in images resides.&#160;Since the Gaussian RBM only models the conditional mean of the input given the&#160;hidden units, it cannot capture conditional covariance information. In response&#160;to these criticisms, alternative models have been proposed that attempt to better&#160;account for the covariance of real-valued data. These models include the mean and&#160;covariance RBM (mcRBM<a id="footnote1"></a><sup><a href="#bookmark3">1</a></sup><sup></sup>), the mean-product of f-distribution (mPoT) model&#160;and the spike and slab RBM (ssRBM).</span></p>
<p><span class="font64" style="font-weight:bold;">Mean and Covariance RBM </span><span class="font64">The mcRBM uses its hidden units to independently encode the conditional mean and covariance of all observed units. The mcRBM hidden layer is divided into two groups of units: mean units and covariance&#160;units. The group that models the conditional mean is simply a Gaussian RBM.&#160;The other half is a covariance RBM (Ranzato </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2010a), also called a cRBM,&#160;whose components model the conditional covariance structure, as described below.</span></p>
<p><span class="font64">Specifically, with binary mean units </span><span class="font64" style="font-weight:bold;">h<sup>(</sup></span><span class="font64"><sup>m</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup> </span><span class="font64">and binary covariance units </span><span class="font64" style="font-weight:bold;">h<sup>(</sup></span><span class="font64"><sup>c</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup></span><span class="font64">, the mcRBM model is defined as the combination of two energy functions:</span></p>
<p><span class="font64" style="font-weight:bold;">Emc(x, h&lt;</span><span class="font64"><sup>m</sup></span><span class="font64" style="font-weight:bold;">&gt;, h&lt;</span><span class="font64"><sup>c</sup></span><span class="font64" style="font-weight:bold;">&gt;) = </span><span class="font64" style="font-weight:bold;font-style:italic;">Em(x,</span><span class="font64"> </span><span class="font64" style="font-weight:bold;">h&lt;</span><span class="font64"><sup>m</sup></span><span class="font64" style="font-weight:bold;">&gt;) + </span><span class="font64" style="font-weight:bold;font-style:italic;">Ec(x,</span><span class="font64"> &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;">),&#160;&#160;&#160;&#160;</span><span class="font64">(20.43)</span></p>
<p><span class="font64">where </span><span class="font64" style="font-weight:bold;">E<sub>m</sub> </span><span class="font64">is the standard Gaussian-Bernoulli RBM energy function:<a id="footnote2"></a><sup><a href="#bookmark4">2</a></sup><sup></sup></span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">Em(x,</span><span class="font64"> </span><span class="font64" style="font-weight:bold;">h<sup>(</sup></span><span class="font64"><sup>m</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup>) = 2</span><span class="font64" style="font-weight:bold;font-style:italic;">x<sup>T</sup>x -</span><span class="font64"> </span><span class="font64" style="font-weight:bold;">^ </span><span class="font64" style="font-weight:bold;font-style:italic;">x<sup>T</sup> W:jh</span><span class="font64">j<sup>m</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup> </span><span class="font64">- </span><span class="font64" style="font-weight:bold;">^ &#160;&#160;&#160;h</span><span class="font64">j<sup>m</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup>,&#160;&#160;&#160;&#160;</span><span class="font64">(20.44)</span></p>
<p><span class="font64" style="font-weight:bold;">2</span></p>
<p><span class="font64">and </span><span class="font64" style="font-weight:bold;">Ec </span><span class="font64">is the cRBM energy function that models the conditional covariance information:</span></p><div>
<p><span class="font64">(20.45)</span></p></div>
<p><span class="font64" style="font-weight:bold;">Ec(x, h<sup>( c)</sup>) =2 &#160;&#160;&#160;hj<sup>c)</sup> ^x<sup>T</sup>r -&#160;&#160;&#160;&#160;bj<sup>c)</sup> hj<sup>c)</sup>.</span></p>
<p><span class="font64">The parameter </span><span class="font64" style="font-weight:bold;">r<sup>(</sup></span><span class="font64"><sup>j</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup> </span><span class="font64">corresponds to the covariance weight vector associated with hj<sup>c</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup> </span><span class="font64">and </span><span class="font64" style="font-weight:bold;">b<sup>( </sup></span><span class="font64"><sup>c</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup> </span><span class="font64">is a vector of covariance offsets. The combined energy function defines&#160;a joint distribution:</span></p>
<p dir="rtl"><span class="font63" style="font-weight:bold;">ך</span></p>
<p><span class="font64">P</span><span class="font64" style="font-weight:bold;">mc</span><span class="font64">(</span><span class="font64" style="font-weight:bold;">x</span><span class="font64">, </span><span class="font64" style="font-weight:bold;">h<sup>(</sup></span><span class="font64"><sup>m</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup></span><span class="font64">, </span><span class="font64" style="font-weight:bold;">h<sup>(</sup></span><span class="font64"><sup>c</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup></span><span class="font64">) = Z exp</span><span class="font64" style="font-weight:bold;">{ </span><span class="font64">E</span><span class="font64" style="font-weight:bold;">mc</span><span class="font64">(</span><span class="font64" style="font-weight:bold;">x</span><span class="font64">, </span><span class="font64" style="font-weight:bold;">h<sup>(</sup></span><span class="font64"><sup>m</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup></span><span class="font64">, </span><span class="font64" style="font-weight:bold;">h<sup>(</sup></span><span class="font64"><sup>c</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup></span><span class="font64">) j, &#160;&#160;&#160;(20.46)</span></p>
<p><span class="font64">and a corresponding conditional distribution over the observations given </span><span class="font64" style="font-weight:bold;">h<sup>(</sup></span><span class="font64"><sup>m</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup> </span><span class="font64">and </span><span class="font64" style="font-weight:bold;">h<sup>(</sup></span><span class="font64"><sup>c</sup></span><span class="font64" style="font-weight:bold;"><sup>)</sup> </span><span class="font64">as a multivariate Gaussian distribution:</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">pmc(x</span><span class="font64"> | </span><span class="font64" style="font-weight:bold;">h</span><span class="font64">&lt;<sup>m</sup>&gt;</span><span class="font64" style="font-weight:bold;">, h</span><span class="font64">&lt;<sup>c</sup>&gt;) = N </span><span class="font64" style="font-weight:bold;">I x</span><span class="font64">; </span><span class="font64" style="font-weight:bold;font-style:italic;">cmh</span><span class="font64"> </span><span class="font64" style="font-weight:bold;">I </span><span class="font64">£ &#160;&#160;&#160;</span><span class="font64" style="font-weight:bold;">I , I .&#160;&#160;&#160;&#160;</span><span class="font64">(20.47)</span></p>
<p><span class="font64">Note that the covariance matrix </span><span class="font64" style="font-weight:bold;">C</span><span class="font64">^jh = &#160;&#160;&#160;hj<sup>c)</sup></span><span class="font64" style="font-weight:bold;">rr</span><span class="font64"><sup>(j)T</sup> + </span><span class="font64" style="font-weight:bold;">7</span><span class="font64">1 is non-diagonal</span></p>
<p><span class="font64">and that </span><span class="font64" style="font-weight:bold;">W </span><span class="font64">is the weight matrix associated with the Gaussian RBM modeling the</span></p>
<p><span class="font64">conditional means. It is difficult to train the mcRBM via contrastive divergence or persistent contrastive divergence because of its non-diagonal conditional covariance&#160;structure. CD and PCD require sampling from the joint distribution of x, h<sup>(m)</sup>, h<sup>(c)&#160;</sup>which, in a standard RBM, is accomplished by Gibbs sampling over the conditionals.&#160;However, in the mcRBM, sampling fromp<sub>mc</sub>(x | h<sup>(m)</sup>, h<sup>(c)</sup>) requires computing&#160;(C<sup>mc</sup>)<sup>-1</sup> at every iteration of learning. This can be an impractical computational&#160;burden for larger observations. Ranzato and Hinton (2010) avoid direct sampling&#160;from the conditional p<sub>mc</sub>( x | h<sup>(m)</sup>, h<sup>(c)</sup>) by sampling directly from the marginal&#160;p(x) using Hamiltonian (hybrid) Monte Carlo (Neal, 1993) on the mcRBM free&#160;energy.</span></p>
<p><span class="font64" style="font-weight:bold;">Mean-Product of Student’s </span><span class="font64">t</span><span class="font64" style="font-weight:bold;">-distributions </span><span class="font64">The mean-product of Student’s t-distribution (mPoT) model (Ranzato </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2010b) extends the PoT model (Welling&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2003a) in a manner similar to how the mcRBM extends the cRBM. This&#160;is achieved by including nonzero Gaussian means by the addition of Gaussian&#160;RBM-like hidden units. Like the mcRBM, the PoT conditional distribution over the&#160;observation is a multivariate Gaussian (with non-diagonal covariance) distribution;&#160;however, unlike the mcRBM, the complementary conditional distribution over the&#160;hidden variables is given by conditionally independent Gamma distributions. The&#160;Gamma distribution </span><span class="font64" style="font-weight:bold;font-style:italic;">G(k, 9</span><span class="font64">) is a probability distribution over positive real numbers,&#160;with mean </span><span class="font64" style="font-weight:bold;font-style:italic;">k9</span><span class="font64">. It is not necessary to have a more detailed understanding of the&#160;Gamma distribution to understand the basic ideas underlying the mPoT model.</span></p>
<p><span class="font64">The mPoT energy function is:</span></p><div>
<p><span class="font64">(20.48)</span></p></div>
<p><span class="font64">EmPoT(x, h<sup>(m)</sup> , h<sup>(c)</sup> )</span></p><div><h3><a id="bookmark5"></a><span class="font64" style="font-weight:bold;font-style:italic;">=</span><span class="font64"> </span><span class="font64" style="font-weight:bold;">E</span><span class="font64">m</span><span class="font64" style="font-weight:bold;">(x, </span><span class="font64" style="font-weight:bold;font-style:italic;">h<sup>(m)</sup>)</span><span class="font64"> </span><span class="font64" style="font-weight:bold;">+</span><span class="font64">£ </span><span class="font67" style="font-style:italic;">(hf(</span><span class="font67"> </span><span class="font64" style="font-weight:bold;">1 + 2 </span><span class="font64">(</span><span class="font64" style="font-weight:bold;">r<sup>(</sup></span><span class="font64"><sup>3</sup></span><span class="font64" style="font-weight:bold;"><sup>)T</sup>x</span><span class="font64">)^ </span><span class="font64" style="font-weight:bold;">+(1</span></h3></div><div>
<p><span class="font64"><sup>-</sup> </span><span class="font64" style="font-weight:bold;font-style:italic;">Yj</span><span class="font64"> <sup>)l0</sup>g <sup>h</sup></span></p></div><div>
<p><span class="font64">(c)</span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">3</span></p></div>
<p><span class="font64">(20.49)</span></p>
<p><span class="font64">where r<sup>(3)</sup> is the covariance weight vector associated with unit h j<sup>c)</sup> and </span><span class="font64" style="font-weight:bold;font-style:italic;">E<sub>m</sub></span><span class="font64">(x, h<sup>( </sup>is as defined in Eq. 20.44.</span></p>
<p><span class="font64">Just as with the mcRBM, the mPoT model energy function specifies a multivariate Gaussian, with a conditional distribution over x that has non-diagonal covariance. Learning in the mPoT model—again, like the mcRBM—is complicated by the inability to sample from the non-diagonal Gaussian conditional&#160;PmPoT(<sup>x 1 h(m)</sup>, h<sup>(c)</sup> ), so Ranzato </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2010b) also advocate direct sampling of&#160;p(x) via Hamiltonian (hybrid) Monte Carlo.</span></p>
<p><span class="font64" style="font-weight:bold;">Spike and Slab Restricted Boltzmann Machines </span><span class="font64">Spike and slab restricted Boltzmann machines (Courville </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2011) or ssRBMs provide another means&#160;of modeling the covariance structure of real-valued data. Compared to mcRBMs,&#160;ssRBMs have the advantage of requiring neither matrix inversion nor Hamiltonian&#160;Monte Carlo methods. As a model of natural images, the ssRBM is interesting&#160;in that, like the mcRBM and the mPoT model, its binary hidden units encode&#160;the conditional covariance across pixels through the use of auxiliary real-valued&#160;variables.</span></p>
<p><span class="font64">The spike and slab RBM has two sets of hidden units: binary </span><span class="font64" style="font-weight:bold;font-style:italic;">spike</span><span class="font64"> units </span><span class="font64" style="font-weight:bold;">h</span><span class="font64">, and real-valued </span><span class="font64" style="font-weight:bold;font-style:italic;">slab</span><span class="font64"> units </span><span class="font64" style="font-weight:bold;">s</span><span class="font64">. The mean of the visible units conditioned on the&#160;hidden units is given by (</span><span class="font64" style="font-weight:bold;">h 0 </span><span class="font64" style="font-style:italic;">s</span><span class="font64" style="font-weight:bold;font-style:italic;">)</span><span class="font64" style="font-style:italic;">W</span><span class="font64"><sup>T</sup>. In other words, each column </span><span class="font64" style="font-weight:bold;">W</span><span class="font64"><sub>:;i</sub> defines a&#160;component that can appear in the input when </span><span class="font64" style="font-weight:bold;font-style:italic;">hi =</span><span class="font64"> 1. The corresponding spike&#160;variable h<sub>i</sub> determines whether that component is present at all. The corresponding&#160;slab variable s<sub>i</sub> determines the intensity of that component, if it is present. When&#160;a spike variable is active, the corresponding slab variable adds variance to the&#160;input along the axis defined by </span><span class="font64" style="font-weight:bold;">W</span><span class="font64"><sub>:;i</sub>. This allows us to model the covariance of the&#160;inputs. Fortunately, contrastive divergence and persistent contrastive divergence&#160;with Gibbs sampling are still applicable. There is no need to invert any matrix.</span></p>
<p><span class="font64">Formally, the ssRBM model is defined via its energy function:</span></p><div>
<p><span class="font64" style="font-weight:bold;">1</span></p></div><div>
<p><span class="font64">E ss(</span><span class="font64" style="font-weight:bold;">x</span><span class="font64">, </span><span class="font64" style="font-weight:bold;">s</span><span class="font64">, </span><span class="font64" style="font-weight:bold;">h</span><span class="font64">) = </span><span class="font64" style="font-weight:bold;">— ^ x </span><span class="font64" style="font-style:italic;"><sup>T</sup>W </span><span class="font64" style="font-weight:bold;font-style:italic;">:,iSihi</span><span class="font64"> + <sub>2</sub> </span><span class="font64" style="font-weight:bold;">x<sup>T</sup></span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-variant:small-caps;">(a. + </span><span class="font64" style="font-weight:bold;"><sup>£</sup> $ihij</span></p></div><div>
<p><span class="font64" style="font-weight:bold;">x</span></p></div><div>
<p><span class="font64">(20.50)</span></p></div>
<p><span class="font64"><sub>1</sub></span></p>
<p><span class="font64">+ 2$^ as? -X} </span><span class="font64" style="font-weight:bold;font-style:italic;"><sup>a</sup>iEi'Sihi -^2 bihi</span><span class="font64"> +5Z </span><span class="font64" style="font-weight:bold;font-style:italic;"><sup>a</sup>i$hi,</span><span class="font64"> &#160;&#160;&#160;(20.51)</span></p>
<p><span class="font64">where </span><span class="font64" style="font-weight:bold;font-style:italic;">bi</span><span class="font64"> is the offset of the spike h<sub>i</sub> and </span><span class="font64" style="font-weight:bold;">A </span><span class="font64">is a diagonal precision matrix on the observations </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">. The parameter a<sub>i</sub> &gt; 0 is a scalar precision parameter for the&#160;real-valued slab variable </span><span class="font64" style="font-weight:bold;">s</span><span class="font64"><sub>i</sub>. The parameter </span><span class="font64" style="font-weight:bold;">$</span><span class="font64"><sub>i</sub> is a non-negative diagonal matrix&#160;that defines an </span><span class="font64" style="font-weight:bold;">h</span><span class="font64">-modulated quadratic penalty on </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">. Each * is a mean parameter&#160;for the slab variable s<sub>i</sub>.</span></p>
<p><span class="font64">With the joint distribution defined via the energy function, it is relatively straightforward to derive the ssRBM conditional distributions. For example,&#160;by marginalizing out the slab variables </span><span class="font64" style="font-weight:bold;">s</span><span class="font64">, the conditional distribution over the&#160;observations given the binary spike variables </span><span class="font64" style="font-weight:bold;">h </span><span class="font64">is given by:</span></p><div>
<p><span class="font64" style="font-weight:bold;">Pss<sup>(x 1 h)</sup></span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">J</span><span class="font64"> exp {—</span><span class="font64" style="font-weight:bold;font-style:italic;">E(</span><span class="font64" style="font-style:italic;">x</span><span class="font64" style="font-weight:bold;font-style:italic;">, </span><span class="font64" style="font-style:italic;">s</span><span class="font64" style="font-weight:bold;font-style:italic;">,</span><span class="font64"> h)} </span><span class="font64" style="font-weight:bold;font-style:italic;">d</span><span class="font64" style="font-style:italic;">s</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">= N</span><span class="font64"> U; cgh £ w:,i*</span><span class="font64" style="font-weight:bold;font-style:italic;">h</span><span class="font64">i, cgJ</span></p></div><div>
<p><span class="font64" style="font-weight:bold;">11</span></p>
<p><span class="font64">P</span><span class="font64" style="font-weight:bold;font-style:italic;">(h) Z</span></p></div><div>
<p><span class="font64">(20.52)</span></p>
<p><span class="font64">(20.53)</span></p></div>
<p><span class="font64">where C־^ = (A +£ , </span><span class="font64" style="font-weight:bold;font-style:italic;">* ,hi</span><span class="font64"> - </span><span class="font64" style="font-weight:bold;font-style:italic;">£,</span><span class="font64"> a-'h WW) <sup>1</sup>. The last equality holds only if the covariance matrix C^h is positive definite.</span></p>
<p><span class="font64">Gating by the spike variables means that the true marginal distribution over h 0 s is sparse. This is different from sparse coding, where samples from the model&#160;“almost never” (in the measure theoretic sense) contain zeros in the code, and MAP&#160;inference is required to impose sparsity.</span></p>
<p><span class="font64">Comparing the ssRBM to the mcRBM and the mPoT models, the ssRBM parametrizes the conditional covariance of the observation in a significantly different&#160;way. The mcRBM and mPoT both model the covariance structure of the observation</span></p>
<p><span class="font64">as ^ </span><span class="font64" style="font-weight:bold;font-style:italic;">Ylj h</span><span class="font64"> j<sup>c</sup>V<sup>(j)</sup> r<sup>(j)T</sup> + &#160;&#160;&#160;, using the activation of the hidden units </span><span class="font64" style="font-weight:bold;font-style:italic;">hj &gt;</span><span class="font64"> 0 to</span></p>
<p><span class="font64">enforce constraints on the conditional covariance in the direction r<sup>(j)</sup>. In contrast, the ssRBM specifies the conditional covariance of the observations using the hidden&#160;spike activations </span><span class="font64" style="font-weight:bold;font-style:italic;">hi =</span><span class="font64"> 1 to pinch the precision matrix along the direction specified&#160;by the corresponding weight vector. The ssRBM conditional covariance is very&#160;similar to that given by a different model: the product of probabilistic principal&#160;components analysis (PoPPCA) (Williams and Agakov, 2002). In the overcomplete&#160;setting, sparse activations with the ssRBM parametrization permit significant&#160;variance (above the nominal variance given by A<sup>-1</sup>) only in the selected directions&#160;of the sparsely activated h<sub>i</sub>. In the mcRBM or mPoT models, an overcomplete&#160;representation would mean that to capture variation in a particular direction in&#160;the observation space requires removing potentially all constraints with positive&#160;projection in that direction. This would suggest that these models are less well&#160;suited to the overcomplete setting.</span></p>
<p><span class="font64">The primary disadvantage of the spike and slab restricted Boltzmann machine is that some settings of the parameters can correspond to a covariance matrix&#160;that is not positive definite. Such a covariance matrix places more unnormalized&#160;probability on values that are farther from the mean, causing the integral over&#160;all possible outcomes to diverge. Generally this issue can be avoided with simple&#160;heuristic tricks. There is not yet any theoretically satisfying solution. Using&#160;constrained optimization to explicitly avoid the regions where the probability is&#160;undefined is difficult to do without being overly conservative and also preventing&#160;the model from accessing high-performing regions of parameter space.</span></p>
<p><span class="font64">Qualitatively, convolutional variants of the ssRBM produce excellent samples of natural images. Some examples are shown in Fig. 16.1.</span></p>
<p><span class="font64">The ssRBM allows for several extensions. Including higher-order interactions and average-pooling of the slab variables (Courville </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2014) enables the model&#160;to learn excellent features for a classifier when labeled data is scarce. Adding a&#160;term to the energy function that prevents the partition function from becoming&#160;undefined results in a sparse coding model, spike and slab sparse coding (Goodfellow&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2013d), also known as S3C.</span></p><h4><a id="bookmark6"></a><span class="font65" style="font-weight:bold;">20.6 Convolutional Boltzmann Machines</span></h4>
<p><span class="font64">As seen in Chapter 9, extremely high dimensional inputs such as images place great strain on the computation, memory and statistical requirements of machine&#160;learning models. Replacing matrix multiplication by discrete convolution with a&#160;small kernel is the standard way of solving these problems for inputs that have&#160;translation invariant spatial or temporal structure. Desjardins and Bengio (2008)&#160;showed that this approach works well when applied to RBMs.</span></p>
<p><span class="font64">Deep convolutional networks usually require a pooling operation so that the spatial size of each successive layer decreases. Feedforward convolutional networks&#160;often use a pooling function such as the maximum of the elements to be pooled.&#160;It is unclear how to generalize this to the setting of energy-based models. We&#160;could introduce a binary pooling unit p over n binary detector units d and enforce&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">p =</span><span class="font64"> max<sub>i</sub> d<sub>i</sub> by setting the energy function to be to whenever that constraint is&#160;violated. This does not scale well though, as it requires evaluating </span><span class="font64" style="font-weight:bold;font-style:italic;">2</span><span class="font64"> different&#160;energy configurations to compute the normalization constant. For a small 3 x 3&#160;pooling region this requires 2<sup>9</sup> = 512 energy function evaluations per pooling unit!</span></p>
<p><span class="font64">Lee </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2009) developed a solution to this problem called </span><span class="font64" style="font-weight:bold;font-style:italic;">probabilistic max pooling</span><span class="font64"> (not to be confused with “stochastic pooling,” which is a technique for&#160;implicitly constructing ensembles of convolutional feedforward networks). The&#160;strategy behind probabilistic max pooling is to constrain the detector units so&#160;at most one may be active at a time. This means there are only n + 1 total&#160;states (one state for each of the n detector units being on, and an additional state&#160;corresponding to all of the detector units being off). The pooling unit is on if&#160;and only if one of the detector units is on. The state with all units off is assigned&#160;energy zero. We can think of this as describing a model with a single variable that&#160;has n + 1 states, or equivalently as a model that has n + 1 variables that assigns&#160;energy to to all but n + 1 joint assignments of variables.</span></p>
<p><span class="font64">While efficient, probabilistic max pooling does force the detector units to be mutually exclusive, which may be a useful regularizing constraint in some contexts&#160;or a harmful limit on model capacity in other contexts. It also does not support&#160;overlapping pooling regions. Overlapping pooling regions are usually required&#160;to obtain the best performance from feedforward convolutional networks, so this&#160;constraint probably greatly reduces the performance of convolutional Boltzmann</span></p>
<p><span class="font64">machines.</span></p>
<p><span class="font64">Lee </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2009) demonstrated that probabilistic max pooling could be used to build convolutional deep Boltzmann machines.<a id="footnote3"></a><sup><a href="#bookmark7">3</a></sup><sup></sup> This model is able to perform&#160;operations such as filling in missing portions of its input. While intellectually&#160;appealing, this model is challenging to make work in practice, and usually does&#160;not perform as well as a classifier as traditional convolutional networks trained&#160;with supervised learning.</span></p>
<p><span class="font64">Many convolutional models work equally well with inputs of many different spatial sizes. For Boltzmann machines, it is difficult to change the input size&#160;for a variety of reasons. The partition function changes as the size of the input&#160;changes. Moreover, many convolutional networks achieve size invariance by scaling&#160;up the size of their pooling regions proportional to the size of the input, but scaling&#160;Boltzmann machine pooling regions is awkward. Traditional convolutional neural&#160;networks can use a fixed number of pooling units and dynamically increase the&#160;size of their pooling regions in order to obtain a fixed-size representation of a&#160;variable-sized input. For Boltzmann machines, large pooling regions become too&#160;expensive for the naive approach. The approach of Lee </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2009) of making&#160;each of the detector units in the same pooling region mutually exclusive solves&#160;the computational problems, but still does not allow variable-size pooling regions.&#160;For example, suppose we learn a model with 2 x 2 probabilistic max pooling over&#160;detector units that learn edge detectors. This enforces the constraint that only&#160;one of these edges may appear in each 2 x 2 region. If we then increase the size of&#160;the input image by 50% in each direction, we would expect the number of edges to&#160;increase correspondingly. Instead, if we increase the size of the pooling regions by&#160;50% in each direction to 3 x 3, then the mutual exclusivity constraint now specifies&#160;that each of these edges may only appear once in a 3 x 3 region. As we grow&#160;a model’s input image in this way, the model generates edges with less density.&#160;Of course, these issues only arise when the model must use variable amounts of&#160;pooling in order to emit a fixed-size output vector. Models that use probabilistic&#160;max pooling may still accept variable-sized input images so long as the output of&#160;the model is a feature map that can scale in size proportional to the input image.</span></p>
<p><span class="font64">Pixels at the boundary of the image also pose some difficulty, which is exacerbated by the fact that connections in a Boltzmann machine are symmetric. If we do not implicitly zero-pad the input, then there are fewer hidden units than&#160;visible units, and the visible units at the boundary of the image are not modeled&#160;well because they lie in the receptive field of fewer hidden units. However, if we do&#160;implicitly zero-pad the input, then the hidden units at the boundary are driven by&#160;fewer input pixels, and may fail to activate when needed.</span></p><h4><a id="bookmark8"></a><span class="font65" style="font-weight:bold;">20.7 Boltzmann Machines for Structured or Sequential&#160;Outputs</span></h4>
<p><span class="font64">In the structured output scenario, we wish to train a model that can map from some input </span><span class="font64" style="font-weight:bold;">x </span><span class="font64">to some output </span><span class="font64" style="font-weight:bold;">y</span><span class="font64">, and the different entries of </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">are related to each&#160;other and must obey some constraints. For example, in the speech synthesis task,&#160;</span><span class="font64" style="font-weight:bold;">y </span><span class="font64">is a waveform, and the entire waveform must sound like a coherent utterance.</span></p>
<p><span class="font64">A natural way to represent the relationships between the entries in </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">is to use a probability distribution p(</span><span class="font64" style="font-weight:bold;">y </span><span class="font64">| </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">). Boltzmann machines, extended to model&#160;conditional distributions, can supply this probabilistic model.</span></p>
<p><span class="font64">The same tool of conditional modeling with a Boltzmann machine can be used not just for structured output tasks, but also for sequence modeling. In the latter&#160;case, rather than mapping an input </span><span class="font64" style="font-weight:bold;">x </span><span class="font64">to an output </span><span class="font64" style="font-weight:bold;">y</span><span class="font64">, the model must estimate a&#160;probability distribution over a sequence of variables,p(</span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(1)</sup>,..., </span><span class="font64" style="font-weight:bold;font-variant:small-caps;">x</span><span class="font64" style="font-variant:small-caps;"><sup>(t)</sup>). Conditional&#160;Boltzmann machines can represent factors of the form p(</span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(t)</sup> | </span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(1)</sup>,..., </span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(t-1)</sup>) in&#160;order to accomplish this task.</span></p>
<p><span class="font64">An important sequence modeling task for the video game and film industry is modeling sequences of joint angles of skeletons used to render 3-D characters.&#160;These sequences are often collected using motion capture systems to record the&#160;movements of actors. A probabilistic model of a character’s movement allows&#160;the generation of new, previously unseen, but realistic animations. To solve&#160;this sequence modeling task, Taylor </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2007) introduced a conditional RBM&#160;modelingp(</span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(t)</sup> | </span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(t-1)</sup>,...,</span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(t-m)</sup>) for small m. The model is an RBM over&#160;p(</span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(t)</sup>) whose bias parameters are a linear function of the preceding m values of </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">.&#160;When we condition on different values of </span><span class="font64" style="font-weight:bold;">x</span><span class="font64"><sup>(t-1)</sup> and earlier variables, we get a new&#160;RBM over </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">. The weights in the RBM over </span><span class="font64" style="font-weight:bold;">x </span><span class="font64">never change, but by conditioning on&#160;different past values, we can change the probability of different hidden units in the&#160;RBM being active. By activating and deactivating different subsets of hidden units,&#160;we can make large changes to the probability distribution induced on </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">. Other&#160;variants of conditional RBM (Mnih </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2011) and other variants of sequence&#160;modeling using conditional RBMs are possible (Taylor and Hinton, 2009; Sutskever&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2009; Boulanger-Lewandowski </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2012).</span></p>
<p><span class="font64">Another sequence modeling task is to model the distribution over sequences of musical notes used to compose songs. Boulanger-Lewandowski </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2012)&#160;introduced the </span><span class="font64" style="font-weight:bold;font-style:italic;">RNN-RBM</span><span class="font64"> sequence model and applied it to this task. The RNN-RBM is a generative model of a sequence of frames consisting of an RNN&#160;that emits the RBM parameters for each time step. Unlike the model described&#160;above, the RNN emits all of the parameters of the RBM, including the weights.&#160;To train the model, we need to be able to back-propagate the gradient of the&#160;loss function through the RNN. The loss function is not applied directly to the&#160;RNN outputs. Instead, it is applied to the RBM. This means that we must&#160;approximately differentiate the loss with respect to the RBM parameters using&#160;contrastive divergence or a related algorithm. This approximate gradient may then&#160;be back-propagated through the RNN using the usual back-propagation through&#160;time algorithm.</span></p><h4><a id="bookmark9"></a><span class="font65" style="font-weight:bold;">20.8 Other Boltzmann Machines</span></h4>
<p><span class="font64">Many other variants of Boltzmann machines are possible.</span></p>
<p><span class="font64">Boltzmann machines may be extended with different training criteria. We have focused on Boltzmann machines trained to approximately maximize the generative&#160;criterion logp(</span><span class="font64" style="font-weight:bold;">v</span><span class="font64">). It is also possible to train discriminative RBMs that aim to&#160;maximize log</span><span class="font64" style="font-weight:bold;font-style:italic;">p(y</span><span class="font64"> | </span><span class="font64" style="font-weight:bold;">v</span><span class="font64">) instead (Larochelle and Bengio, 2008). This approach often&#160;performs the best when using a linear combination of both the generative and&#160;the discriminative criteria. Unfortunately, RBMs do not seem to be as powerful&#160;supervised learners as MLPs, at least using existing methodology.</span></p>
<p><span class="font64">Most Boltzmann machines used in practice have only second-order interactions in their energy functions, meaning that their energy functions are the sum of many&#160;terms and each individual term only includes the product between two random&#160;variables. An example of such a term is </span><span class="font64" style="font-weight:bold;font-style:italic;">v<sub>i</sub>W<sub>i</sub>,jhj</span><span class="font64"> . It is also possible to train&#160;higher-order Boltzmann machines (Sejnowski, 1987) whose energy function terms&#160;involve the products between many variables. Three-way interactions between a&#160;hidden unit and two different images can model spatial transformations from one&#160;frame of video to the next (Memisevic and Hinton, 2007, 2010). Multiplication by a&#160;one-hot class variable can change the relationship between visible and hidden units&#160;depending on which class is present (Nair and Hinton, 2009). One recent example&#160;of the use of higher-order interactions is a Boltzmann machine with two groups of&#160;hidden units, with one group of hidden units that interact with both the visible&#160;units </span><span class="font64" style="font-weight:bold;">v </span><span class="font64">and the class label y, and another group of hidden units that interact only&#160;with the </span><span class="font64" style="font-weight:bold;">v </span><span class="font64">input values (Luo </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2011). This can be interpreted as encouraging&#160;some hidden units to learn to model the input using features that are relevant to&#160;the class but also to learn extra hidden units that explain nuisance details that&#160;are necessary for the samples of </span><span class="font64" style="font-weight:bold;">v </span><span class="font64">to be realistic but do not determine the class&#160;of the example. Another use of higher-order interactions is to gate some features.&#160;Sohn </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2013) introduced a Boltzmann machine with third-order interactions&#160;with binary mask variables associated with each visible unit. When these masking&#160;variables are set to zero, they remove the influence of a visible unit on the hidden&#160;units. This allows visible units that are not relevant to the classification problem&#160;to be removed from the inference pathway that estimates the class.</span></p>
<p><span class="font64">More generally, the Boltzmann machine framework is a rich space of models permitting many more model structures than have been explored so far. Developing&#160;a new form of Boltzmann machine requires some more care and creativity than&#160;developing a new neural network layer, because it is often difficult to find an energy&#160;function that maintains tractability of all of the different conditional distributions&#160;needed to use the Boltzmann machine, but despite this required effort the field&#160;remains open to innovation.</span></p><h4><a id="bookmark10"></a><span class="font65" style="font-weight:bold;">20.9 Back-Propagation through Random Operations</span></h4>
<p><span class="font64">Traditional neural networks implement a deterministic transformation of some input variables </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">. When developing generative models, we often wish to extend&#160;neural networks to implement stochastic transformations of </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">. One straightforward&#160;way to do this is to augment the neural network with extra inputs </span><span class="font64" style="font-weight:bold;">z </span><span class="font64">that are&#160;sampled from some simple probability distribution, such as a uniform or Gaussian&#160;distribution. The neural network can then continue to perform deterministic&#160;computation internally, but the function f (</span><span class="font64" style="font-weight:bold;">x</span><span class="font64">, </span><span class="font64" style="font-weight:bold;">z</span><span class="font64">) will appear stochastic to an&#160;observer who does not have access to </span><span class="font64" style="font-weight:bold;">z</span><span class="font64">. Provided that f is continuous and&#160;differentiable, we can then compute the gradients necessary for training using&#160;back-propagation as usual.</span></p>
<p><span class="font64">As an example, let us consider the operation consisting of drawing samples y from a Gaussian distribution with mean ! and variance </span><span class="font64" style="font-weight:bold;font-style:italic;">a<sup>2</sup>:</span></p>
<p><span class="font64">y </span><span class="font64" style="font-weight:bold;">~N(</span><span class="font64">!,a<sup>2</sup> </span><span class="font64" style="font-weight:bold;">)</span><span class="font64">. &#160;&#160;&#160;(20.54)</span></p>
<p><span class="font64">Because an individual sample of y is not produced by a function, but rather by a sampling process whose output changes every time we query it, it may seem&#160;counterintuitive to take the derivatives of y with respect to the parameters of&#160;its distribution, </span><span class="font64" style="font-weight:bold;font-style:italic;">!</span><span class="font64"> and a<sup>2</sup>. However, we can rewrite the sampling process as&#160;transforming an underlying random value z </span><span class="font64" style="font-weight:bold;">~ N(</span><span class="font64">z</span><span class="font64" style="font-weight:bold;">; 0</span><span class="font64">, </span><span class="font64" style="font-weight:bold;">1) </span><span class="font64">to obtain a sample from</span></p>
<p><span class="font64">the desired distribution:</span></p>
<p><span class="font64">y = </span><span class="font64" style="font-style:italic;">p</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">+ az &#160;&#160;&#160;(20.55)</span></p>
<p><span class="font64">We are now able to back-propagate through the sampling operation, by regarding it as a deterministic operation with an extra input z. Crucially, the extra input is a random variable whose distribution is not a function of any of the variables&#160;whose derivatives we want to calculate. The result tells us how an infinitesimal&#160;change in </span><span class="font64" style="font-style:italic;">p</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">or a would change the output if we could repeat the sampling operation&#160;again with the same value of z.</span></p>
<p><span class="font64">Being able to back-propagate through this sampling operation allows us to incorporate it into a larger graph. We can build elements of the graph on top of the&#160;output of the sampling distribution. For example, we can compute the derivatives&#160;of some loss function J(y). We can also build elements of the graph whose outputs&#160;are the inputs or the parameters of the sampling operation. For example, we could&#160;build a larger graph with </span><span class="font64" style="font-style:italic;">p </span><span class="font64" style="font-weight:bold;font-style:italic;">= </span><span class="font64" style="font-style:italic;">f</span><span class="font64" style="font-weight:bold;font-style:italic;">(x; 6)</span><span class="font64"> and a = g(</span><span class="font64" style="font-weight:bold;">x</span><span class="font64">; </span><span class="font64" style="font-weight:bold;">6</span><span class="font64">). In this augmented graph,&#160;we can use back-propagation through these functions to derive </span><span class="font64" style="font-weight:bold;font-style:italic;font-variant:small-caps;">V qJ</span><span class="font64">(y).</span></p>
<p><span class="font64">The principle used in this Gaussian sampling example is more generally applicable. We can express any probability distribution of the formp(y; </span><span class="font64" style="font-weight:bold;">6</span><span class="font64">) or </span><span class="font64" style="font-style:italic;">p</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">(y | </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">; </span><span class="font64" style="font-weight:bold;">6</span><span class="font64">) as p(y | </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">), where </span><span class="font64" style="font-weight:bold;">u </span><span class="font64">is a variable containing both parameters </span><span class="font64" style="font-weight:bold;">6</span><span class="font64">, and if applicable,&#160;the inputs </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">. Given a value y sampled from distribution p(y | </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">), where </span><span class="font64" style="font-weight:bold;">u </span><span class="font64">may in&#160;turn be a function of other variables, we can rewrite</span></p>
<p><span class="font64" style="font-weight:bold;">y </span><span class="font64">~ p(</span><span class="font64" style="font-weight:bold;">y </span><span class="font64">| </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">) &#160;&#160;&#160;(20.56)</span></p>
<p><span class="font64">as</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">y = </span><span class="font64" style="font-style:italic;">f </span><span class="font64" style="font-weight:bold;font-style:italic;">(z; u</span><span class="font64">), &#160;&#160;&#160;(20.57)</span></p>
<p><span class="font64">where </span><span class="font64" style="font-weight:bold;">z </span><span class="font64">is a source of randomness. We may then compute the derivatives of </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">with respect to </span><span class="font64" style="font-weight:bold;">u </span><span class="font64">using traditional tools such as the back-propagation algorithm applied&#160;to f, so long as f is continuous and differentiable almost everywhere. Crucially, </span><span class="font64" style="font-weight:bold;">u&#160;</span><span class="font64">must not be a function of </span><span class="font64" style="font-weight:bold;">z</span><span class="font64">, and </span><span class="font64" style="font-weight:bold;">z </span><span class="font64">must not be a function of </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">. This technique is&#160;often called the </span><span class="font64" style="font-style:italic;">reparametrization trick, stochastic back-propagation</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">or </span><span class="font64" style="font-style:italic;">perturbation&#160;analysis.</span></p>
<p><span class="font64">The requirement that f be continuous and differentiable of course requires </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">to be continuous. If we wish to back-propagate through a sampling process that&#160;produces discrete-valued samples, it may still be possible to estimate a gradient on&#160;</span><span class="font64" style="font-weight:bold;">u</span><span class="font64">, using reinforcement learning algorithms such as variants of the REINFORCE&#160;algorithm (Williams, 1992), discussed in Sec. 20.9.1.</span></p>
<p><span class="font64">In neural network applications, we typically choose </span><span class="font64" style="font-weight:bold;">z </span><span class="font64">to be drawn from some simple distribution, such as a unit uniform or unit Gaussian distribution, and&#160;achieve more complex distributions by allowing the deterministic portion of the&#160;network to reshape its input.</span></p>
<p><span class="font64">The idea of propagating gradients or optimizing through stochastic operations dates back to the mid-twentieth century (Price, 1958; Bonnet, 1964) and was&#160;first used for machine learning in the context of reinforcement learning (Williams,&#160;1992). More recently, it has been applied to variational approximations (Opper&#160;and Archambeau, 2009) and stochastic or generative neural networks (Bengio&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2013b; Kingma, 2013; Kingma and Welling, 2014b,a; Rezende </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2014;&#160;Goodfellow </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2014c). Many networks, such as denoising autoencoders or&#160;networks regularized with dropout, are also naturally designed to take noise&#160;as an input without requiring any special reparametrization to make the noise&#160;independent from the model.</span></p><h5><a id="bookmark11"></a><span class="font64" style="font-weight:bold;">20.9.1 Back-Propagating through Discrete Stochastic Operations</span></h5>
<p><span class="font64">When a model emits a discrete variable </span><span class="font64" style="font-weight:bold;">y</span><span class="font64">, the reparametrization trick is not applicable. Suppose that the model takes inputs </span><span class="font64" style="font-weight:bold;">x </span><span class="font64">and parameters </span><span class="font64" style="font-weight:bold;">6</span><span class="font64">, both&#160;encapsulated in the vector </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">, and combines them with random noise </span><span class="font64" style="font-weight:bold;">z </span><span class="font64">to produce</span></p>
<p><span class="font64" style="font-weight:bold;">y</span><span class="font64"><sup>:</sup></span></p>
<p><span class="font64" style="font-weight:bold;">y </span><span class="font64">= f (</span><span class="font64" style="font-weight:bold;">z</span><span class="font64">; </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">). &#160;&#160;&#160;(20.58)</span></p>
<p><span class="font64">Because </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">is discrete, f must be a step function. The derivatives of a step function are not useful at any point. Right at each step boundary, the derivatives are&#160;undefined, but that is a small problem. The large problem is that the derivatives&#160;are zero almost everywhere, on the regions between step boundaries. The derivatives&#160;of any cost function J(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">) therefore do not give any information for how to update&#160;the model parameters </span><span class="font64" style="font-weight:bold;">6</span><span class="font64">.</span></p>
<p><span class="font64">The REINFORCE algorithm (REward Increment = Non-negative Factor x Offset Reinforcement x Characteristic Eligibility) provides a framework defining a&#160;family of simple but powerful solutions (Williams, 1992). The core idea is that&#160;even though J(f (</span><span class="font64" style="font-weight:bold;">z</span><span class="font64">; </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">)) is a step function with useless derivatives, the expected&#160;cost E<sub>z</sub>~<sub>P</sub>(z)J (f (</span><span class="font64" style="font-weight:bold;">z</span><span class="font64">; </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">)) is often a smooth function amenable to gradient descent.&#160;Although that expectation is typically not tractable when </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">is high-dimensional&#160;(or is the result of the composition of many discrete stochastic decisions), it can be&#160;estimated without bias using a Monte Carlo average. The stochastic estimate of&#160;the gradient can be used with SGD or other stochastic gradient-based optimization&#160;techniques.</span></p>
<p><span class="font64">The simplest version of REINFORCE can be derived by simply differentiating</span></p>
<p><span class="font64">the expected cost:</span></p>
<table border="1">
<tr><td>
<p><span class="font64"><sup>E</sup> </span><span class="font64" style="font-weight:bold;">z</span><span class="font64"><sup>[J (</sup>y<sup>)]</sup> </span><span class="font64" style="font-weight:bold;font-style:italic;">_</span><span class="font64" style="font-style:italic;">Y^</span><span class="font64" style="font-weight:bold;font-style:italic;"><sup>J (</sup></span><span class="font64" style="font-style:italic;">y</span><span class="font64" style="font-weight:bold;font-style:italic;"><sup>)</sup>p<sup>(</sup></span><span class="font64" style="font-style:italic;">y</span><span class="font64"><sup>)</sup></span></p></td><td>
<p><span class="font64">(20.59)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font46" style="font-weight:bold;font-style:italic;"><sub>y</sub></span></p>
<p><span class="font64">״ <sup>E</sup>J«»_ E J &lt;»&gt; t״’</span></p>
<p><span class="font64" style="font-weight:bold;">y</span></p></td><td style="vertical-align:middle;">
<p><span class="font64">(20.60)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font64">_ E J (y)p(y)<sup>d</sup></span></p>
<p><span class="font64" style="font-weight:bold;">y</span></p></td><td style="vertical-align:middle;">
<p><span class="font64">(20.61)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font64">« <sup>1</sup> </span><span class="font66" style="font-style:italic;">E </span><span class="font64" style="font-weight:bold;font-style:italic;">J</span><span class="font64"> (y(</span><span class="font64" style="font-weight:bold;">i</span><span class="font64">) </span><span class="font64" style="font-weight:bold;font-style:italic;">f</span><span class="font64"> <sup>1og p(y,</sup></span><span class="font64" style="font-weight:bold;"><sup>&lt;</sup></span><span class="font64"><sup>))</sup>.</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">m d</span><span class="font64" style="font-style:italic;">u</span></p>
<p><span class="font64">y<sup>(i)</sup></span><span class="font64" style="font-weight:bold;">~p</span><span class="font64">(y)</span><span class="font64" style="font-weight:bold;">, i</span><span class="font64">= 1</span></p></td><td style="vertical-align:middle;">
<p><span class="font64">(20.62)</span></p></td></tr>
</table><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;text-decoration:underline;">d</span><span class="font64" style="text-decoration:underline;"> logp(y)</span><span class="font64"> _ &#160;&#160;&#160;</span><span class="font64" style="text-decoration:underline;">1 </span><span class="font64" style="font-weight:bold;font-style:italic;text-decoration:underline;">dp(y)</span></p></div>
<p><span class="font64">Eq. 20.60 relies on the assumption that J does not reference </span><span class="font64" style="font-weight:bold;font-style:italic;">u</span><span class="font64"> directly. It is trivial to extend the approach to relax this assumption. Eq. 20.61 exploits the derivative</span></p><div>
<p><span class="font64">Eq. 20.62 gives an unbiased Monte</span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">p(y) du</span></p></div>
<p><span class="font64">rule for the logarithm,</span></p>
<p><span class="font64">Carlo estimator of the gradient.</span></p>
<p><span class="font64">Anywhere we write </span><span class="font64" style="font-weight:bold;font-style:italic;">p( </span><span class="font64" style="font-style:italic;">y</span><span class="font64" style="font-weight:bold;font-style:italic;">)</span><span class="font64"> in this section, one could equally write </span><span class="font64" style="font-weight:bold;font-style:italic;">p(</span><span class="font64" style="font-style:italic;">y</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">| </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">). This is because p(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">) is parametrized by </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">, and </span><span class="font64" style="font-weight:bold;">u </span><span class="font64">contains both </span><span class="font64" style="font-weight:bold;">6 </span><span class="font64">and </span><span class="font64" style="font-weight:bold;">x</span><span class="font64">, if </span><span class="font64" style="font-weight:bold;">x </span><span class="font64">is present.</span></p>
<p><span class="font64">One issue with the above simple REINFORCE estimator is that it has a very high variance, so that many samples of </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">need to be drawn to obtain a good&#160;estimator of the gradient, or equivalently, if only one sample is drawn, SGD will&#160;converge very slowly and will require a smaller learning rate. It is possible to&#160;considerably reduce the variance of that estimator by using </span><span class="font64" style="font-weight:bold;font-style:italic;">variance reduction&#160;</span><span class="font64">methods (Wilson, 1984; L’Ecuyer, 1994). The idea is to modify the estimator so&#160;that its expected value remains unchanged but its variance get reduced. In the&#160;context of REINFORCE, the proposed variance reduction methods involve the&#160;computation of a </span><span class="font64" style="font-weight:bold;font-style:italic;">baseline</span><span class="font64"> that is used to offset J (</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">). Note that any offset b(</span><span class="font64" style="font-weight:bold;">u</span><span class="font64">)&#160;that does not depend on </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">would not change the expectation of the estimated&#160;gradient because</span></p><div>
<p><span class="font64"><sup>E</sup>p<sup>(</sup>y<sup>)</sup></span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">d</span><span class="font64"> log p(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">) </span><span class="font64" style="font-weight:bold;font-style:italic;">d </span><span class="font64" style="font-style:italic;">u</span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">d</span><span class="font64"> tog p<sup>(</sup></span><span class="font64" style="font-weight:bold;">y</span><span class="font64"><sup>) </sup>_&#160;&#160;&#160;&#160;<sup>p(</sup></span><span class="font64" style="font-weight:bold;"><sup>y</sup></span><span class="font64"><sup>)</sup>&#160;&#160;&#160;&#160;d</span><span class="font64" style="font-weight:bold;">u</span></p></div><div>
<p><span class="font46" style="font-weight:bold;font-style:italic;"><sup>y</sup></span></p></div><div><h3><a id="bookmark12"></a><span class="font66">E</span></h3><h3><a id="bookmark13"></a><span class="font46" style="font-weight:bold;font-style:italic;"><sup>y</sup></span></h3></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">dp<sup>(</sup></span><span class="font64" style="font-style:italic;">y) </span><span class="font64" style="font-weight:bold;font-style:italic;">d </span><span class="font64" style="font-style:italic;">u</span></p></div><div>
<p><span class="font64" style="font-weight:bold;">dW E p(y) _ dW<sup>1</sup></span></p></div><div>
<p><span class="font64" style="font-weight:bold;">0,</span></p></div><div>
<p><span class="font64">(20.63)</span></p>
<p><span class="font64">(20.64)</span></p>
<p><span class="font64">(20.65)</span></p></div><div>
<p><span class="font46" style="font-weight:bold;font-style:italic;"><sup>y</sup></span></p></div>
<p><span class="font64">which means that</span></p><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;"><sup>E</sup>p<sup>(</sup>y<sup>)</sup></span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;"><sup>(J</sup></span><span class="font64"><sup>(</sup>y<sup>) - b(u))</sup></span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">d</span><span class="font64"> log p(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">) </span><span class="font64" style="font-weight:bold;font-style:italic;">d u</span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">— <sup>E</sup>p<sup>(</sup>y<sup>)</sup></span></p></div><div>
<p><span class="font64" style="font-weight:bold;">— E</span></p></div><div>
<p><span class="font64">p(y)</span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;"><sup>J (</sup>y)</span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;"><sup>J (</sup>y)</span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">d</span><span class="font64"> log p(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">) </span><span class="font64" style="font-weight:bold;font-style:italic;">d u</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">d</span><span class="font64"> log p(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">) </span><span class="font64" style="font-weight:bold;font-style:italic;">d u</span></p></div><div>
<p><span class="font64" style="font-weight:bold;"><sup>b(u)E</sup>p</span><span class="font64">(y)</span></p></div><div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">d</span><span class="font64"> log </span><span class="font64" style="font-weight:bold;font-style:italic;">p(y) d u</span></p>
<p><span class="font64">(20.66)</span></p>
<p><span class="font64">(20.67)</span></p></div>
<p><span class="font64">Furthermore, we can obtain the optimal b(</span><span class="font64" style="font-weight:bold;">u</span><span class="font64">) by computing the variance of (J(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">) </span><span class="font64" style="font-weight:bold;">— </span><span class="font64" style="font-style:italic;">b</span><span class="font64" style="font-weight:bold;font-style:italic;">(</span><span class="font64" style="font-style:italic;">u</span><span class="font64">))</span><span class="font64" style="font-weight:bold;font-style:italic;text-decoration:line-through;"><sup>d</sup></span><span class="font64" style="text-decoration:line-through;"><sup> 1</sup>°g<sub>&lt;</sub>P<sup>(y)</sup></span><span class="font64"> under </span><span class="font64" style="font-style:italic;">p</span><span class="font64">(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">) and minimizing with respect to b (</span><span class="font64" style="font-weight:bold;">u</span><span class="font64">). What we find is&#160;that this optimal baseline b </span><span class="font64" style="font-weight:bold;font-style:italic;">(</span><span class="font64" style="font-style:italic;">u</span><span class="font64" style="font-weight:bold;font-style:italic;">)i</span><span class="font64"> is different for each element </span><span class="font64" style="font-weight:bold;font-style:italic;">c</span><span class="font64" style="font-style:italic;">v</span><span class="font64" style="font-weight:bold;font-style:italic;"><sub>i</sub></span><span class="font64"> of the vector </span><span class="font64" style="font-style:italic;">u:</span></p><div>
<p><span class="font64" style="font-weight:bold;"><sup>b</sup> *<sup>(u)</sup>i <sup>—</sup></span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font64"><sup>E</sup>p<sup>(</sup>y<sup>)</sup></span></p></td><td colspan="3">
<p><span class="font50">r ס n</span></p>
<p><span class="font64">J (y)</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font64"><sup>E</sup>p<sup>(</sup>y<sup>)</sup></span></p></td><td>
<p><span class="font64" style="font-weight:bold;font-style:italic;">d</span><span class="font64"> log p(y) <sup>2</sup></span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">Owi</span></p></td><td>
<p></p></td></tr>
</table></div>
<p><span class="font64">(20.68)</span></p>
<p><span class="font64">The gradient estimator with respect to w<sub>i</sub> then becomes</span></p><div>
<p><span class="font64">(20.69)</span></p></div><div>
<p><span class="font64"><sup>(J (</sup>y<sup>) — b(u)</sup> i</span><span class="font64" style="font-weight:bold;font-style:italic;">)-</span></p></div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">d</span><span class="font64"> logp(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">)</span></p>
<p><span class="font64" style="font-style:italic;">du<sub>i</sub></span></p><div>
<p><span class="font64">where </span><span class="font64" style="font-weight:bold;font-style:italic;">b(u</span><span class="font64">) estimates the above b*(</span><span class="font64" style="font-weight:bold;">u </span><span class="font64">)<sub>i</sub>. The estimate b is usually obtained by adding extra outputs to the neural network and training the new outputs to estimate</span></p></div><div>
<p><span class="font64" style="font-style:italic;">C\-</span></p>
<p><span class="font64" style="font-weight:bold;">d</span><span class="font64">1°g</span><span class="font64" style="font-weight:bold;">p</span><span class="font64">y)<sup>2</sup></span></p>
<p><span class="font64" style="font-weight:bold;"><sup>dw</sup></span><span class="font64">i</span></p>
<p><span class="font64">outputs can be trained with the mean squared error objective, using respectively</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">J(y</span><span class="font64">)</span><span class="font64" style="font-weight:bold;font-style:italic;text-decoration:line-through;"><sup>d</sup></span><span class="font64" style="text-decoration:line-through;"><sup> 10</sup>g</span><span class="font64" style="font-weight:bold;text-decoration:line-through;">?■^</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">and </span><span class="font64" style="font-weight:bold;font-style:italic;text-decoration:line-through;"><sup>d</sup></span><span class="font64" style="text-decoration:line-through;"><sup> 1</sup>Og</span><span class="font64" style="font-weight:bold;text-decoration:line-through;">J^</span><span class="font64" style="font-weight:bold;"> </span><span class="font64">as targets when </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">is sampled from </span><span class="font64" style="font-weight:bold;font-style:italic;">p(y</span><span class="font64">), for a given </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">. The estimate b may then be recovered by substituting these estimates into Eq.&#160;20.68. Mnih and Gregor (2014) preferred to use a single shared output (across all&#160;elements i of </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">) trained with the target J(</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">), using as baseline b(</span><span class="font64" style="font-weight:bold;">u</span><span class="font64">)&#160;&#160;&#160;&#160;<sup>E</sup></span><span class="font64" style="font-weight:bold;">p</span><span class="font64">(y) <sup>[J (</sup></span><span class="font64" style="font-weight:bold;"><sup>y</sup></span><span class="font64"><sup>)]</sup>.</span></p></div><div>
<p><span class="font64" style="font-weight:bold;"><sup>E</sup>p</span></p></div><div>
<p><span class="font64">p(y)</span></p></div><div>
<p dir="rtl"><span class="font63">(־&gt;</span></p>
<p><span class="font64">[</span><span class="font64" style="font-weight:bold;">J</span><span class="font64">(y) </span><span class="font64" style="font-weight:bold;">^</span><span class="font64">V</span><span class="font64" style="font-weight:bold;">p</span><span class="font64">M ] </span><span class="font64" style="font-weight:bold;">and</span></p></div><div>
<p><span class="font64" style="font-weight:bold;">E</span></p></div><div>
<p><span class="font64">p(y)</span></p></div><div>
<p><span class="font64">for each element of </span><span class="font64" style="font-weight:bold;">u</span><span class="font64">. These extra</span></p></div>
<p><span class="font64">Variance reduction methods have been introduced in the reinforcement learning context (Sutton </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2000; Weaver and Tao, 2001), generalizing previous work&#160;on the case of binary reward by Dayan (1990). See Bengio </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2013b), Mnih&#160;and Gregor (2014), Ba </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2014), Mnih </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2014), or Xu </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2015) for&#160;examples of modern uses of the REINFORCE algorithm with reduced variance in&#160;the context of deep learning. In addition to the use of an input-dependent baseline&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">b(u</span><span class="font64">), Mnih and Gregor (2014) found that the scale of (J(y) — b(u)) could be&#160;adjusted during training by dividing it by its standard deviation estimated by a&#160;moving average during training, as a kind of adaptive learning rate, to counter&#160;the effect of important variations that occur during the course of training in the&#160;magnitude of this quantity. Mnih and Gregor (2014) called this heuristic </span><span class="font64" style="font-weight:bold;font-style:italic;">variance&#160;normalization.</span></p>
<p><span class="font64">REINFORCE-based estimators can be understood as estimating the gradient by correlating choices of </span><span class="font64" style="font-weight:bold;">y </span><span class="font64">with corresponding values of J (</span><span class="font64" style="font-weight:bold;">y</span><span class="font64">). If a good value of </span><span class="font64" style="font-weight:bold;">y&#160;</span><span class="font64">is unlikely under the current parametrization, it might take a long time to obtain it&#160;by chance, and get the required signal that this configuration should be reinforced.</span></p>
<p><a id="bookmark3"><sup><a href="#footnote1">1</a></sup></a></p>
<p><span class="font64"><sup></sup>The term “mcRBM” is pronounced by saying the name of the letters M-C-R-B-M; the “mc” is not pronounced like the “Mc” in “McDonald’s.”</span></p>
<p><a id="bookmark4"><sup><a href="#footnote2">2</a></sup></a></p>
<p><span class="font64"><sup></sup>This version of the Gaussian-Bernoulli RBM energy function assumes the image data has zero mean, per pixel. Pixel offsets can easily be added to the model to account for nonzero pixel&#160;means.</span></p>
<p><a id="bookmark7"><sup><a href="#footnote3">3</a></sup></a></p>
<p><span class="font64"><sup></sup>The publication describes the model as a “deep belief network” but because it can be described as a purely undirected model with tractable layer-wise mean field fixed point updates, it best fits&#160;the definition of a deep Boltzmann machine.</span></p>
</body>
</html>