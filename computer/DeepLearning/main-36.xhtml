<?xml version="1.0" encoding="UTF-8"?>

<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta name="charset" content="UTF-8"/><title></title><link rel="stylesheet" href="main.css" type="text/css"/>
</head>
<body><h4><a id="bookmark0"></a><span class="font65" style="font-weight:bold;">19.5 Learned Approximate Inference</span></h4>
<p><span class="font64">We have seen that inference can be thought of as an optimization procedure that increases the value of a function L. Explicitly performing optimization via&#160;iterative procedures such as fixed point equations or gradient-based optimization&#160;is often very expensive and time-consuming. Many approaches to inference avoid&#160;this expense by learning to perform approximate inference. Specifically, we can&#160;think of the optimization process as a function f that maps an input v to an&#160;approximate distribution q* = argmax^ L(v, q). Once we think of the multi-step&#160;iterative optimization process as just being a function, we can approximate it with&#160;a neural network that implements an approximation f(v; 6).</span></p><h5><a id="bookmark1"></a><span class="font64">19.5.1 Wake-Sleep</span></h5>
<p><span class="font64">One of the main difficulties with training a model to infer h from v is that we do not have a supervised training set with which to train the model. Given a v,&#160;we do not know the appropriate h. The mapping from v to h depends on the&#160;choice of model family, and evolves throughout the learning process as 6 changes.&#160;The wake-sleep algorithm (Hinton </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 1995b; Frey </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 1996) resolves this&#160;problem by drawing samples of both h and v from the model distribution. For&#160;example, in a directed model, this can be done cheaply by performing ancestral&#160;sampling beginning at h and ending at v. The inference network can then be&#160;trained to perform the reverse mapping: predicting which h caused the present&#160;v. The main drawback to this approach is that we will only be able to train the&#160;inference network on values of v that have high probability under the model. Early&#160;in learning, the model distribution will not resemble the data distribution, so the&#160;inference network will not have an opportunity to learn on samples that resemble&#160;data.</span></p>
<p><span class="font64">In Sec. 18.2 we saw that one possible explanation for the role of dream sleep in human beings and animals is that dreams could provide the negative phase samples&#160;that Monte Carlo training algorithms use to approximate the negative gradient of&#160;the log partition function of undirected models. Another possible explanation for&#160;biological dreaming is that it is providing samples from p( h, v) which can be used&#160;to train an inference network to predict h given v. In some senses, this explanation&#160;is more satisfying than the partition function explanation. Monte Carlo algorithms&#160;generally do not perform well if they are run using only the positive phase of the&#160;gradient for several steps then with only the negative phase of the gradient for&#160;several steps. Human beings and animals are usually awake for several consecutive&#160;hours then asleep for several consecutive hours. It is not readily apparent how this&#160;schedule could support Monte Carlo training of an undirected model. Learning&#160;algorithms based on maximizing L can be run with prolonged periods of improving&#160;q and prolonged periods of improving 6, however. If the role of biological dreaming&#160;is to train networks for predicting q, then this explains how animals are able to&#160;remain awake for several hours (the longer they are awake, the greater the gap&#160;between L and log</span><span class="font64" style="font-weight:bold;font-style:italic;">p(v</span><span class="font64">), but L will remain a lower bound) and to remain asleep&#160;for several hours (the generative model itself is not modified during sleep) without&#160;damaging their internal models. Of course, these ideas are purely speculative, and&#160;there is no hard evidence to suggest that dreaming accomplishes either of these&#160;goals. Dreaming may also serve reinforcement learning rather than probabilistic&#160;modeling, by sampling synthetic experiences from the animal’s transition model,&#160;on which to train the animal’s policy. Or sleep may serve some other purpose not&#160;yet anticipated by the machine learning community.</span></p><h5><a id="bookmark2"></a><span class="font64" style="font-weight:bold;">19.5.2 Other Forms of Learned Inference</span></h5>
<p><span class="font64">This strategy of learned approximate inference has also been applied to other models. Salakhutdinov and Larochelle (2010) showed that a single pass in a&#160;learned inference network could yield faster inference than iterating the mean field&#160;fixed point equations in a DBM. The training procedure is based on running the&#160;inference network, then applying one step of mean field to improve its estimates,&#160;and training the inference network to output this refined estimate instead of its&#160;original estimate.</span></p>
<p><span class="font64">We have already seen in Sec. 14.8 that the predictive sparse decomposition model trains a shallow encoder network to predict a sparse code for the input.&#160;This can be seen as a hybrid between an autoencoder and sparse coding. It is&#160;possible to devise probabilistic semantics for the model, under which the encoder&#160;may be viewed as performing learned approximate MAP inference. Due to its&#160;shallow encoder, PSD is not able to implement the kind of competition between&#160;units that we have seen in mean field inference. However, that problem can be&#160;remedied by training a deep encoder to perform learned approximate inference, as&#160;in the ISTA technique (Gregor and LeCun, 2010b).</span></p>
<p><span class="font64">Learned approximate inference has recently become one of the dominant approaches to generative modeling, in the form of the variational autoencoder&#160;(Kingma, 2013; Rezende </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2014). In this elegant approach, there is no need to&#160;construct explicit targets for the inference network. Instead, the inference network&#160;is simply used to define Lelegant approach, there is no need the inference network&#160;are adapted to increase L. This model is described in depth later, in Sec. 20.10.3.</span></p>
<p><span class="font64">Using approximate inference, it is possible to train and use a wide variety of models. Many of these models are described in the next chapter.</span></p>
</body>
</html>