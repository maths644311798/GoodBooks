<?xml version="1.0" encoding="UTF-8"?>

<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta name="charset" content="UTF-8"/><title></title><link rel="stylesheet" href="main.css" type="text/css"/>
</head>
<body><h2><span class="font66" style="font-weight:bold;">Chapter 16</span></h2><h2><a id="bookmark0"></a><span class="font67" style="font-weight:bold;">Structured Probabilistic Models for Deep Learning</span></h2>
<p><span class="font64">Deep learning draws upon many modeling formalisms that researchers can use to guide their design efforts and describe their algorithms. One of these formalisms is&#160;the idea of </span><span class="font64" style="font-weight:bold;font-style:italic;">structured probabilistic models.</span><span class="font64"> We have already discussed structured&#160;probabilistic models briefly in Sec. 3.14. That brief presentation was sufficient to&#160;understand how to use structured probabilistic models as a language to describe&#160;some of the algorithms in Part II. Now, in Part III, structured probabilistic models&#160;are a key ingredient of many of the most important research topics in deep learning.&#160;In order to prepare to discuss these research ideas, this chapter describes structured&#160;probabilistic models in much greater detail. This chapter is intended to be self-contained; the reader does not need to review the earlier introduction before&#160;continuing with this chapter.</span></p>
<p><span class="font64">A structured probabilistic model is a way of describing a probability distribution, using a graph to describe which random variables in the probability distribution&#160;interact with each other directly. Here we use “graph” in the graph theory sense—a&#160;set of vertices connected to one another by a set of edges. Because the structure of&#160;the model is defined by a graph, these models are often also referred to as </span><span class="font64" style="font-weight:bold;font-style:italic;">graphical&#160;models.</span></p>
<p><span class="font64">The graphical models research community is large and has developed many different models, training algorithms, and inference algorithms. In this chapter, we&#160;provide basic background on some of the most central ideas of graphical models,&#160;with an emphasis on the concepts that have proven most useful to the deep learning&#160;research community. If you already have a strong background in graphical models,&#160;you may wish to skip most of this chapter. However, even a graphical model expert&#160;may benefit from reading the final section of this chapter, Sec. 16.7, in which we&#160;highlight some of the unique ways that graphical models are used for deep learning&#160;algorithms. Deep learning practitioners tend to use very different model structures,&#160;learning algorithms and inference procedures than are commonly used by the rest&#160;of the graphical models research community. In this chapter, we identify these&#160;differences in preferences and explain the reasons for them.</span></p>
<p><span class="font64">In this chapter we first describe the challenges of building large-scale probabilistic models. Next, we describe how to use a graph to describe the structure of a probability distribution. While this approach allows us to overcome many&#160;challenges, it is not without its own complications. One of the major difficulties in&#160;graphical modeling is understanding which variables need to be able to interact&#160;directly, i.e., which graph structures are most suitable for a given problem. We&#160;outline two approaches to resolving this difficulty by learning about the dependencies in Sec. 16.5. Finally, we close with a discussion of the unique emphasis that&#160;deep learning practitioners place on specific approaches to graphical modeling in&#160;Sec. 16.7.</span></p><h4><a id="bookmark1"></a><span class="font65" style="font-weight:bold;">16.1 The Challenge of Unstructured Modeling</span></h4>
<p><span class="font64">The goal of deep learning is to scale machine learning to the kinds of challenges needed to solve artificial intelligence. This means being able to understand highdimensional data with rich structure. For example, we would like AI algorithms to&#160;be able to understand natural images,<a id="footnote1"></a><sup><a href="#bookmark2">1</a></sup><sup></sup> audio waveforms representing speech, and&#160;documents containing multiple words and punctuation characters.</span></p>
<p><span class="font64">Classification algorithms can take an input from such a rich high-dimensional distribution and summarize it with a categorical label—what object is in a photo,&#160;what word is spoken in a recording, what topic a document is about. The process&#160;of classification discards most of the information in the input and produces a&#160;single output (or a probability distribution over values of that single output). The&#160;classifier is also often able to ignore many parts of the input. For example, when&#160;recognizing an object in a photo, it is usually possible to ignore the background of&#160;the photo.</span></p>
<p><span class="font64">It is possible to ask probabilistic models to do many other tasks. These tasks are often more expensive than classification. Some of them require producing multiple&#160;output values. Most require a complete understanding of the entire structure of</span></p>
<p><span class="font64">the input, with no option to ignore sections of it. These tasks include the following:</span></p>
<p><span class="font64">• &#160;&#160;&#160;Density estimation: given an input x, the machine learning system returns an&#160;estimate of the true density p(x) under the data generating distribution. This&#160;requires only a single output, but it does require a complete understanding&#160;of the entire input. If even one element of the vector is unusual, the system&#160;must assign it a low probability.</span></p>
<p><span class="font64">• &#160;&#160;&#160;Denoising: given a damaged or incorrectly observed input </span><span class="font63" style="font-style:italic;">X</span><span class="font64">, the machine&#160;learning system returns an estimate of the original or correct x. For example,&#160;the machine learning system might be asked to remove dust or scratches&#160;from an old photograph. This requires multiple outputs (every element of the&#160;estimated clean example x) and an understanding of the entire input (since&#160;even one damaged area will still reveal the final estimate as being damaged).</span></p>
<p><span class="font64">• &#160;&#160;&#160;Missing value imputation: given the observations of some elements of x,&#160;the model is asked to return estimates of or a probability distribution over&#160;some or all of the unobserved elements of x. This requires multiple outputs.&#160;Because the model could be asked to restore any of the elements of x, it&#160;must understand the entire input.</span></p>
<p><span class="font64">• &#160;&#160;&#160;Sampling: the model generates new samples from the distribution </span><span class="font63" style="font-style:italic;">p(x).&#160;</span><span class="font64">Applications include speech synthesis, i.e. producing new waveforms that&#160;sound like natural human speech. This requires multiple output values and a&#160;good model of the entire input. If the samples have even one element drawn&#160;from the wrong distribution, then the sampling process is wrong.</span></p>
<p><span class="font64">For an example of a sampling task using small natural images, see Fig. 16.1.</span></p>
<p><span class="font64">Modeling a rich distribution over thousands or millions of random variables is a challenging task, both computationally and statistically. Suppose we only wanted&#160;to model binary variables. This is the simplest possible case, and yet already it&#160;seems overwhelming. For a small, 32 x 32 pixel color (RGB) image, there are 2<sup>3072&#160;</sup>possible binary images of this form. This number is over 10<sup>800</sup> times larger than&#160;the estimated number of atoms in the universe.</span></p>
<p><span class="font64">In general, if we wish to model a distribution over a random vector x containing n discrete variables capable of taking on k values each, then the naive approach of&#160;representing </span><span class="font63" style="font-style:italic;">P (x)</span><span class="font64"> by storing a lookup table with one probability value per possible&#160;outcome requires k<sup>n</sup> parameters!</span></p>
<p><span class="font64">This is not feasible for several reasons:</span></p><div>
<table border="1">
<tr><td>
<p dir="rtl"><span class="font65">■׳</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p><span class="font65" style="font-weight:bold;font-style:italic;">K</span></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font65" style="font-weight:bold;font-style:italic;">y</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p><span class="font66" style="font-weight:bold;">V</span></p></td><td>
<p><span class="font65">1 *5</span></p></td><td>
<p></p></td></tr>
<tr><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:middle;">
<p><span class="font65" style="font-weight:bold;font-style:italic;">r</span><span class="font65"> ן</span></p></td><td>
<p></p></td><td style="vertical-align:middle;">
<p><span class="font63">w.</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td></tr>
<tr><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font65">«u-*</span></p></td></tr>
<tr><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font65">&lt;5</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:middle;">
<p><span class="font65">1</span></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:middle;">
<p><span class="font65">▼</span></p></td><td>
<p></p></td><td style="vertical-align:middle;">
<p><span class="font65" style="font-weight:bold;font-style:italic;">It*</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font65">*</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p dir="rtl"><span class="font65" style="font-weight:bold;font-style:italic;">ב</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font65" style="font-weight:bold;font-style:italic;">t</span><span class="font65">.</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font65">*■e</span></p></td><td>
<p></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font63">—</span></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font63" style="font-style:italic;">m</span></p>
<p dir="rtl"><span class="font63">•יי * </span><span class="font65" style="font-weight:bold;font-style:italic;">'</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:middle;">
<p><span class="font65" style="font-weight:bold;font-style:italic;">׳•A*</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:bottom;">
<p><span class="font63">jj</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td></tr>
<tr><td>
<p dir="rtl"><span class="font65">ודיו</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td style="vertical-align:middle;">
<p><span class="font65" style="font-weight:bold;font-style:italic;">&amp;</span></p></td><td style="vertical-align:middle;">
<p dir="rtl"><span class="font65">ד־•*.</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font65">\</span></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td><td>
<p></p></td></tr>
</table></div><div><div><img src="main-163.jpg" alt=""/>
<p><span class="font64">Figure 16.1: Probabilistic modeling of natural images. </span><span class="font64" style="font-style:italic;">(Top)</span><span class="font64"> Example 32x 32 pixel color images from the CIFAR-10 dataset (Krizhevsky and Hinton, 2009). </span><span class="font64" style="font-style:italic;">(Bottom)</span><span class="font64"> Samples&#160;drawn from a structured probabilistic model trained on this dataset. Each sample appears&#160;at the same position in the grid as the training example that is closest to it in Euclidean&#160;space. This comparison allows us to see that the model is truly synthesizing new images,&#160;rather than memorizing the training data. Contrast of both sets of images has been&#160;adjusted for display. Figure reproduced with permission from Courville </span><span class="font64" style="font-style:italic;">et al.</span><span class="font64"> (2011).</span></p></div></div>
<p><span class="font31" style="font-style:italic;">•</span><span class="font64" style="font-weight:bold;"> &#160;&#160;&#160;Memory: the cost of storing the representation</span><span class="font64">: For all but very&#160;small values of n and k, representing the distribution as a table will require&#160;too many values to store.</span></p>
<p><span class="font64">•</span><span class="font64" style="font-weight:bold;"> &#160;&#160;&#160;Statistical efficiency</span><span class="font64">: As the number of parameters in a model increases,&#160;so does the amount of training data needed to choose the values of those&#160;parameters using a statistical estimator. Because the table-based model&#160;has an astronomical number of parameters, it will require an astronomically&#160;large training set to fit accurately. Any such model will overfit the training&#160;set very badly unless additional assumptions are made linking the different&#160;entries in the table (for example, like in back-off or smoothed n-gram models,&#160;Sec. 12.4.1).</span></p>
<p><span class="font64">•</span><span class="font64" style="font-weight:bold;"> &#160;&#160;&#160;Runtime: the cost of inference</span><span class="font64">: Suppose we want to perform an inference&#160;task where we use our model of the joint distribution P(x) to compute some&#160;other distribution, such as the marginal distribution P(x!) or the conditional&#160;distribution P(x</span><span class="font18">2</span><span class="font64"> | x!). Computing these distributions will require summing&#160;across the entire table, so the runtime of these operations is as high as the&#160;intractable memory cost of storing the model.</span></p>
<p><span class="font64">•</span><span class="font64" style="font-weight:bold;"> &#160;&#160;&#160;Runtime: the cost of sampling</span><span class="font64">: Likewise, suppose we want to draw a&#160;sample from the model. The naive way to do this is to sample some value&#160;u ~ </span><span class="font64" style="font-weight:bold;font-style:italic;">U</span><span class="font64">(</span><span class="font18">0</span><span class="font64">,</span><span class="font18">1</span><span class="font64">), then iterate through the table adding up the probability values&#160;until they exceed u and return the outcome whose probability value was&#160;added last. This requires reading through the whole table in the worst case,&#160;so it has the same exponential cost as the other operations.</span></p>
<p><span class="font64">The problem with the table-based approach is that we are explicitly modeling every possible kind of interaction between every possible subset of variables. The&#160;probability distributions we encounter in real tasks are much simpler than this.&#160;Usually, most variables influence each other only indirectly.</span></p>
<p><span class="font64">For example, consider modeling the finishing times of a team in a relay race. Suppose the team consists of three runners: Alice, Bob and Carol. At the start of&#160;the race, Alice carries a baton and begins running around a track. After completing&#160;her lap around the track, she hands the baton to Bob. Bob then runs his own&#160;lap and hands the baton to Carol, who runs the final lap. We can model each of&#160;their finishing times as a continuous random variable. Alice’s finishing time does&#160;not depend on anyone else’s, since she goes first. Bob’s finishing time depends&#160;on Alice’s, because Bob does not have the opportunity to start his lap until Alice&#160;has completed hers. If Alice finishes faster, Bob will finish faster, all else being&#160;equal. Finally, Carol’s finishing time depends on both her teammates. If Alice is&#160;slow, Bob will probably finish late too. As a consequence, Carol will have quite a&#160;late starting time and thus is likely to have a late finishing time as well. However,&#160;Carol’s finishing time depends only </span><span class="font64" style="font-weight:bold;font-style:italic;">indirectly</span><span class="font64"> on Alice’s finishing time via Bob’s.&#160;If we already know Bob’s finishing time, we will not be able to estimate Carol’s&#160;finishing time better by finding out what Alice’s finishing time was. This means&#160;we can model the relay race using only two interactions: Alice’s effect on Bob and&#160;Bob’s effect on Carol. We can omit the third, indirect interaction between Alice&#160;and Carol from our model.</span></p>
<p><span class="font64">Structured probabilistic models provide a formal framework for modeling only direct interactions between random variables. This allows the models to have&#160;significantly fewer parameters which can in turn be estimated reliably from less&#160;data. These smaller models also have dramatically reduced computational cost&#160;in terms of storing the model, performing inference in the model, and drawing&#160;samples from the model.</span></p><h4><a id="bookmark3"></a><span class="font65" style="font-weight:bold;">16.2 Using Graphs to Describe Model Structure</span></h4>
<p><span class="font64">Structured probabilistic models use graphs (in the graph theory sense of “nodes” or “vertices” connected by edges) to represent interactions between random variables.&#160;Each node represents a random variable. Each edge represents a direct interaction.&#160;These direct interactions imply other, indirect interactions, but only the direct&#160;interactions need to be explicitly modeled.</span></p>
<p><span class="font64">There is more than one way to describe the interactions in a probability distribution using a graph. In the following sections we describe some of the most&#160;popular and useful approaches. Graphical models can be largely divided into&#160;two categories: models based on directed acyclic graphs, and models based on&#160;undirected graphs.</span></p><h5><a id="bookmark4"></a><span class="font64" style="font-weight:bold;">16.2.1 Directed Models</span></h5>
<p><span class="font64">One kind of structured probabilistic model is the </span><span class="font64" style="font-weight:bold;font-style:italic;">directed graphical model,</span><span class="font64"> otherwise known as the </span><span class="font64" style="font-weight:bold;font-style:italic;">belief network</span><span class="font64"> or </span><span class="font64" style="font-weight:bold;font-style:italic;">Bayesian network<a id="footnote2"></a><sup><a href="#bookmark5">2</a></sup></span><span class="font18"><sup></sup></span><span class="font64"> (Pearl, 1985).</span></p>
<p><span class="font64">Directed graphical models are called “directed” because their edges are directed,</span></p><div>
<p><span class="font63">Alice &#160;&#160;&#160;Bob&#160;&#160;&#160;&#160;Carol</span></p><img src="main-164.jpg" alt=""/></div>
<p><span class="font64">Figure 16.2: A directed graphical model depicting the relay race example. Alice’s finishing time to influences Bob’s finishing time t</span><span class="font19">1</span><span class="font64">, because Bob does not get to start running until&#160;Alice finishes. Likewise, Carol only gets to start running after Bob finishes, so Bob’s&#160;finishing time t! directly influences Carol’s finishing time t</span><span class="font19">2</span><span class="font64">-that is, they point from one vertex to another. This direction is represented in&#160;the drawing with an arrow. The direction of the arrow indicates which variable’s&#160;probability distribution is defined in terms of the other’s. Drawing an arrow from&#160;a to b means that we define the probability distribution over b via a conditional&#160;distribution, with a as one of the variables on the right side of the conditioning&#160;bar. In other words, the distribution over b depends on the value of a.</span></p>
<p><span class="font64">Continuing with the relay race example from Sec. 16.1, suppose we name Alice’s finishing time to, Bob’s finishing time t!, and Carol’s finishing time t</span><span class="font18">2</span><span class="font64">. As we saw&#160;earlier, our estimate of t! depends on to. Our estimate of t</span><span class="font18">2</span><span class="font64"> depends directly on t!&#160;but only indirectly on to. We can draw this relationship in a directed graphical&#160;model, illustrated in Fig. 16.2.</span></p>
<p><span class="font64">Formally, a directed graphical model defined on variables x is defined by a directed acyclic graph G whose vertices are the random variables in the model, and&#160;a set of </span><span class="font63" style="font-style:italic;">local conditional probability distributions</span><span class="font64"> p(x^ | </span><span class="font64" style="font-weight:bold;font-style:italic;">Pa</span><span class="font63" style="font-style:italic;">g</span><span class="font64">(x^) where </span><span class="font64" style="font-weight:bold;font-style:italic;">Pa</span><span class="font63" style="font-style:italic;">g</span><span class="font64">(x^)&#160;gives the parents of x<sub>i</sub> in G. The probability distribution over x is given by</span></p>
<p><span class="font64">p(x) = n</span><span class="font64" style="font-weight:bold;font-style:italic;">ip(xi</span><span class="font64"> | </span><span class="font64" style="font-weight:bold;font-style:italic;">Pag(xi)).</span><span class="font64"> &#160;&#160;&#160;(16.1)</span></p>
<p><span class="font64">In our relay race example, this means that, using the graph drawn in Fig. 16.2, p(t</span><span class="font18">0</span><span class="font64">, t</span><span class="font18">1</span><span class="font64">, t</span><span class="font18">2</span><span class="font64">) = p(t</span><span class="font18">0</span><span class="font64">)p(t! | t</span><span class="font18">0</span><span class="font64">)p(t</span><span class="font18">2</span><span class="font64"> | t!).&#160;&#160;&#160;&#160;(16.2)</span></p>
<p><span class="font64">This is our first time seeing a structured probabilistic model in action. We can examine the cost of using it, in order to observe how structured modeling has&#160;many advantages relative to unstructured modeling.</span></p>
<p><span class="font64">Suppose we represented time by discretizing time ranging from minute 0 to minute 10 into </span><span class="font18">6</span><span class="font64"> second chunks. This would make to, t! and t</span><span class="font18">2</span><span class="font64"> each be discrete&#160;variables with 100 possible values. If we attempted to represent p(t</span><span class="font18">0</span><span class="font64">, t!, t</span><span class="font18">2</span><span class="font64">) with a&#160;table, it would need to store 999,999 values (100 values of to x 100 values oft </span><span class="font18"><sub>1</sub></span><span class="font64"> x&#160;</span><span class="font18">100</span><span class="font64"> values of t</span><span class="font18">2</span><span class="font64">, minus </span><span class="font18">1</span><span class="font64">, since the probability of one of the configurations is made&#160;redundant by the constraint that the sum of the probabilities be 1). If instead, we&#160;only make a table for each of the conditional probability distributions, then the&#160;distribution over to requires 99 values, the table defining t! given to requires 9900&#160;values, and so does the table defining t</span><span class="font18"><sub>2</sub></span><span class="font64"> given t<sub>1</sub>. This comes to a total of 19,899&#160;values. This means that using the directed graphical model reduced our number of&#160;parameters by a factor of more than 50!</span></p>
<p><span class="font64">In general, to model n discrete variables each having k values, the cost of the single table approach scales like </span><span class="font64" style="font-weight:bold;font-style:italic;">O(k<sup>n</sup>),</span><span class="font64"> as we have observed before. Now suppose&#160;we build a directed graphical model over these variables. If m is the maximum&#160;number of variables appearing (on either side of the conditioning bar) in a single&#160;conditional probability distribution, then the cost of the tables for the directed&#160;model scales like O(</span><span class="font64" style="font-weight:bold;font-style:italic;">k</span><span class="font64"><sup>m</sup>). As long as we can design a model such that m &lt;&lt; n, we&#160;get very dramatic savings.</span></p>
<p><span class="font64">In other words, so long as each variable has few parents in the graph, the distribution can be represented with very few parameters. Some restrictions on&#160;the graph structure, such as requiring it to be a tree, can also guarantee that&#160;operations like computing marginal or conditional distributions over subsets of&#160;variables are efficient.</span></p>
<p><span class="font64">It is important to realize what kinds of information can and cannot be encoded in the graph. The graph encodes only simplifying assumptions about which variables&#160;are conditionally independent from each other. It is also possible to make other&#160;kinds of simplifying assumptions. For example, suppose we assume Bob always&#160;runs the same regardless of how Alice performed. (In reality, Alice’s performance&#160;probably influences Bob’s performance—depending on Bob’s personality, if Alice&#160;runs especially fast in a given race, this might encourage Bob to push hard and&#160;match her exceptional performance, or it might make him overconfident and lazy).&#160;Then the only effect Alice has on Bob’s finishing time is that we must add Alice’s&#160;finishing time to the total amount of time we think Bob needs to run. This&#160;observation allows us to define a model with O(k) parameters instead of O(k<sup>2</sup>).&#160;However, note that to and t! are still directly dependent with this assumption,&#160;because t! represents the absolute time at which Bob finishes, not the total time&#160;he himself spends running. This means our graph must still contain an arrow from&#160;to to t!. The assumption that Bob’s personal running time is independent from&#160;all other factors cannot be encoded in a graph over to, t!, and t</span><span class="font18">2</span><span class="font64">. Instead, we&#160;encode this information in the definition of the conditional distribution itself. The&#160;conditional distribution is no longer a k x k — </span><span class="font18">1</span><span class="font64"> element table indexed by to and t!&#160;but is now a slightly more complicated formula using only k — </span><span class="font18">1</span><span class="font64"> parameters. The&#160;directed graphical model syntax does not place any constraint on how we define&#160;our conditional distributions. It only defines which variables they are allowed to&#160;take in as arguments.</span></p><h5><a id="bookmark6"></a><span class="font64" style="font-weight:bold;">16.2.2 Undirected Models</span></h5>
<p><span class="font64">Directed graphical models give us one language for describing structured probabilistic models. Another popular language is that of </span><span class="font64" style="font-weight:bold;font-style:italic;">undirected models</span><span class="font64">, otherwise known as </span><span class="font64" style="font-weight:bold;font-style:italic;">Markov random fields</span><span class="font64"> (MRFs) or </span><span class="font64" style="font-weight:bold;font-style:italic;">Markov networks</span><span class="font64"> (Kindermann, 1980).&#160;As their name implies, undirected models use graphs whose edges are undirected.</span></p>
<p><span class="font64">Directed models are most naturally applicable to situations where there is a clear reason to draw each arrow in one particular direction. Often these are&#160;situations where we understand the causality and the causality only flows in one&#160;direction. One such situation is the relay race example. Earlier runners affect the&#160;finishing times of later runners; later runners do not affect the finishing times of&#160;earlier runners.</span></p>
<p><span class="font64">Not all situations we might want to model have such a clear direction to their interactions. When the interactions seem to have no intrinsic direction, or to&#160;operate in both directions, it may be more appropriate to use an undirected model.</span></p>
<p><span class="font64">As an example of such a situation, suppose we want to model a distribution over three binary variables: whether or not you are sick, whether or not your&#160;coworker is sick, and whether or not your roommate is sick. As in the relay race&#160;example, we can make simplifying assumptions about the kinds of interactions&#160;that take place. Assuming that your coworker and your roommate do not know&#160;each other, it is very unlikely that one of them will give the other a disease such as&#160;a cold directly. This event can be seen as so rare that it is acceptable not to model&#160;it. However, it is reasonably likely that either of them could give you a cold, and&#160;that you could pass it on to the other. We can model the indirect transmission of&#160;a cold from your coworker to your roommate by modeling the transmission of the&#160;cold from your coworker to you and the transmission of the cold from you to your&#160;roommate.</span></p>
<p><span class="font64">In this case, it is just as easy for you to cause your roommate to get sick as it is for your roommate to make you sick, so there is not a clean, uni-directional&#160;narrative on which to base the model. This motivates using an undirected model.&#160;As with directed models, if two nodes in an undirected model are connected by an&#160;edge, then the random variables corresponding to those nodes interact with each&#160;other directly. Unlike directed models, the edge in an undirected model has no&#160;arrow, and is not associated with a conditional probability distribution.</span></p>
<p><span class="font64">We denote the random variable representing your health as </span><span class="font64" style="font-weight:bold;font-style:italic;">h</span><span class="font64"><sub>y</sub>, the random</span></p>
<p dir="rtl"><span class="font67" style="font-weight:bold;">©־&amp;)־&amp;</span></p>
<p><span class="font64">Figure 16.3: An undirected graph representing how your roommate’s health h<sub>r</sub>, your health h<sub>y</sub>, and your work colleague’s health h <sub>c</sub> affect each other. You and your roommate&#160;might infect each other with a cold, and you and your work colleague might do the same,&#160;but assuming that your roommate and your colleague do not know each other, they can&#160;only infect each other indirectly via you.</span></p>
<p><span class="font64">variable representing your roommate’s health as h<sub>r</sub>, and the random variable representing your colleague’s health as h<sub>c</sub>. See Fig. 16.3 for a drawing of the graph&#160;representing this scenario.</span></p>
<p><span class="font64">Formally, an undirected graphical model is a structured probabilistic model defined on an undirected graph Q. For each clique C in the graph,<a id="footnote3"></a><sup><a href="#bookmark7">3</a></sup><sup></sup> a </span><span class="font63" style="font-style:italic;">factor rf&gt;(C)&#160;</span><span class="font64">(also called a </span><span class="font63" style="font-style:italic;">clique potential)</span><span class="font64"> measures the affinity of the variables in that clique&#160;for being in each of their possible joint states. The factors are constrained to be&#160;non-negative. Together they define an </span><span class="font63" style="font-style:italic;">unnormalized probability distribution</span></p><div>
<p><span class="font64">(16.3)</span></p></div>
<p><span class="font64"><sup>p(x)</sup> = <sup>n</sup>ceG </span><span class="font18">0</span><span class="font64">(C).</span></p>
<p><span class="font64">The unnormalized probability distribution is efficient to work with so long as all the cliques are small. It encodes the idea that states with higher affinity are&#160;more likely. However, unlike in a Bayesian network, there is little structure to the&#160;definition of the cliques, so there is nothing to guarantee that multiplying them&#160;together will yield a valid probability distribution. See Fig. 16.4 for an example of&#160;reading factorization information from an undirected graph.</span></p>
<p><span class="font64">Our example of the cold spreading between you, your roommate, and your colleague contains two cliques. One clique contains h<sub>y</sub> and The factor for this&#160;clique can be defined by a table, and might have values resembling these:</span></p>
<table border="1">
<tr><td>
<p></p></td><td>
<p></p></td><td>
<p><span class="font64">o</span></p>
<p><span class="font64">II</span></p></td><td style="vertical-align:bottom;">
<p><span class="font64"><sup>h</sup>y = </span><span class="font18"><sup>1</sup></span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font64"><sup>h</sup>c</span></p></td><td style="vertical-align:middle;">
<p><span class="font64">= </span><span class="font18">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font18">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font18">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font64">h<sub>c</sub></span></p></td><td style="vertical-align:middle;">
<p><span class="font64">= </span><span class="font18">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font18">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font18">10</span></p></td></tr>
</table>
<p><span class="font64">A state of 1 indicates good health, while a state of 0 indicates poor health (having been infected with a cold). Both of you are usually healthy, so the</span></p>
<p><span class="font64">corresponding state has the highest affinity. The state where only one of you is sick has the lowest affinity, because this is a rare state. The state where both of&#160;you are sick (because one of you has infected the other) is a higher affinity state,&#160;though still not as common as the state where both are healthy.</span></p>
<p><span class="font64">To complete the model, we would need to also define a similar factor for the clique containing h<sub>y</sub> and h<sub>r</sub></span></p><h5><a id="bookmark8"></a><span class="font64" style="font-weight:bold;">16.2.3 The Partition Function</span></h5>
<p><span class="font64">While the unnormalized probability distribution is guaranteed to be non-negative everywhere, it is not guaranteed to sum or integrate to 1. To obtain a valid&#160;probability distribution, we must use the corresponding normalized probability&#160;distribution</span><span class="font18">:<a id="footnote4"></a><sup><a href="#bookmark9">4</a></sup><sup> <a id="footnote5"></a><a href="#bookmark10">5</a></sup></span></p>
<p><span class="font18">1</span></p>
<p><span class="font64">P<sup>(x)</sup> = </span><span class="font64" style="font-weight:bold;font-style:italic;">—p</span><span class="font64">(x) &#160;&#160;&#160;(1</span><span class="font18"><sup>6</sup></span><span class="font64">.4)</span></p>
<p><span class="font64">where — is the value that results in the probability distribution summing or integrating to </span><span class="font18">1</span><span class="font64">:</span></p>
<p><span class="font64">— = </span><span class="font64" style="font-weight:bold;font-style:italic;">I p(x)dx.</span><span class="font64"> &#160;&#160;&#160;(16.5)</span></p>
<p><span class="font64">You can think of — as a constant when the ^ functions are held constant. Note that if the ^ functions have parameters, then — is a function of those parameters.&#160;It is common in the literature to write — with its arguments omitted to save space.&#160;The normalizing constant — is known as the </span><span class="font64" style="font-weight:bold;font-style:italic;">partition function,</span><span class="font64"> a term borrowed&#160;from statistical physics.</span></p>
<p><span class="font64">Since — is an integral or sum over all possible joint assignments of the state x it is often intractable to compute. In order to be able to obtain the normalized&#160;probability distribution of an undirected model, the model structure and the&#160;definitions of the ^ functions must be conducive to computing — efficiently. In&#160;the context of deep learning, — is usually intractable. Due to the intractability&#160;of computing — exactly, we must resort to approximations. Such approximate&#160;algorithms are the topic of Chapter 18.</span></p>
<p><span class="font64">One important consideration to keep in mind when designing undirected models is that it is possible to specify the factors in such a way that — does not exist.&#160;This happens if some of the variables in the model are continuous and the integral&#160;of </span><span class="font64" style="font-weight:bold;font-style:italic;">p</span><span class="font64"> over their domain diverges. For example, suppose we want to model a single&#160;scalar variable x G R with a single clique potential </span><span class="font64" style="font-weight:bold;font-style:italic;">$(x) = x<sup>2</sup>.</span><span class="font64"> In this case,</span></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">Z = J</span><span class="font64"> x</span><span class="font18"><sup>2</sup></span><span class="font64">dx. &#160;&#160;&#160;(16.6)</span></p>
<p><span class="font64">Since this integral diverges, there is no probability distribution corresponding to this choice of ^ (x). Sometimes the choice of some parameter of the ^ functions&#160;determines whether the probability distribution is defined. For example, for&#160;^&gt;(x; fi) = exp </span><span class="font64" style="font-weight:bold;font-style:italic;">(-fix</span><span class="font64"><sup>2</sup>), the fi parameter determines whether Z exists. Positive fi&#160;results in a Gaussian distribution over x but all other values offi make ^ impossible&#160;to normalize.</span></p>
<p><span class="font64">One key difference between directed modeling and undirected modeling is that directed models are defined directly in terms of probability distributions from&#160;the start, while undirected models are defined more loosely by ^ functions that&#160;are then converted into probability distributions. This changes the intuitions one&#160;must develop in order to work with these models. One key idea to keep in mind&#160;while working with undirected models is that the domain of each of the variables&#160;has dramatic effect on the kind of probability distribution that a given set of ^&#160;functions corresponds to. For example, consider an n-dimensional vector-valued&#160;random variable x and an undirected model parametrized by a vector of biases&#160;b. Suppose we have one clique for each element of x, ^<sup>(i)</sup>(x^) =exp(b^). What&#160;kind of probability distribution does this result in? The answer is that we do&#160;not have enough information, because we have not yet specified the domain of x.&#160;If x G R<sup>n</sup>, then the integral defining Z diverges and no probability distribution&#160;exists. If x G {0,1}<sup>n</sup>, then </span><span class="font64" style="font-weight:bold;font-style:italic;">p(x</span><span class="font64">) factorizes into n independent distributions, with&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">p(xi =</span><span class="font64"> 1) = sigmoid </span><span class="font64" style="font-weight:bold;font-style:italic;">(bi</span><span class="font64">). If the domain of x is the set of elementary basis vectors&#160;({[</span><span class="font18">1</span><span class="font64">, </span><span class="font18">0</span><span class="font64">,..., </span><span class="font18">0</span><span class="font64">], [</span><span class="font18">0</span><span class="font64">,</span><span class="font18">1</span><span class="font64">,..., </span><span class="font18">0</span><span class="font64">],..., [</span><span class="font18">0</span><span class="font64">,</span><span class="font18">0</span><span class="font64">,..., </span><span class="font18">1</span><span class="font64">]} ) then </span><span class="font64" style="font-weight:bold;font-style:italic;">p(x) =</span><span class="font64"> softmax(b), so a large&#160;value of bi actually reduces p(xj = 1) for j = i. Often, it is possible to leverage&#160;the effect of a carefully chosen domain of a variable in order to obtain complicated&#160;behavior from a relatively simple set of ^ functions. We will explore a practical&#160;application of this idea later, in Sec. 20.6.</span></p><h5><a id="bookmark11"></a><span class="font64" style="font-weight:bold;">16.2.4 Energy-Based Models</span></h5>
<p><span class="font64">Many interesting theoretical results about undirected models depend on the assumption that Vx,p(x) &gt; 0. A convenient way to enforce this condition is to use an </span><span class="font64" style="font-weight:bold;font-style:italic;">energy-based model</span><span class="font64"> (EBM) where</span></p>
<p><span class="font64">p(x) = exp(-E (x)) &#160;&#160;&#160;(16.7)</span></p>
<p><span class="font64">and E (x) is known as the </span><span class="font64" style="font-weight:bold;font-style:italic;">energy function.</span><span class="font64"> Because exp(z) is positive for all z, this guarantees that no energy function will result in a probability of zero for any state x.</span></p><div><img src="main-165.jpg" alt=""/>
<p><span class="font64">Figure 16.4: &#160;&#160;&#160;This graph implies that p(a, b, c, d, e, f) can be written as</span></p>
<p><span class="font64">Z ^<sub>a</sub>,b(a, b</span><span class="font64" style="font-style:italic;">)$</span><span class="font64">b,<sub>c</sub>(b, c)^<sub>a</sub>,d(a, d)^b,<sub>e</sub>(b, e)^<sub>e</sub>,f(e, f) for an appropriate choice of the ^ functions.</span></p></div>
<p><span class="font64">Being completely free to choose the energy function makes learning simpler. If we learned the clique potentials directly, we would need to use constrained optimization&#160;to arbitrarily impose some specific minimal probability value. By learning the&#160;energy function, we can use unconstrained optimization</span><span class="font18">.<a id="footnote6"></a><sup><a href="#bookmark12">6</a></sup><sup></sup></span><span class="font64"> The probabilities in an&#160;energy-based model can approach arbitrarily close to zero but never reach it.</span></p>
<p><span class="font64">Any distribution of the form given by Eq. 16.7 is an example of a </span><span class="font63" style="font-style:italic;">Boltzmann distribution</span><span class="font64" style="font-weight:bold;font-style:italic;">.</span><span class="font64"> For this reason, many energy-based models are called </span><span class="font63" style="font-style:italic;">Boltzmann&#160;machines</span><span class="font64"> (Fahlman </span><span class="font63" style="font-style:italic;">et al.</span><span class="font64" style="font-weight:bold;font-style:italic;">,</span><span class="font64"> 1983; Ackley </span><span class="font63" style="font-style:italic;">et al.</span><span class="font64" style="font-weight:bold;font-style:italic;">,</span><span class="font64"> 1985; Hinton </span><span class="font63" style="font-style:italic;">et al.</span><span class="font64" style="font-weight:bold;font-style:italic;">,</span><span class="font64"> 1984; Hinton&#160;and Sejnowski, 1986). There is no accepted guideline for when to call a model an&#160;energy-based model and when to call it a Boltzmann machine. The term Boltzmann&#160;machine was first introduced to describe a model with exclusively binary variables,&#160;but today many models such as the mean-covariance restricted Boltzmann machine&#160;incorporate real-valued variables as well. While Boltzmann machines were originally&#160;defined to encompass both models with and without latent variables, the term&#160;Boltzmann machine is today most often used to designate models with latent&#160;variables, while Boltzmann machines without latent variables are more often called&#160;Markov random fields or log-linear models.</span></p>
<p><span class="font64">Cliques in an undirected graph correspond to factors of the unnormalized probability function. Because exp(a) exp( b) = exp(a + </span><span class="font63" style="font-style:italic;">b)</span><span class="font64" style="font-weight:bold;font-style:italic;">,</span><span class="font64"> this means that different&#160;cliques in the undirected graph correspond to the different terms of the energy&#160;function. In other words, an energy-based model is just a special kind of Markov&#160;network: the exponentiation makes each term in the energy function correspond&#160;to a factor for a different clique. See Fig. 16.5 for an example of how to read the&#160;form of the energy function from an undirected graph structure. One can view an&#160;energy-based model with multiple terms in its energy function as being a </span><span class="font63" style="font-style:italic;">product&#160;of experts</span><span class="font64"> (Hinton, 1999). Each term in the energy function corresponds to another&#160;factor in the probability distribution. Each term of the energy function can be&#160;thought of as an “expert” that determines whether a particular soft constraint&#160;is satisfied. Each expert may enforce only one constraint that concerns only&#160;a low-dimensional projection of the random variables, but when combined by&#160;multiplication of probabilities, the experts together enforce a complicated highdimensional constraint.</span></p>
<p><span class="font64">One part of the definition of an energy-based model serves no functional purpose from a machine learning point of view: the — sign in Eq. 16.7. This&#160;— sign could be incorporated into the definition of E, or for many functions E&#160;the learning algorithm could simply learn parameters with opposite sign. The —&#160;sign is present primarily to preserve compatibility between the machine learning&#160;literature and the physics literature. Many advances in probabilistic modeling&#160;were originally developed by statistical physicists, for whom E refers to actual,&#160;physical energy and does not have arbitrary sign. Terminology such as “energy”&#160;and “partition function” remains associated with these techniques, even though&#160;their mathematical applicability is broader than the physics context in which they&#160;were developed. Some machine learning researchers (e.g., Smolensky (1986), who&#160;referred to negative energy as </span><span class="font64" style="font-weight:bold;font-style:italic;">harmony)</span><span class="font64"> have chosen to emit the negation, but this&#160;is not the standard convention.</span></p>
<p><span class="font64">Many algorithms that operate on probabilistic models do not need to compute p<sub>mo</sub>d<sub>e</sub>i (x) but only log p<sub>mo</sub>d</span><span class="font18"><sub>e</sub>1</span><span class="font64">(x). For energy-based models with latent variables h,&#160;these algorithms are sometimes phrased in terms of the negative of this quantity,&#160;called the </span><span class="font64" style="font-weight:bold;font-style:italic;">free energy:</span></p><div>
<p><span class="font64">(16.8)</span></p></div><div><div><img src="main-166.jpg" alt=""/>
<p><span class="font64">Figure 16.5: This graph implies that E(a, b, c, d, e, f) can be written as E<sub>a</sub>,b (a, b) + Eb,<sub>c</sub>(b, c) + E<sub>a</sub>,d(a, d) + Eb,<sub>e</sub>(b, e) + E<sub>e</sub>,f(e, f) for an appropriate choice of the per-clique&#160;energy functions. Note that we can obtain the </span><span class="font64" style="font-style:italic;">$</span><span class="font64"> functions in Fig. 16.4 by setting each </span><span class="font64" style="font-style:italic;">$&#160;</span><span class="font64">to the exponential of the corresponding negative energy, e.g., ^<sub>a</sub>,b( a, b) = exp(-E (a, b)).</span></p></div></div>
<p><span class="font64" style="font-weight:bold;font-style:italic;">F</span><span class="font64">(x) = — log </span><span class="font18">5</span><span class="font64">־] exp (—E(x, h)).</span></p>
<p><span class="font64">h</span></p>
<p><span class="font64">In this book, we usually prefer the more general log p<sub>mo</sub>d<sub>e</sub>i(x) formulation.</span></p><div><img src="main-167.jpg" alt=""/>
<p><span class="font64">(a) &#160;&#160;&#160;(<sup>b</sup>)</span></p>
<p><span class="font64">Figure 16.6: (a) The path between random variablea and random variable b through s is active, because s is not observed. This means that a and b are not separated. (b) Here s&#160;is shaded in, to indicate that it is observed. Because the only path between a and b is&#160;through s, and that path is inactive, we can conclude that a and b are separated given s.</span></p></div><h5><a id="bookmark13"></a><span class="font64" style="font-weight:bold;">16.2.5 Separation and D-Separation</span></h5>
<p><span class="font64">The edges in a graphical model tell us which variables directly interact. We often need to know which variables </span><span class="font63" style="font-style:italic;">indirectly</span><span class="font64"> interact. Some of these indirect interactions&#160;can be enabled or disabled by observing other variables. More formally, we would&#160;like to know which subsets of variables are conditionally independent from each&#160;other, given the values of other subsets of variables.</span></p>
<p><span class="font64">Identifying the conditional independences in a graph is very simple in the case of undirected models. In this case, conditional independence implied by the graph&#160;is called </span><span class="font63" style="font-style:italic;">separation.</span><span class="font64"> We say that a set of variables A is </span><span class="font63" style="font-style:italic;">separated</span><span class="font64"> from another set&#160;of variables B given a third set of variables S if the graph structure implies that A&#160;is independent from B given S. If two variables a and b are connected by a path&#160;involving only unobserved variables, then those variables are not separated. If no&#160;path exists between them, or all paths contain an observed variable, then they are&#160;separated. We refer to paths involving only unobserved variables as “active” and&#160;paths including an observed variable as “inactive.”</span></p>
<p><span class="font64">When we draw a graph, we can indicate observed variables by shading them in. See Fig. 16.6 for a depiction of how active and inactive paths in an undirected&#160;model look when drawn in this way. See Fig. 16.7 for an example of reading&#160;separation from an undirected graph.</span></p>
<p><span class="font64">Similar concepts apply to directed models, except that in the context of directed models, these concepts are referred to as </span><span class="font63" style="font-style:italic;">d-separation.</span><span class="font64"> The “d” stands for&#160;“dependence.” D-separation for directed graphs is defined the same as separation&#160;for undirected graphs: We say that a set of variables A is d-separated from another&#160;set of variables B given a third set of variables S if the graph structure implies&#160;that A is independent from B given S.</span></p>
<p><span class="font64">As with undirected models, we can examine the independences implied by the graph by looking at what active paths exist in the graph. As before, two variables&#160;are dependent if there is an active path between them, and d-separated if no such</span></p><div><img src="main-168.jpg" alt=""/></div>
<p><span class="font64">Figure 16.7: An example of reading separation properties from an undirected graph. Here b is shaded to indicate that it is observed. Because observing b blocks the only path from&#160;a to c, we say that a and c are separated from each other given b. The observation of b&#160;also blocks one path between a and d, but there is a second, active path between them.&#160;Therefore, a and d are not separated given b.</span></p>
<p><span class="font64">path exists. In directed nets, determining whether a path is active is somewhat more complicated. See Fig. 16.8 for a guide to identifying active paths in a directed&#160;model. See Fig. 16.9 for an example of reading some properties from a graph.</span></p>
<p><span class="font64">It is important to remember that separation and d-separation tell us only about those conditional independences </span><span class="font64" style="font-weight:bold;">that are implied by the graph. </span><span class="font64">There is no&#160;requirement that the graph imply all independences that are present. In particular,&#160;it is always legitimate to use the complete graph (the graph with all possible edges)&#160;to represent any distribution. In fact, some distributions contain independences&#160;that are not possible to represent with existing graphical notation. </span><span class="font64" style="font-weight:bold;font-style:italic;">Context-specific&#160;independences</span><span class="font64"> are independences that are present dependent on the value of some&#160;variables in the network. For example, consider a model of three binary variables:&#160;a, b and c. Suppose that when a is 0, b and c are independent, but when a is 1, b&#160;is deterministically equal to c. Encoding the behavior when a = 1 requires an edge&#160;connecting b and c. The graph then fails to indicate that b and c are independent&#160;when a = </span><span class="font18">0</span><span class="font64">.</span></p>
<p><span class="font64">In general, a graph will never imply that an independence exists when it does not. However, a graph may fail to encode an independence.</span></p><h5><a id="bookmark14"></a><span class="font64" style="font-weight:bold;">16.2.6 Converting between Undirected and Directed Graphs</span></h5>
<p><span class="font64">We often refer to a specific machine learning model as being undirected or directed. For example, we typically refer to RBMs as undirected and sparse coding as directed.&#160;This choice of wording can be somewhat misleading, because no probabilistic&#160;model is inherently directed or undirected. Instead, some models are most easily&#160;</span><span class="font64" style="font-weight:bold;">described </span><span class="font64">using a directed graph, or most easily described using an undirected&#160;graph.</span></p><div><img src="main-169.jpg" alt=""/></div>
<p><span class="font64">Figure 16.8: All of the kinds of active paths of length two that can exist between random variables a and b. </span><span class="font64" style="font-style:italic;">(a)</span><span class="font64"> Any path with arrows proceeding directly from a to b or vice versa.&#160;This kind of path becomes blocked if s is observed. We have already seen this kind of&#160;path in the relay race example. </span><span class="font64" style="font-style:italic;">(b)</span><span class="font64"> a and b are connected by a </span><span class="font64" style="font-style:italic;">common cause</span><span class="font64"> s. For&#160;example, suppose s is a variable indicating whether or not there is a hurricane and a and&#160;b measure the wind speed at two different nearby weather monitoring outposts. If we&#160;observe very high winds at station a, we might expect to also see high winds at b. This&#160;kind of path can be blocked by observing s. If we already know there is a hurricane, we&#160;expect to see high winds at b, regardless of what is observed at a. A lower than expected&#160;wind at a (for a hurricane) would not change our expectation of winds at b (knowing&#160;there is a hurricane). However, if s is not observed, then a and b are dependent, i.e.,&#160;the path is active. </span><span class="font64" style="font-style:italic;">(c)</span><span class="font64"> a and b are both parents ofs. This is called a </span><span class="font64" style="font-style:italic;">V-structure</span><span class="font64"> or </span><span class="font64" style="font-style:italic;">the&#160;collider case.</span><span class="font64"> The V-structure causes a and b to be related by the </span><span class="font64" style="font-style:italic;">explaining away effect.&#160;</span><span class="font64">In this case, the path is actually active when s is observed. For example, suppose s is a&#160;variable indicating that your colleague is not at work. The variable a represents her being&#160;sick, while b represents her being on vacation. If you observe that she is not at work,&#160;you can presume she is probably sick or on vacation, but it is not especially likely that&#160;both have happened at the same time. If you find out that she is on vacation, this fact&#160;is sufficient to </span><span class="font64" style="font-style:italic;">explain</span><span class="font64"> her absence. You can infer that she is probably not also sick. </span><span class="font64" style="font-style:italic;">(d)&#160;</span><span class="font64">The explaining away effect happens even if any descendant of s is observed! For example,&#160;suppose that c is a variable representing whether you have received a report from your&#160;colleague. If you notice that you have not received the report, this increases your estimate&#160;of the probability that she is not at work today, which in turn makes it more likely that&#160;she is either sick or on vacation. The only way to block a path through a V-structure is&#160;to observe none of the descendants of the shared child.</span></p><div><img src="main-170.jpg" alt=""/></div>
<p><span class="font64">Figure 16.9: From this graph, we can read out several d-separation properties. Examples include:</span></p>
<p><span class="font64">• &#160;&#160;&#160;a and b are d-separated given the empty set.</span></p>
<p><span class="font64">• &#160;&#160;&#160;a and e are d-separated given c.</span></p>
<p><span class="font64">• &#160;&#160;&#160;d and e are d-separated given c.</span></p>
<p><span class="font64">We can also see that some variables are no longer d-separated when we observe some variables:</span></p>
<p><span class="font64">• &#160;&#160;&#160;a and b are not d-separated given c.</span></p>
<p><span class="font64">• &#160;&#160;&#160;a and b are not d-separated given d.</span></p><div><img src="main-171.jpg" alt=""/>
<p><span class="font64">Figure 16.10: Examples of complete graphs, which can describe any probability distribution. Here we show examples with four random variables. </span><span class="font64" style="font-style:italic;">(Left)</span><span class="font64"> The complete undirected graph.&#160;In the undirected case, the complete graph is unique. </span><span class="font64" style="font-style:italic;">(Right)</span><span class="font64"> A complete directed graph.&#160;In the directed case, there is not a unique complete graph. We choose an ordering of the&#160;variables and draw an arc from each variable to every variable that comes after it in the&#160;ordering. There are thus a factorial number of complete graphs for every set of random&#160;variables. In this example we order the variables from left to right, top to bottom.</span></p></div>
<p><span class="font64">Directed models and undirected models both have their advantages and disadvantages. Neither approach is clearly superior and universally preferred. Instead, we should choose which language to use for each task. This choice will partially&#160;depend on which probability distribution we wish to describe. We may choose to&#160;use either directed modeling or undirected modeling based on which approach can&#160;capture the most independences in the probability distribution or which approach&#160;uses the fewest edges to describe the distribution. There are other factors that&#160;can affect the decision of which language to use. Even while working with a single&#160;probability distribution, we may sometimes switch between different modeling&#160;languages. Sometimes a different language becomes more appropriate if we observe&#160;a certain subset of variables, or if we wish to perform a different computational&#160;task. For example, the directed model description often provides a straightforward&#160;approach to efficiently draw samples from the model (described in Sec. 16.3) while&#160;the undirected model formulation is often useful for deriving approximate inference&#160;procedures (as we will see in Chapter 19, where the role of undirected models is&#160;highlighted in Eq. 19.56).</span></p>
<p><span class="font64">Every probability distribution can be represented by either a directed model or by an undirected model. In the worst case, one can always represent any&#160;distribution by using a “complete graph.” In the case of a directed model, the&#160;complete graph is any directed acyclic graph where we impose some ordering on&#160;the random variables, and each variable has all other variables that precede it in&#160;the ordering as its ancestors in the graph. For an undirected model, the complete&#160;graph is simply a graph containing a single clique encompassing all of the variables.&#160;See Fig. 16.10 for an example.</span></p>
<p><span class="font64">Of course, the utility of a graphical model is that the graph implies that some variables do not interact directly. The complete graph is not very useful because it&#160;does not imply any independences.</span></p>
<p><span class="font64">When we represent a probability distribution with a graph, we want to choose a graph that implies as many independences as possible, without implying any&#160;independences that do not actually exist.</span></p>
<p><span class="font64">From this point of view, some distributions can be represented more efficiently using directed models, while other distributions can be represented more efficiently&#160;using undirected models. In other words, directed models can encode some&#160;independences that undirected models cannot encode, and vice versa.</span></p>
<p><span class="font64">Directed models are able to use one specific kind of substructure that undirected models cannot represent perfectly. This substructure is called an </span><span class="font63" style="font-style:italic;">immorality.</span><span class="font64"> The&#160;structure occurs when two random variables a and b are both parents of a third&#160;random variable c, and there is no edge directly connecting a and b in either&#160;direction. (The name “immorality” may seem strange; it was coined in the graphical&#160;models literature as a joke about unmarried parents.) To convert a directed model&#160;with graph D into an undirected model, we need to create a new graph </span><span class="font63" style="font-style:italic;">U.</span><span class="font64"> For&#160;every pair of variables x and y, we add an undirected edge connecting x and y to&#160;U if there is a directed edge (in either direction) connecting x and y in D or if x&#160;and y are both parents in D of a third variable z. The resulting U is known as&#160;a </span><span class="font63" style="font-style:italic;">moralized graph.</span><span class="font64"> See Fig. 16.11 for examples of converting directed models to&#160;undirected models via moralization.</span></p>
<p><span class="font64">Likewise, undirected models can include substructures that no directed model can represent perfectly. Specifically, a directed graph D cannot capture all of the&#160;conditional independences implied by an undirected graph U if U contains a </span><span class="font63" style="font-style:italic;">loop&#160;</span><span class="font64">of length greater than three, unless that loop also contains a </span><span class="font63" style="font-style:italic;">chord.</span><span class="font64"> A loop is&#160;a sequence of variables connected by undirected edges, with the last variable in&#160;the sequence connected back to the first variable in the sequence. A chord is a&#160;connection between any two non-consecutive variables in the sequence defining a&#160;loop. If U has loops of length four or greater and does not have chords for these&#160;loops, we must add the chords before we can convert it to a directed model. Adding&#160;these chords discards some of the independence information that was encoded in&#160;U. The graph formed by adding chords to U is known as a </span><span class="font63" style="font-style:italic;">chordal</span><span class="font64"> or </span><span class="font63" style="font-style:italic;">triangulated&#160;</span><span class="font64">graph, because all the loops can now be described in terms of smaller, triangular&#160;loops. To build a directed graph D from the chordal graph, we need to also assign&#160;directions to the edges. When doing so, we must not create a directed cycle in&#160;D, or the result does not define a valid directed probabilistic model. One way&#160;to assign directions to the edges in D is to impose an ordering on the random</span></p><div><img src="main-172.jpg" alt=""/></div><div><img src="main-173.jpg" alt=""/>
<p><span class="font64">Figure 16.12: Converting an undirected model to a directed model. </span><span class="font64" style="font-style:italic;">(Left)</span><span class="font64"> This undirected model cannot be converted directed to a directed model because it has a loop of length four&#160;with no chords. Specifically, the undirected model encodes two different independences that&#160;no directed model can capture simultaneously: aTc | {b, d} and bTd | {a, c}. </span><span class="font64" style="font-style:italic;">(Center)&#160;</span><span class="font64">To convert the undirected model to a directed model, we must triangulate the graph,&#160;by ensuring that all loops of greater than length three have a chord. To do so, we can&#160;either add an edge connecting a and c or we can add an edge connecting b and d. In this&#160;example, we choose to add the edge connecting a and c. </span><span class="font64" style="font-style:italic;">(Right)</span><span class="font64"> To finish the conversion&#160;process, we must assign a direction to each edge. When doing so, we must not create any&#160;directed cycles. One way to avoid directed cycles is to impose an ordering over the nodes,&#160;and always point each edge from the node that comes earlier in the ordering to the node&#160;that comes later in the ordering. In this example, we use the variable names to impose&#160;alphabetical order.</span></p></div>
<p><span class="font64">variables, then point each edge from the node that comes earlier in the ordering to the node that comes later in the ordering. See Fig. 16.12 for a demonstration.</span></p><h5><a id="bookmark15"></a><span class="font64" style="font-weight:bold;">16.2.7 Factor Graphs</span></h5>
<p><span class="font63" style="font-style:italic;">Factor graphs</span><span class="font64"> are another way of drawing undirected models that resolve an ambiguity in the graphical representation of standard undirected model syntax.&#160;In an undirected model, the scope of every ^ function must be a subset of some&#160;clique in the graph. However, it is not necessary that there exist any ^ whose&#160;scope contains the entirety of every clique. Factor graphs explicitly represent the&#160;scope of each ^ function. Specifically, a factor graph is a graphical representation&#160;of an undirected model that consists of a bipartite undirected graph. Some of the&#160;nodes are drawn as circles. These nodes correspond to random variables as in a&#160;standard undirected model. The rest of the nodes are drawn as squares. These&#160;nodes correspond to the factors ^ of the unnormalized probability distribution.&#160;Variables and factors may be connected with undirected edges. A variable and a&#160;factor are connected in the graph if and only if the variable is one of the arguments&#160;to the factor in the unnormalized probability distribution. No factor may be&#160;connected to another factor in the graph, nor can a variable be connected to a</span></p>
<p><span class="font64">variable. See Fig. 16.13 for an example of how factor graphs can resolve ambiguity in the interpretation of undirected networks.</span></p><div><div><img src="main-174.jpg" alt=""/></div></div><div><div><img src="main-175.jpg" alt=""/>
<p><span class="font64">Figure 16.13: An example of how a factor graph can resolve ambiguity in the interpretation of undirected networks. </span><span class="font63" style="font-style:italic;">(Left)</span><span class="font64"> An undirected network with a clique involving three&#160;variables: a, b and c. </span><span class="font63" style="font-style:italic;">(Center)</span><span class="font64"> A factor graph corresponding to the same undirected&#160;model. This factor graph has one factor over all three variables. </span><span class="font63" style="font-style:italic;">(Right)</span><span class="font64"> Another valid&#160;factor graph for the same undirected model. This factor graph has three factors, each&#160;over only two variables. Representation, inference, and learning are all asymptotically&#160;cheaper in this factor graph than in the factor graph depicted in the center, even though&#160;both require the same undirected graph to represent.</span></p></div></div><h4><a id="bookmark16"></a><span class="font65" style="font-weight:bold;">16.3 Sampling from Graphical Models</span></h4>
<p><span class="font64">Graphical models also facilitate the task of drawing samples from a model.</span></p>
<p><span class="font64">One advantage of directed graphical models is that a simple and efficient procedure called </span><span class="font64" style="font-weight:bold;font-style:italic;">ancestral sampling</span><span class="font64"> can produce a sample from the joint distribution&#160;represented by the model.</span></p>
<p><span class="font64">The basic idea is to sort the variables x* in the graph into a topological ordering, so that for all </span><span class="font64" style="font-weight:bold;font-style:italic;">i</span><span class="font64"> and j, j is greater than </span><span class="font64" style="font-weight:bold;font-style:italic;">i</span><span class="font64"> if xi is a parent of xj. The variables&#160;can then be sampled in this order. In other words, we first sample x! ~ P(x </span><span class="font18">1</span><span class="font64">),&#160;then sample P(x</span><span class="font18">2</span><span class="font64"> | </span><span class="font64" style="font-weight:bold;font-style:italic;">Pag(x</span><span class="font18">2</span><span class="font64">)), and so on, until finally we sample P(xn | </span><span class="font64" style="font-weight:bold;font-style:italic;">Pag</span><span class="font64">(xn)).&#160;So long as each conditional distribution p( x^ | Pag (xi)) is easy to sample from,&#160;then the whole model is easy to sample from. The topological sorting operation&#160;guarantees that we can read the conditional distributions in Eq.16.1 and sample&#160;from them in order. Without the topological sorting, we might attempt to sample&#160;a variable before its parents are available.</span></p>
<p><span class="font64">For some graphs, more than one topological ordering is possible. Ancestral sampling may be used with any of these topological orderings.</span></p>
<p><span class="font64">Ancestral sampling is generally very fast (assuming sampling from each conditional is easy) and convenient.</span></p>
<p><span class="font64">One drawback to ancestral sampling is that it only applies to directed graphical models. Another drawback is that it does not support every conditional sampling&#160;operation. When we wish to sample from a subset of the variables in a directed&#160;graphical model, given some other variables, we often require that all the conditioning variables come earlier than the variables to be sampled in the ordered graph.&#160;In this case, we can sample from the local conditional probability distributions&#160;specified by the model distribution. Otherwise, the conditional distributions we&#160;need to sample from are the posterior distributions given the observed variables.&#160;These posterior distributions are usually not explicitly specified and parametrized&#160;in the model. Inferring these posterior distributions can be costly. In models where&#160;this is the case, ancestral sampling is no longer efficient.</span></p>
<p><span class="font64">Unfortunately, ancestral sampling is applicable only to directed models. We can sample from undirected models by converting them to directed models, but this&#160;often requires solving intractable inference problems (to determine the marginal&#160;distribution over the root nodes of the new directed graph) or requires introducing&#160;so many edges that the resulting directed model becomes intractable. Sampling&#160;from an undirected model without first converting it to a directed model seems to&#160;require resolving cyclical dependencies. Every variable interacts with every other&#160;variable, so there is no clear beginning point for the sampling process. Unfortunately,&#160;drawing samples from an undirected graphical model is an expensive, multi-pass&#160;process. The conceptually simplest approach is </span><span class="font63" style="font-style:italic;">Gibbs sampling.</span><span class="font64"> Suppose we&#160;have a graphical model over an n-dimensional vector of random variables x. We&#160;iteratively visit each variable </span><span class="font63" style="font-style:italic;">xi</span><span class="font64"> and draw a sample conditioned on all of the other&#160;variables, from p(x<sub>i</sub> | x<sub>-i</sub>). Due to the separation properties of the graphical&#160;model, we can equivalently condition on only the neighbors ofx<sub>i</sub>. Unfortunately,&#160;after we have made one pass through the graphical model and sampled all </span><span class="font63" style="font-style:italic;">n&#160;</span><span class="font64">variables, we still do not have a fair sample from p(x). Instead, we must repeat the&#160;process and resample all n variables using the updated values of their neighbors.&#160;Asymptotically, after many repetitions, this process converges to sampling from&#160;the correct distribution. It can be difficult to determine when the samples have&#160;reached a sufficiently accurate approximation of the desired distribution. Sampling&#160;techniques for undirected models are an advanced topic, covered in more detail in&#160;Chapter 17.</span></p><div><div><img src="main-176.jpg" alt=""/>
<p><span class="font64">Figure 16.11: Examples of converting directed models (top row) to undirected models (bottom row) by constructing moralized graphs. </span><span class="font64" style="font-style:italic;">(Left)</span><span class="font64"> This simple chain can be converted&#160;to a moralized graph merely by replacing its directed edges with undirected edges. The&#160;resulting undirected model implies exactly the same set of independences and conditional&#160;independences. </span><span class="font64" style="font-style:italic;">(Center)</span><span class="font64"> This graph is the simplest directed model that cannot be&#160;converted to an undirected model without losing some independences. This graph consists&#160;entirely of a single immorality. Because a and b are parents of c, they are connected by an&#160;active path when c is observed. To capture this dependence, the undirected model must&#160;include a clique encompassing all three variables. This clique fails to encode the fact that&#160;aTb. </span><span class="font64" style="font-style:italic;">(Right)</span><span class="font64"> In general, moralization may add many edges to the graph, thus losing many&#160;implied independences. For example, this sparse coding graph requires adding moralizing&#160;edges between every pair of hidden units, thus introducing a quadratic number of new&#160;direct dependences.</span></p></div></div><h4><a id="bookmark17"></a><span class="font65" style="font-weight:bold;">16.4 Advantages of Structured Modeling</span></h4>
<p><span class="font64">The primary advantage of using structured probabilistic models is that they allow us to dramatically reduce the cost of representing probability distributions as well&#160;as learning and inference. Sampling is also accelerated in the case of directed&#160;models, while the situation can be complicated with undirected models. The&#160;primary mechanism that allows all of these operations to use less runtime and&#160;memory is choosing to not model certain interactions. Graphical models convey&#160;information by leaving edges out. Anywhere there is not an edge, the model&#160;specifies the assumption that we do not need to model a direct interaction.</span></p>
<p><span class="font64">A less quantifiable benefit of using structured probabilistic models is that they allow us to explicitly separate representation of knowledge from learning of&#160;knowledge or inference given existing knowledge. This makes our models easier to&#160;develop and debug. We can design, analyze, and evaluate learning algorithms and&#160;inference algorithms that are applicable to broad classes of graphs. Independently,&#160;we can design models that capture the relationships we believe are important in our&#160;data. We can then combine these different algorithms and structures and obtain&#160;a Cartesian product of different possibilities. It would be much more difficult to&#160;design end-to-end algorithms for every possible situation.</span></p>
<p><a id="bookmark2"><sup><a href="#footnote1">1</a></sup></a></p>
<p><span class="font64"><sup></sup> A </span><span class="font64" style="font-style:italic;">natural image</span><span class="font64"> is an image that might be captured by a camera in a reasonably ordinary environment, as opposed to a synthetically rendered image, a screenshot of a web page, etc.</span></p>
<p><a id="bookmark5"><sup><a href="#footnote2">2</a></sup></a></p>
<p><span class="font64"><sup></sup> Judea Pearl suggested using the term “Bayesian network” when one wishes to “emphasize the judgmental” nature of the values computed by the network, i.e. to highlight that they usually&#160;represent degrees of belief rather than frequencies of events.</span></p>
<p><a id="bookmark7"><sup><a href="#footnote3">3</a></sup></a></p>
<p><span class="font64"><sup></sup> A clique of the graph is a subset of nodes that are all connected to each other by an edge of&#160;the graph.</span></p>
<p><a id="bookmark9"><sup><a href="#footnote4">4</a></sup></a></p>
<p><span class="font64"><sup></sup> A distribution defined by normalizing a product of clique potentials is also called a </span><span class="font64" style="font-weight:bold;font-style:italic;">Gibbs</span></p>
<p><a id="bookmark10"><sup><a href="#footnote5">5</a></sup></a></p>
<p><span class="font64" style="font-weight:bold;font-style:italic;">distribution.</span></p>
<p><a id="bookmark12"><sup><a href="#footnote6">6</a></sup></a></p>
<p><span class="font64"><sup></sup> For some models, we may still need to use constrained optimization to make sure Z exists.</span></p>
</body>
</html>