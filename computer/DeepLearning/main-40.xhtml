<?xml version="1.0" encoding="UTF-8"?>

<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta name="charset" content="UTF-8"/><title></title><link rel="stylesheet" href="main.css" type="text/css"/>
</head>
<body><h4><a id="bookmark0"></a><span class="font65" style="font-weight:bold;">20.11 Drawing Samples from Autoencoders</span></h4>
<p><span class="font64">In Chapter 14, we saw that many kinds of autoencoders learn the data distribution. There are close connections between score matching, denoising autoencoders, and&#160;contractive autoencoders. These connections demonstrate that some kinds of&#160;autoencoders learn the data distribution in some way. We have not yet seen how&#160;to draw samples from such models.</span></p>
<p><span class="font64">Some kinds of autoencoders, such as the variational autoencoder, explicitly represent a probability distribution and admit straightforward ancestral sampling.&#160;Most other kinds of autoencoders require MCMC sampling.</span></p>
<p><span class="font64">Contractive autoencoders are designed to recover an estimate of the tangent plane of the data manifold. This means that repeated encoding and decoding with&#160;injected noise will induce a random walk along the surface of the manifold (Rifai&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2012; Mesnil </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2012). This manifold diffusion technique is a kind of&#160;Markov chain.</span></p>
<p><span class="font64">There is also a more general Markov chain that can sample from any denoising autoencoder.</span></p><h5><a id="bookmark1"></a><span class="font64" style="font-weight:bold;">20.11.1 &#160;&#160;&#160;Markov Chain Associated with any Denoising Autoencoder</span></h5>
<p><span class="font64">The above discussion left open the question of what noise to inject and where, in order to obtain a Markov chain that would generate from the distribution estimated&#160;by the autoencoder. Bengio </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2013c) showed how to construct such a Markov&#160;chain for </span><span class="font64" style="font-weight:bold;font-style:italic;">generalized denoising autoencoders.</span><span class="font64"> Generalized denoising autoencoders&#160;are specified by a denoising distribution for sampling an estimate of the clean input&#160;given the corrupted input.</span></p>
<p><span class="font64">Each step of the Markov chain that generates from the estimated distribution consists of the following sub-steps, illustrated in Fig. 20.11: <a id="footnote1"></a><sup><a href="#bookmark2">1</a></sup><sup> <a id="footnote2"></a><a href="#bookmark3">2</a> <a id="footnote3"></a><a href="#bookmark4">3</a> <a id="footnote4"></a><a href="#bookmark5">4</a></sup></span></p><div><img src="main-202.jpg" alt=""/>
<p><span class="font64">Figure 20.11: Each step of the Markov chain associated with a trained denoising autoencoder, that generates the samples from the probabilistic model implicitly trained by the denoising log-likelihood criterion. Each step consists in (a) injecting noise via corruption&#160;process C in state x, yielding x, (b) encoding it with function f, yielding </span><span class="font64" style="font-style:italic;">h = f</span><span class="font64"> (x),&#160;(c) decoding the result with function g, yielding parameters u for the reconstruction&#160;distribution, and (d) given u, sampling a new state from the reconstruction distribution&#160;</span><span class="font64" style="font-style:italic;">p(x</span><span class="font64"> | u </span><span class="font64" style="font-style:italic;">= g</span><span class="font64">(f (X))). In the typical squared reconstruction error case, g (h) = X, which&#160;estimates E[x | X], corruption consists in adding Gaussian noise and sampling from&#160;</span><span class="font64" style="font-style:italic;">p(x</span><span class="font64"> | u) consists in adding Gaussian noise, a second time, to the reconstruction x. The&#160;latter noise level should correspond to the mean squared error of reconstructions, whereas&#160;the injected noise is a hyperparameter that controls the mixing speed as well as the&#160;extent to which the estimator smooths the empirical distribution (Vincent, 2011). In the&#160;example illustrated here, only the C and </span><span class="font64" style="font-style:italic;">p</span><span class="font64"> conditionals are stochastic steps (f and g are&#160;deterministic computations), although noise can also be injected inside the autoencoder,&#160;as in generative stochastic networks (Bengio </span><span class="font64" style="font-style:italic;">et al.,</span><span class="font64"> 2014).</span></p></div><div>
<p><span class="font64">consistent stationary&#160;(albeit an</span></p></div>
<p><span class="font64">the </span><span class="font64" style="font-weight:bold;font-style:italic;">free</span><span class="font64"> units </span><span class="font64" style="font-weight:bold;font-style:italic;">x<sub>o</sub></span><span class="font64"> given xf and the sampled latent variables (if any). For example, MP-DBMs can be interpreted as a form of denoising autoencoder, and are able&#160;to sample missing inputs. GSNs later generalized some of the ideas present in&#160;MP-DBMs to perform the same operation (Bengio </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.,</span><span class="font64"> 2014). Alain </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2015)&#160;identified a missing condition from Proposition 1 of Bengio </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> (2014), which is&#160;that the transition operator (defined by the stochastic mapping going from one&#160;state of the chain to the next) should satisfy a property called </span><span class="font64" style="font-weight:bold;font-style:italic;">detailed balance,&#160;</span><span class="font64">which specifies that a Markov Chain at equilibrium will remain in equilibrium&#160;whether the transition operator is run in forward or reverse.</span></p>
<p><span class="font64">An experiment in clamping half of the pixels (the right part of the image) and running the Markov chain on the other half is shown in Fig. 20.12.</span></p>
<p><a id="bookmark2"><sup><a href="#footnote1">1</a></sup></a></p>
<p><span class="font64"> &#160;&#160;&#160;Starting from the previous state x, inject corruption noise, sampling X from&#160;</span><span class="font64" style="font-weight:bold;font-style:italic;">C(X |</span><span class="font64"> x).</span></p>
<p><a id="bookmark3"><sup><a href="#footnote2">2</a></sup></a></p>
<p><span class="font64"> &#160;&#160;&#160;Encode X into </span><span class="font64" style="font-weight:bold;font-style:italic;">h = f (X).</span></p>
<p><a id="bookmark4"><sup><a href="#footnote3">3</a></sup></a></p>
<p><span class="font64"> Decode h to obtain the parameters w = g(h) of p(x | w = g(h)) = p(x | </span><span class="font64" style="font-weight:bold;font-style:italic;">X).</span></p>
<p><a id="bookmark5"><sup><a href="#footnote4">4</a></sup></a></p>
<p><span class="font64"> Sample the next state x from </span><span class="font64" style="font-weight:bold;font-style:italic;">p(x</span><span class="font64"> | w = g(h)) = </span><span class="font64" style="font-weight:bold;font-style:italic;">p(x</span><span class="font64"> | </span><span class="font64" style="font-weight:bold;font-style:italic;">X).</span></p>
<p><span class="font64">Bengio </span><span class="font64" style="font-weight:bold;font-style:italic;">et al.</span><span class="font64"> ( 01׳ ) showed that if the autoencoder p( </span><span class="font64" style="font-weight:bold;font-style:italic;">x</span><span class="font64"> | x) forms a estimator of the corresponding true conditional distribution, then the&#160;distribution of the above Markov chain forms a consistent estimator&#160;implicit one) of the data generating distribution of x.</span></p>
<p><span class="font64" style="font-weight:bold;">20.11.2 &#160;&#160;&#160;Clamping and Conditional Sampling</span></p>
<p><span class="font64">Similarly to Boltzmann machines, denoising autoencoders and their generalizations (such as GSNs, described below) can be used to sample from a conditional distribution p(xf | x<sub>o</sub>), simply by clamping the </span><span class="font64" style="font-weight:bold;font-style:italic;">observed</span><span class="font64"> units </span><span class="font64" style="font-weight:bold;font-style:italic;">xf</span><span class="font64"> and only resampling</span></p>
</body>
</html>